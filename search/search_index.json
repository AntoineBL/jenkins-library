{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project \"Piper\" User Documentation \u00b6 An efficient software development process is vital for success in building business applications on SAP Cloud Platform or SAP on-premise platforms. SAP addresses this need for efficiency with project \"Piper\". The goal of project \"Piper\" is to substantially ease setting up continuous delivery processes for the most important SAP technologies by means of Jenkins pipelines. What you get \u00b6 Project \"Piper\" consists of two parts: A shared library containing steps and utilities that are required by Jenkins pipelines. A set of Docker images used in the piper library to implement best practices. The shared library contains all the necessary steps to run our best practice Jenkins pipelines described in the Scenarios section or to run a pipeline as step . The best practice pipelines are based on the general concepts of Jenkins 2.0 Pipelines as Code . With that you have the power of the Jenkins community at hand to optimize your pipelines. You can run the best practice Jenkins pipelines out of the box, take them as a starting point for project-specific adaptations or implement your own pipelines from scratch using the shared library. Extensibility \u00b6 If you consider adding additional capabilities to your Jenkinsfile , consult the Jenkins Pipeline Steps Reference . There, you get an overview about steps that are natively supported by Jenkins. The Jenkins shared libraries concept helps you to extract reusable parts from your pipeline and to keep your pipeline code small and easy to maintain. Custom library steps can be added using a custom library according to the Jenkins shared libraries concept instead of adding groovy coding to the Jenkinsfile . Your custom library can coexist next to the provided pipeline library. API \u00b6 All steps ( vars and resources directory) are intended to be used by Pipelines and are considered API. All the classes / groovy-scripts contained in the src folder are by default not part of the API and are subjected to change without prior notice. Types and methods annotated with @API are considered to be API, used e.g. from other shared libraries. Changes to those methods/types needs to be announced, discussed and agreed.","title":"Home"},{"location":"#project-piper-user-documentation","text":"An efficient software development process is vital for success in building business applications on SAP Cloud Platform or SAP on-premise platforms. SAP addresses this need for efficiency with project \"Piper\". The goal of project \"Piper\" is to substantially ease setting up continuous delivery processes for the most important SAP technologies by means of Jenkins pipelines.","title":"Project \"Piper\" User Documentation"},{"location":"#what-you-get","text":"Project \"Piper\" consists of two parts: A shared library containing steps and utilities that are required by Jenkins pipelines. A set of Docker images used in the piper library to implement best practices. The shared library contains all the necessary steps to run our best practice Jenkins pipelines described in the Scenarios section or to run a pipeline as step . The best practice pipelines are based on the general concepts of Jenkins 2.0 Pipelines as Code . With that you have the power of the Jenkins community at hand to optimize your pipelines. You can run the best practice Jenkins pipelines out of the box, take them as a starting point for project-specific adaptations or implement your own pipelines from scratch using the shared library.","title":"What you get"},{"location":"#extensibility","text":"If you consider adding additional capabilities to your Jenkinsfile , consult the Jenkins Pipeline Steps Reference . There, you get an overview about steps that are natively supported by Jenkins. The Jenkins shared libraries concept helps you to extract reusable parts from your pipeline and to keep your pipeline code small and easy to maintain. Custom library steps can be added using a custom library according to the Jenkins shared libraries concept instead of adding groovy coding to the Jenkinsfile . Your custom library can coexist next to the provided pipeline library.","title":"Extensibility"},{"location":"#api","text":"All steps ( vars and resources directory) are intended to be used by Pipelines and are considered API. All the classes / groovy-scripts contained in the src folder are by default not part of the API and are subjected to change without prior notice. Types and methods annotated with @API are considered to be API, used e.g. from other shared libraries. Changes to those methods/types needs to be announced, discussed and agreed.","title":"API"},{"location":"configuration/","text":"Configuration \u00b6 Configuration is done via a yml-file, located at .pipeline/config.yml in the master branch of your source code repository. Your configuration inherits from the default configuration located at https://github.com/SAP/jenkins-library/blob/master/resources/default_pipeline_environment.yml . Adding custom parameters Please note that adding custom parameters to the configuration is at your own risk. We may introduce new parameters at any time which may clash with your custom parameters. Configuration of the Piper steps as well the Piper templates can be done in a hierarchical manner. Directly passed step parameters will always take precedence over other configuration values and defaults Stage configuration parameters define a Jenkins pipeline stage dependent set of parameters (e.g. deployment options for the Acceptance stage) Step configuration defines how steps behave in general (e.g. step cloudFoundryDeploy ) General configuration parameters define parameters which are available across step boundaries Default configuration comes with the Piper library and is always available Collecting telemetry data \u00b6 In order to improve this Jenkins library we are collecting telemetry data. Data is send using com.sap.piper.pushToSWA Following data (non-personal) is collected for example: Hashed job url, e.g. 4944f745e03f5f79daf0001eec9276ce351d3035 hash calculation is done in your Jenkins server and no original values are transmitted Name of library step which has been executed, like e.g. artifactSetVersion Certain parameters of the executed steps, e.g. buildTool=maven We store the telemetry data for not longer than 6 months on premises of SAP SE. Disable collection of telemetry data If you do not want to send telemetry data you can easily deactivate this. This is done with either of the following two ways: General deactivation in your .pipeline/config.yml file by setting the configuration parameter general -> collectTelemetryData: false (default setting can be found in the library defaults ). Please note: this will only take effect in all steps if you run setupCommonPipelineEnvironment at the beginning of your pipeline Individual deactivation per step by passing the parameter collectTelemetryData: false , like e.g. setVersion script:this, collectTelemetryData: false Example configuration \u00b6 general : gitSshKeyCredentialsId : GitHub_Test_SSH steps : cloudFoundryDeploy : deployTool : 'cf_native' cloudFoundry : org : 'testOrg' space : 'testSpace' credentialsId : 'MY_CF_CREDENTIALSID_IN_JENKINS' newmanExecute : newmanCollection : 'myNewmanCollection.file' newmanEnvironment : 'myNewmanEnvironment' newmanGlobals : 'myNewmanGlobals' Access to configuration from custom scripts \u00b6 Configuration is loaded into commonPipelineEnvironment during step setupCommonPipelineEnvironment . You can access the configuration values via commonPipelineEnvironment.configuration which will return you the complete configuration map. Thus following access is for example possible (accessing gitSshKeyCredentialsId from general section): commonPipelineEnvironment . configuration . general . gitSshKeyCredentialsId Access to configuration in custom library steps \u00b6 Within library steps the ConfigurationHelper object is used. You can see its usage in all the Piper steps, for example newmanExecute .","title":"Configuration"},{"location":"configuration/#configuration","text":"Configuration is done via a yml-file, located at .pipeline/config.yml in the master branch of your source code repository. Your configuration inherits from the default configuration located at https://github.com/SAP/jenkins-library/blob/master/resources/default_pipeline_environment.yml . Adding custom parameters Please note that adding custom parameters to the configuration is at your own risk. We may introduce new parameters at any time which may clash with your custom parameters. Configuration of the Piper steps as well the Piper templates can be done in a hierarchical manner. Directly passed step parameters will always take precedence over other configuration values and defaults Stage configuration parameters define a Jenkins pipeline stage dependent set of parameters (e.g. deployment options for the Acceptance stage) Step configuration defines how steps behave in general (e.g. step cloudFoundryDeploy ) General configuration parameters define parameters which are available across step boundaries Default configuration comes with the Piper library and is always available","title":"Configuration"},{"location":"configuration/#collecting-telemetry-data","text":"In order to improve this Jenkins library we are collecting telemetry data. Data is send using com.sap.piper.pushToSWA Following data (non-personal) is collected for example: Hashed job url, e.g. 4944f745e03f5f79daf0001eec9276ce351d3035 hash calculation is done in your Jenkins server and no original values are transmitted Name of library step which has been executed, like e.g. artifactSetVersion Certain parameters of the executed steps, e.g. buildTool=maven We store the telemetry data for not longer than 6 months on premises of SAP SE. Disable collection of telemetry data If you do not want to send telemetry data you can easily deactivate this. This is done with either of the following two ways: General deactivation in your .pipeline/config.yml file by setting the configuration parameter general -> collectTelemetryData: false (default setting can be found in the library defaults ). Please note: this will only take effect in all steps if you run setupCommonPipelineEnvironment at the beginning of your pipeline Individual deactivation per step by passing the parameter collectTelemetryData: false , like e.g. setVersion script:this, collectTelemetryData: false","title":"Collecting telemetry data"},{"location":"configuration/#example-configuration","text":"general : gitSshKeyCredentialsId : GitHub_Test_SSH steps : cloudFoundryDeploy : deployTool : 'cf_native' cloudFoundry : org : 'testOrg' space : 'testSpace' credentialsId : 'MY_CF_CREDENTIALSID_IN_JENKINS' newmanExecute : newmanCollection : 'myNewmanCollection.file' newmanEnvironment : 'myNewmanEnvironment' newmanGlobals : 'myNewmanGlobals'","title":"Example configuration"},{"location":"configuration/#access-to-configuration-from-custom-scripts","text":"Configuration is loaded into commonPipelineEnvironment during step setupCommonPipelineEnvironment . You can access the configuration values via commonPipelineEnvironment.configuration which will return you the complete configuration map. Thus following access is for example possible (accessing gitSshKeyCredentialsId from general section): commonPipelineEnvironment . configuration . general . gitSshKeyCredentialsId","title":"Access to configuration from custom scripts"},{"location":"configuration/#access-to-configuration-in-custom-library-steps","text":"Within library steps the ConfigurationHelper object is used. You can see its usage in all the Piper steps, for example newmanExecute .","title":"Access to configuration in custom library steps"},{"location":"guidedtour/","text":"Getting Started with Project \"Piper\" \u00b6 Follow this guided tour to become familiar with the basics of using project \"Piper\". The public sample application cloud-cf-helloworld-nodejs will be enriched with a pipeline which syncs the sources, builds these as MTA and deploys the result into a Cloud Foundry environment. The application contains a simple nodejs application. Deployed as web service, it serves static data. Recommendation: We recommend to clone the sample application cloud-cf-helloworld-nodejs and execute the instructions on your own repository. See (Optional) Sample Application . The stated instructions assume the use of this application. Prerequisites \u00b6 You have installed a Linux system with at least 4 GB memory. Note: We have tested our samples on Ubuntu 16.04. On Microsoft Windows, you might face some issues. You have installed the newest version of Docker. See Docker Community Edition . Note: we have tested on Docker 18.09.6. You have installed Jenkins 2.60.3 or higher. Recommendation: We recommend to use the cx-server toolkit. See (Optional) Install the cx-server Toolkit for Jenkins . Note: If you use your own Jenkins installation you need to care for \"Piper\" specific configuration. Follow my own Jenkins installation . Your system has access to GitHub.com . (Optional) Install the cx-server Toolkit for Jenkins \u00b6 cx-server is a lifecycle management toolkit that provides Docker images with a preconfigured Jenkins and a Nexus-based cache to facilitate the configuration and usage of Jenkins. To use the toolkit, get the cx-server script and its configuration file server.cfg by using the following command: docker run -it --rm -u $( id -u ) : $( id -g ) -v \" ${ PWD } \" :/cx-server/mount/ ppiper/cx-server-companion:latest init-cx-server When the files are downloaded into the current directory, launch the Jenkins server by using the following command: ./cx-server start For more information on the Jenkins lifecycle management and how to customize your Jenkins, have a look at the Operations Guide for Cx Server . (Optional) Sample Application \u00b6 Copy the sources of the application into your own Git repository. While we will ask you to fork the application's repository into a GitHub space, you can use any version control system based on Git like GitLab or plain git . Note: A public GitHub repository is visible to the public. The configuration files may contain data you don't want to expose, so use a private repository. Create an organization on GitHub, if you haven't any yet. See Creating a new organization . Duplicate the repository cloud-cf-helloworld-nodejs into your GitHub organization. Make this repository private . Note: Forked public repositories cannot be made private. Get an account and space in the Cloud Foundry environment. For the deployment of the application you need access to a space on the Cloud Foundry environment of the SAP Cloud Platform. If you haven't any yet, get a Trial Account . Select the 1_REST_persist_in_Memory branch of your cloud-cf-helloworld-nodejs fork. Other branches might work as well, but this one is tested. Create Your First Pipeline \u00b6 Get your application repository in place. Create a new file with the name Jenkinsfile in the root level of your repository and enter the following code: @Library('piper-lib-os') _ node() { stage('prepare') { checkout scm setupCommonPipelineEnvironment script:this } } The \"prepare\" step synchronizes the repository and initializes the project specific settings. For more information about Jenkinsfiles and pipelines, see Using a Jenkinsfile . Save your changes to your remote repository. To set up a Jenkins job for your repository, open the Jenkins UI under http://<jenkins-server-address>:<http-port> and choose New Item . Per default, the cx-server starts Jenkins on HTTP port 80 . For more information, see the Jenkins User Documentation . Provide a name for your new item (for example, My First Pipeline ) and select Pipeline . For Definition in the Pipeline options, choose Pipeline script from SCM . For SCM , choose Git . For Repository URL in the Repositories section, enter the URL of your Git repository, for example https://github.com/<your-org>/cloud-cf-helloworld-nodejs . Note: If your repository is protected, you must provide your credentials in the Credentials section. For Branch Specifier in the Branches to build section, enter the branch name */1_REST_persist_in_Memory . Choose Save . To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed the single stage \"prepare\". Add a Build Step \u00b6 In your Jenkinsfile , add the following code snippet: stage('build') { mtaBuild script: this } The mtaBuild step calls a build tool to build a multi-target application (MTA). The tool consumes an MTA descriptor that contains the metadata of all entities which comprise an application or are used by one during deployment or runtime, and the dependencies between them. For more information about MTAs, see sap.com . Create the MTA descriptor file with the name mta.yaml in the root level of the repository. Insert the following code: _schema-version: 2.1.0 ID: com.sap.piper.node.hello.world version: 1.0.0 description: A Hello World sample application provider: SAP Sample generator modules: - name: piper.node.hello.world type: nodejs path: . Configure the step to build an MTA for the Cloud Foundry environment. Create the configuration file .pipeline/config.yml relative to the root level of the repository and insert the following content: general: steps: mtaBuild: buildTarget: 'CF' For additional information about the configuration, have a look at the Common Configuration Guide and the MTA build step documentation . Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed two stages, the \"prepare\" and the \"build\". Add a Deploy Step \u00b6 In your Jenkinsfile , add the following code snippet: stage('deploy') { cloudFoundryDeploy script: this } The cloudFoundryDeploy step calls the Cloud Foundry command line client to deploy the built MTA into SAP Cloud Platform. To configure the step to deploy into the Cloud Foundry environment, in your repository, open the .pipeline/config.yml and add the following content: cloudFoundryDeploy: deployTool: 'mtaDeployPlugin' deployType: 'standard' cloudFoundry: org: '<your-organisation>' space: '<your-space>' credentialsId: 'CF_CREDENTIALSID' Note: look after the indentation of the step within the YAML. Specify the organisation and space properties. For more information about the configuration, see the Common Configuration Guide and cloudFoundryDeploy . The key CF_CREDENTIALSID refers to a user-password credential you must create in Jenkins: In Jenkins, choose Credentials from the main menu and add a Username with Password entry. Save the Credential Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed the three stages \"prepare\", \"build\" and \"deploy\". If your pipeline fails, compare its files to the final Jenkinsfile , the config.yml , and the mta.yaml . Note : YAML files are surprisingly sensitive regarding indentation. Open Application \u00b6 Your application has been deployed into your space in the Cloud Foundry space on SAP Cloud Platform. Login to SAP Cloud Platform and navigate into you space. Result: Your space contains the application piper.node.hello.world , the state of the application is Started . Open the application name to get into the Application Overview . Open the Application Route and add /users to the URL. Result: The application returns a list of user data. What's Next \u00b6 You are now familiar with the basics of using project \"Piper\". Through the concept of pipeline as code, project \"Piper\" and Jenkins pipelines are extremely powerful. While Jenkins pipelines offer a full set of common programming features, project \"Piper\" adds SAP-specific flavors. Have a look at the different Scenarios to understand how to easily integrate SAP systems with default pipelines. Browse the steadily increasing list of features you can implement through the project \"Piper\" Steps . The Configuration pattern supports simple pipelines that can be reused by multiple applications. To understand the principles of inheritance and customization, have a look at the the configuration documentation. Please also consult the blog post on setting up Continuous Delivery for S/4HANA extensions and get tons of informations around the application development with the S/4HANA Cloud SDK .","title":"Guided Tour"},{"location":"guidedtour/#getting-started-with-project-piper","text":"Follow this guided tour to become familiar with the basics of using project \"Piper\". The public sample application cloud-cf-helloworld-nodejs will be enriched with a pipeline which syncs the sources, builds these as MTA and deploys the result into a Cloud Foundry environment. The application contains a simple nodejs application. Deployed as web service, it serves static data. Recommendation: We recommend to clone the sample application cloud-cf-helloworld-nodejs and execute the instructions on your own repository. See (Optional) Sample Application . The stated instructions assume the use of this application.","title":"Getting Started with Project \"Piper\""},{"location":"guidedtour/#prerequisites","text":"You have installed a Linux system with at least 4 GB memory. Note: We have tested our samples on Ubuntu 16.04. On Microsoft Windows, you might face some issues. You have installed the newest version of Docker. See Docker Community Edition . Note: we have tested on Docker 18.09.6. You have installed Jenkins 2.60.3 or higher. Recommendation: We recommend to use the cx-server toolkit. See (Optional) Install the cx-server Toolkit for Jenkins . Note: If you use your own Jenkins installation you need to care for \"Piper\" specific configuration. Follow my own Jenkins installation . Your system has access to GitHub.com .","title":"Prerequisites"},{"location":"guidedtour/#optional-install-the-cx-server-toolkit-for-jenkins","text":"cx-server is a lifecycle management toolkit that provides Docker images with a preconfigured Jenkins and a Nexus-based cache to facilitate the configuration and usage of Jenkins. To use the toolkit, get the cx-server script and its configuration file server.cfg by using the following command: docker run -it --rm -u $( id -u ) : $( id -g ) -v \" ${ PWD } \" :/cx-server/mount/ ppiper/cx-server-companion:latest init-cx-server When the files are downloaded into the current directory, launch the Jenkins server by using the following command: ./cx-server start For more information on the Jenkins lifecycle management and how to customize your Jenkins, have a look at the Operations Guide for Cx Server .","title":"(Optional) Install the cx-server Toolkit for Jenkins"},{"location":"guidedtour/#optional-sample-application","text":"Copy the sources of the application into your own Git repository. While we will ask you to fork the application's repository into a GitHub space, you can use any version control system based on Git like GitLab or plain git . Note: A public GitHub repository is visible to the public. The configuration files may contain data you don't want to expose, so use a private repository. Create an organization on GitHub, if you haven't any yet. See Creating a new organization . Duplicate the repository cloud-cf-helloworld-nodejs into your GitHub organization. Make this repository private . Note: Forked public repositories cannot be made private. Get an account and space in the Cloud Foundry environment. For the deployment of the application you need access to a space on the Cloud Foundry environment of the SAP Cloud Platform. If you haven't any yet, get a Trial Account . Select the 1_REST_persist_in_Memory branch of your cloud-cf-helloworld-nodejs fork. Other branches might work as well, but this one is tested.","title":"(Optional) Sample Application"},{"location":"guidedtour/#create-your-first-pipeline","text":"Get your application repository in place. Create a new file with the name Jenkinsfile in the root level of your repository and enter the following code: @Library('piper-lib-os') _ node() { stage('prepare') { checkout scm setupCommonPipelineEnvironment script:this } } The \"prepare\" step synchronizes the repository and initializes the project specific settings. For more information about Jenkinsfiles and pipelines, see Using a Jenkinsfile . Save your changes to your remote repository. To set up a Jenkins job for your repository, open the Jenkins UI under http://<jenkins-server-address>:<http-port> and choose New Item . Per default, the cx-server starts Jenkins on HTTP port 80 . For more information, see the Jenkins User Documentation . Provide a name for your new item (for example, My First Pipeline ) and select Pipeline . For Definition in the Pipeline options, choose Pipeline script from SCM . For SCM , choose Git . For Repository URL in the Repositories section, enter the URL of your Git repository, for example https://github.com/<your-org>/cloud-cf-helloworld-nodejs . Note: If your repository is protected, you must provide your credentials in the Credentials section. For Branch Specifier in the Branches to build section, enter the branch name */1_REST_persist_in_Memory . Choose Save . To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed the single stage \"prepare\".","title":"Create Your First Pipeline"},{"location":"guidedtour/#add-a-build-step","text":"In your Jenkinsfile , add the following code snippet: stage('build') { mtaBuild script: this } The mtaBuild step calls a build tool to build a multi-target application (MTA). The tool consumes an MTA descriptor that contains the metadata of all entities which comprise an application or are used by one during deployment or runtime, and the dependencies between them. For more information about MTAs, see sap.com . Create the MTA descriptor file with the name mta.yaml in the root level of the repository. Insert the following code: _schema-version: 2.1.0 ID: com.sap.piper.node.hello.world version: 1.0.0 description: A Hello World sample application provider: SAP Sample generator modules: - name: piper.node.hello.world type: nodejs path: . Configure the step to build an MTA for the Cloud Foundry environment. Create the configuration file .pipeline/config.yml relative to the root level of the repository and insert the following content: general: steps: mtaBuild: buildTarget: 'CF' For additional information about the configuration, have a look at the Common Configuration Guide and the MTA build step documentation . Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed two stages, the \"prepare\" and the \"build\".","title":"Add a Build Step"},{"location":"guidedtour/#add-a-deploy-step","text":"In your Jenkinsfile , add the following code snippet: stage('deploy') { cloudFoundryDeploy script: this } The cloudFoundryDeploy step calls the Cloud Foundry command line client to deploy the built MTA into SAP Cloud Platform. To configure the step to deploy into the Cloud Foundry environment, in your repository, open the .pipeline/config.yml and add the following content: cloudFoundryDeploy: deployTool: 'mtaDeployPlugin' deployType: 'standard' cloudFoundry: org: '<your-organisation>' space: '<your-space>' credentialsId: 'CF_CREDENTIALSID' Note: look after the indentation of the step within the YAML. Specify the organisation and space properties. For more information about the configuration, see the Common Configuration Guide and cloudFoundryDeploy . The key CF_CREDENTIALSID refers to a user-password credential you must create in Jenkins: In Jenkins, choose Credentials from the main menu and add a Username with Password entry. Save the Credential Save your changes to your remote repository. To run your pipeline, choose Build Now in the job UI. Result: The pipeline processed the three stages \"prepare\", \"build\" and \"deploy\". If your pipeline fails, compare its files to the final Jenkinsfile , the config.yml , and the mta.yaml . Note : YAML files are surprisingly sensitive regarding indentation.","title":"Add a Deploy Step"},{"location":"guidedtour/#open-application","text":"Your application has been deployed into your space in the Cloud Foundry space on SAP Cloud Platform. Login to SAP Cloud Platform and navigate into you space. Result: Your space contains the application piper.node.hello.world , the state of the application is Started . Open the application name to get into the Application Overview . Open the Application Route and add /users to the URL. Result: The application returns a list of user data.","title":"Open Application"},{"location":"guidedtour/#whats-next","text":"You are now familiar with the basics of using project \"Piper\". Through the concept of pipeline as code, project \"Piper\" and Jenkins pipelines are extremely powerful. While Jenkins pipelines offer a full set of common programming features, project \"Piper\" adds SAP-specific flavors. Have a look at the different Scenarios to understand how to easily integrate SAP systems with default pipelines. Browse the steadily increasing list of features you can implement through the project \"Piper\" Steps . The Configuration pattern supports simple pipelines that can be reused by multiple applications. To understand the principles of inheritance and customization, have a look at the the configuration documentation. Please also consult the blog post on setting up Continuous Delivery for S/4HANA extensions and get tons of informations around the application development with the S/4HANA Cloud SDK .","title":"What's Next"},{"location":"myownjenkins/","text":"My own Jenkins \u00b6 Note: This guide is not sufficient yet, to setup a Jenkins for project \"Piper\". Requirements \u00b6 Java Runtime Environment 8 Installation of Jenkins v 2.60.3 or higher running on Linux. We tested with debian-stretch. Jenkins Plugins installed as described in the Required Plugin section. A Jenkins user with administration privileges. The Jenkins instance has access to github.com . Download and Installation \u00b6 To setup the shared library, you need to perform the following steps: Login to your Jenkins instance with administration privileges. Open the system configuration page ( Manage Jenkins > Configure System ). Scroll down to section Global Pipeline Libraries and add a new Library by clicking the Add button. set Library Name to piper-lib-os set Default Version to the branch or tag you want to consume (e.g. master or v0.1 ) set Retrieval Method to Modern SCM set Source Code Management to Git set Project Repository to https://github.com/SAP/jenkins-library Save changes Now the library is available as piper-lib-os and can be used in any Jenkinsfile by adding this line: @Library ( 'piper-lib-os' ) _ Jenkins will download the library during execution of the Jenkinsfile .","title":"My own Jenkins"},{"location":"myownjenkins/#my-own-jenkins","text":"Note: This guide is not sufficient yet, to setup a Jenkins for project \"Piper\".","title":"My own Jenkins"},{"location":"myownjenkins/#requirements","text":"Java Runtime Environment 8 Installation of Jenkins v 2.60.3 or higher running on Linux. We tested with debian-stretch. Jenkins Plugins installed as described in the Required Plugin section. A Jenkins user with administration privileges. The Jenkins instance has access to github.com .","title":"Requirements"},{"location":"myownjenkins/#download-and-installation","text":"To setup the shared library, you need to perform the following steps: Login to your Jenkins instance with administration privileges. Open the system configuration page ( Manage Jenkins > Configure System ). Scroll down to section Global Pipeline Libraries and add a new Library by clicking the Add button. set Library Name to piper-lib-os set Default Version to the branch or tag you want to consume (e.g. master or v0.1 ) set Retrieval Method to Modern SCM set Source Code Management to Git set Project Repository to https://github.com/SAP/jenkins-library Save changes Now the library is available as piper-lib-os and can be used in any Jenkinsfile by adding this line: @Library ( 'piper-lib-os' ) _ Jenkins will download the library during execution of the Jenkinsfile .","title":"Download and Installation"},{"location":"jenkins/requiredPlugins/","text":"Required Plugins \u00b6 The following Jenkins plugins are needed in order to use the Piper Library. The list below contains the plugin Id and version of the plugin. Plugins ace-editor 1.1 authentication-tokens 1.3 bouncycastle-api 2.16.2 branch-api 2.0.14 cloudbees-folder 6.2.1 credentials 2.1.16 credentials-binding 1.13 display-url-api 2.1.0 docker-commons 1.9 docker-workflow 1.10 durable-task 1.15 git 3.6.2 git-client 2.5.0 git-server 1.7 handlebars 1.1.1 icon-shim 2.0.3 jquery-detached 1.2.1 junit 1.21 mailer 1.20 matrix-project 1.12 momentjs 1.1.1 pipeline-build-step 2.5.1 pipeline-graph-analysis 1.3 pipeline-input-step 2.8 pipeline-milestone-step 1.3.1 pipeline-model-api 1.2.2 pipeline-model-definition 1.1.1 pipeline-model-extensions 1.1.1 pipeline-rest-api 2.6 pipeline-stage-step 2.2 pipeline-stage-tags-metadata 1.2.2 pipeline-stage-view 2.6 pipeline-utility-steps 1.3.0 plain-credentials 1.4 scm-api 2.2.3 script-security 1.34 ssh-credentials 1.13 structs 1.10 workflow-aggregator 2.5 workflow-api 2.23.1 workflow-basic-steps 2.6 workflow-cps 2.41 workflow-cps-global-lib 2.7 workflow-durable-task-step 2.17 workflow-job 2.12.2 workflow-multibranch 2.14 workflow-scm-step 2.6 workflow-step-api 2.13 workflow-support 2.16","title":"Required Plugins"},{"location":"jenkins/requiredPlugins/#required-plugins","text":"The following Jenkins plugins are needed in order to use the Piper Library. The list below contains the plugin Id and version of the plugin. Plugins ace-editor 1.1 authentication-tokens 1.3 bouncycastle-api 2.16.2 branch-api 2.0.14 cloudbees-folder 6.2.1 credentials 2.1.16 credentials-binding 1.13 display-url-api 2.1.0 docker-commons 1.9 docker-workflow 1.10 durable-task 1.15 git 3.6.2 git-client 2.5.0 git-server 1.7 handlebars 1.1.1 icon-shim 2.0.3 jquery-detached 1.2.1 junit 1.21 mailer 1.20 matrix-project 1.12 momentjs 1.1.1 pipeline-build-step 2.5.1 pipeline-graph-analysis 1.3 pipeline-input-step 2.8 pipeline-milestone-step 1.3.1 pipeline-model-api 1.2.2 pipeline-model-definition 1.1.1 pipeline-model-extensions 1.1.1 pipeline-rest-api 2.6 pipeline-stage-step 2.2 pipeline-stage-tags-metadata 1.2.2 pipeline-stage-view 2.6 pipeline-utility-steps 1.3.0 plain-credentials 1.4 scm-api 2.2.3 script-security 1.34 ssh-credentials 1.13 structs 1.10 workflow-aggregator 2.5 workflow-api 2.23.1 workflow-basic-steps 2.6 workflow-cps 2.41 workflow-cps-global-lib 2.7 workflow-durable-task-step 2.17 workflow-job 2.12.2 workflow-multibranch 2.14 workflow-scm-step 2.6 workflow-step-api 2.13 workflow-support 2.16","title":"Required Plugins"},{"location":"scenarios/CAP_Scenario/","text":"Build and Deploy Applications with Jenkins and the SAP Cloud Application Programming Model \u00b6 Set up a basic continuous delivery process for developing applications according to the SAP Cloud Application Programming Model. Prerequisites \u00b6 You have an account on SAP Cloud Platform in the Cloud Foundry environment. See Accounts . You have downloaded and installed the Cloud Foundry command line interface (CLI). See Download and Install the Cloud Foundry Command Line Interface . You have installed the multi-target application plug-in for the Cloud Foundry command line interface. See Install the Multi-Target Application Plug-in in the Cloud Foundry Environment . You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . Context \u00b6 The Application Programming Model for SAP Cloud Platform is an end-to-end best practice guide for developing applications on SAP Cloud Platform and provides a supportive set of APIs, languages, and libraries. For more information about the SAP Cloud Application Programming Model, see Working with the SAP Cloud Application Programming Model . In this scenario, we want to show how to implement a basic continuous delivery process for developing applications according to this programming model with the help of project \"Piper\" on Jenkins. This basic scenario can be adapted and enriched according to your specific needs. Example \u00b6 Jenkinsfile \u00b6 @Library ( 'piper-library-os' ) _ node (){ stage ( 'Prepare' ) { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } stage ( 'Build' ) { mtaBuild script: this } stage ( 'Deploy' ) { cloudFoundryDeploy script: this , deployTool: 'mtaDeployPlugin' } } Configuration ( .pipeline/config.yml ) \u00b6 steps : mtaBuild : buildTarget : 'CF' cloudFoundryDeploy : cloudFoundry : credentialsId : 'CF' apiEndpoint : '<CF Endpoint>' org : '<CF Organization>' space : '<CF Space>' Parameters \u00b6 For the detailed description of the relevant parameters, see: mtaBuild cloudFoundryDeploy","title":"Build and Deploy Applications with Jenkins and the SAP Cloud Application Programming Model"},{"location":"scenarios/CAP_Scenario/#build-and-deploy-applications-with-jenkins-and-the-sap-cloud-application-programming-model","text":"Set up a basic continuous delivery process for developing applications according to the SAP Cloud Application Programming Model.","title":"Build and Deploy Applications with Jenkins and the SAP Cloud Application Programming Model"},{"location":"scenarios/CAP_Scenario/#prerequisites","text":"You have an account on SAP Cloud Platform in the Cloud Foundry environment. See Accounts . You have downloaded and installed the Cloud Foundry command line interface (CLI). See Download and Install the Cloud Foundry Command Line Interface . You have installed the multi-target application plug-in for the Cloud Foundry command line interface. See Install the Multi-Target Application Plug-in in the Cloud Foundry Environment . You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js .","title":"Prerequisites"},{"location":"scenarios/CAP_Scenario/#context","text":"The Application Programming Model for SAP Cloud Platform is an end-to-end best practice guide for developing applications on SAP Cloud Platform and provides a supportive set of APIs, languages, and libraries. For more information about the SAP Cloud Application Programming Model, see Working with the SAP Cloud Application Programming Model . In this scenario, we want to show how to implement a basic continuous delivery process for developing applications according to this programming model with the help of project \"Piper\" on Jenkins. This basic scenario can be adapted and enriched according to your specific needs.","title":"Context"},{"location":"scenarios/CAP_Scenario/#example","text":"","title":"Example"},{"location":"scenarios/CAP_Scenario/#jenkinsfile","text":"@Library ( 'piper-library-os' ) _ node (){ stage ( 'Prepare' ) { deleteDir () checkout scm setupCommonPipelineEnvironment script: this } stage ( 'Build' ) { mtaBuild script: this } stage ( 'Deploy' ) { cloudFoundryDeploy script: this , deployTool: 'mtaDeployPlugin' } }","title":"Jenkinsfile"},{"location":"scenarios/CAP_Scenario/#configuration-pipelineconfigyml","text":"steps : mtaBuild : buildTarget : 'CF' cloudFoundryDeploy : cloudFoundry : credentialsId : 'CF' apiEndpoint : '<CF Endpoint>' org : '<CF Organization>' space : '<CF Space>'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/CAP_Scenario/#parameters","text":"For the detailed description of the relevant parameters, see: mtaBuild cloudFoundryDeploy","title":"Parameters"},{"location":"scenarios/changeManagement/","text":"Build and Deploy Hybrid Applications with Jenkins and SAP Solution Manager \u00b6 Set up an agile development process with Jenkins CI, which automatically feeds changes into SAP Solution Manager. Prerequisites \u00b6 You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed SAP Solution Manager 7.2 SP6. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . Context \u00b6 In many SAP development scenarios, it is vital to synchronize both backend and frontend deliveries. These deliveries are typically an SAP UI5 application and an ABAP backend from which it is served. The SAP UI5 parts are often developed using agile practices and use Continuous Integration pipelines that automatically build, test, and deploy the application. Note This scenario description is an example. You can apply the process to other scenarios and component sets, as well. In this scenario, we want to show how an agile development process with Jenkins CI can automatically feed changes into SAP Solution Manager. In SAP Solution Manager, all parts of the application stack come together and can be subject to classic change and transport management. The basic workflow is as follows: The pipeline scans the Git commit messages for a line like ChangeDocument : <changeDocumentId> , and validates that the change is in the correct status in development . For more information, see checkChangeInDevelopment . An example for the commit message looks as follows: Fix terminology in documentation Terminology must be consistent with official channels. ChangeDocument: <Your Change Document ID> Note: The blank line between message header and message description is mandatory. To communicate with SAP Solution Manager, the pipeline uses credentials that must be stored on Jenkins using the credential ID CM . For more information, see checkChangeInDevelopment . The required transport request is created on the fly. Note: The change document can contain various components (for example, UI and backend components). The changes of your development team trigger the Jenkins pipeline. It builds and validates the changes and attaches them to the respective transport request. As soon as the development process is completed, the change document in SAP Solution Manager can be set to status to be tested and all components can be transported to the test system. Hybrid Application Development Workflow \u00b6 Example \u00b6 Jenkinsfile \u00b6 @Library ( 'piper-library-os' ) _ node () { stage ( 'prepare' ) { checkout scm setupCommonPipelineEnvironment script: this checkChangeInDevelopment script: this } stage ( 'buildMta' ) { mtaBuild script: this } stage ( 'uploadToTransportRequest' ) { transportRequestCreate script: this transportRequestUploadFile script: this transportRequestRelease script: this } } Configuration ( .pipeline/config.yml ) \u00b6 #Steps Specific Configuration general : changeManagement : endpoint : 'https://<backend-system>/sap/opu/odata/sap/AI_CRM_GW_CM_CI_SRV' credentialsId : 'CM' type : 'SOLMAN' steps : mtaBuild : buildTarget : 'NEO' transportRequestCreate : developmentSystemId : '<value for developmentSystemId>' transportRequestUploadFile : applicationId : 'HCP' Parameters \u00b6 For the detailed description of the relevant parameters, see: checkChangeInDevelopment mtaBuild transportRequestCreate transportRequestUploadFile transportRequestRelease","title":"Build and Deploy Hybrid Applications with Jenkins and SAP Solution Manager"},{"location":"scenarios/changeManagement/#build-and-deploy-hybrid-applications-with-jenkins-and-sap-solution-manager","text":"Set up an agile development process with Jenkins CI, which automatically feeds changes into SAP Solution Manager.","title":"Build and Deploy Hybrid Applications with Jenkins and SAP Solution Manager"},{"location":"scenarios/changeManagement/#prerequisites","text":"You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed SAP Solution Manager 7.2 SP6. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js .","title":"Prerequisites"},{"location":"scenarios/changeManagement/#context","text":"In many SAP development scenarios, it is vital to synchronize both backend and frontend deliveries. These deliveries are typically an SAP UI5 application and an ABAP backend from which it is served. The SAP UI5 parts are often developed using agile practices and use Continuous Integration pipelines that automatically build, test, and deploy the application. Note This scenario description is an example. You can apply the process to other scenarios and component sets, as well. In this scenario, we want to show how an agile development process with Jenkins CI can automatically feed changes into SAP Solution Manager. In SAP Solution Manager, all parts of the application stack come together and can be subject to classic change and transport management. The basic workflow is as follows: The pipeline scans the Git commit messages for a line like ChangeDocument : <changeDocumentId> , and validates that the change is in the correct status in development . For more information, see checkChangeInDevelopment . An example for the commit message looks as follows: Fix terminology in documentation Terminology must be consistent with official channels. ChangeDocument: <Your Change Document ID> Note: The blank line between message header and message description is mandatory. To communicate with SAP Solution Manager, the pipeline uses credentials that must be stored on Jenkins using the credential ID CM . For more information, see checkChangeInDevelopment . The required transport request is created on the fly. Note: The change document can contain various components (for example, UI and backend components). The changes of your development team trigger the Jenkins pipeline. It builds and validates the changes and attaches them to the respective transport request. As soon as the development process is completed, the change document in SAP Solution Manager can be set to status to be tested and all components can be transported to the test system.","title":"Context"},{"location":"scenarios/changeManagement/#hybrid-application-development-workflow","text":"","title":"Hybrid Application Development Workflow"},{"location":"scenarios/changeManagement/#example","text":"","title":"Example"},{"location":"scenarios/changeManagement/#jenkinsfile","text":"@Library ( 'piper-library-os' ) _ node () { stage ( 'prepare' ) { checkout scm setupCommonPipelineEnvironment script: this checkChangeInDevelopment script: this } stage ( 'buildMta' ) { mtaBuild script: this } stage ( 'uploadToTransportRequest' ) { transportRequestCreate script: this transportRequestUploadFile script: this transportRequestRelease script: this } }","title":"Jenkinsfile"},{"location":"scenarios/changeManagement/#configuration-pipelineconfigyml","text":"#Steps Specific Configuration general : changeManagement : endpoint : 'https://<backend-system>/sap/opu/odata/sap/AI_CRM_GW_CM_CI_SRV' credentialsId : 'CM' type : 'SOLMAN' steps : mtaBuild : buildTarget : 'NEO' transportRequestCreate : developmentSystemId : '<value for developmentSystemId>' transportRequestUploadFile : applicationId : 'HCP'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/changeManagement/#parameters","text":"For the detailed description of the relevant parameters, see: checkChangeInDevelopment mtaBuild transportRequestCreate transportRequestUploadFile transportRequestRelease","title":"Parameters"},{"location":"scenarios/ui5-sap-cp/Readme/","text":"Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins \u00b6 Build an application based on SAPUI5 or SAP Fiori with Jenkins and deploy the build result into an SAP Cloud Platform account in the Neo environment. Prerequisites \u00b6 You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . You have installed the SAP Cloud Platform Neo Environment SDK. See SAP Development Tools . Project Prerequisites \u00b6 This scenario requires additional files in your project and in the execution environment on your Jenkins instance. On the project level, provide and adjust the following template: File Name Description Position .npmrc This file contains a reference to the SAP NPM registry ( @sap:registry https://npm.sap.com ), which is required to fetch the dependencies required to build the application. Place the .npmrc file in the root directory of your project. mta.yaml This file controls the behavior of the MTA toolset. Place the mta.yaml file in your application root folder and adjust the values in brackets with your data. package.json This file lists the required development dependencies for the build. Add the content of the package.json file to your existing package.json file. Gruntfile.js This file controls the grunt build. By default the tasks clean , build , and lint are executed. Place the Gruntfile.js in the root directory of your project. Context \u00b6 This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build an application based on SAPUI5 or SAP Fiori by using the multi-target application (MTA) concept and how to deploy the build result into an SAP Cloud Platform account in the Neo environment. This document comprises the mtaBuild and the neoDeploy steps. Screenshot: Build and Deploy Process in Jenkins \u00b6 Example \u00b6 Jenkinsfile \u00b6 Following the convention for pipeline definitions, use a Jenkinsfile which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ fioriOnCloudPlatformPipeline script: this Configuration ( .pipeline/config.yml ) \u00b6 This is a basic configuration example, which is also located in the sources of the project. steps : mtaBuild : buildTarget : 'NEO' mtaJarLocation : '/opt/sap/mta.jar' neoDeploy : neoHome : '/opt/sap/neo-sdk/' neo : credentialsId : 'NEO_DEPLOY' account : 'your-account-id' host : 'hana.ondemand.com' Configuration for the MTA Build \u00b6 Parameter Description buildTarget The target platform to which the mtar can be deployed. Possible values are: CF , NEO , XSA mtaJarLocation The location of the multi-target application archive builder jar file, including file name and extension. Configuration for the Deployment to SAP Cloud Platform \u00b6 Parameter Description account The SAP Cloud Platform account to deploy to. credentialsId The Jenkins credentials that contain the user and password which are used for the deployment on SAP Cloud Platform. host The SAP Cloud Platform host to deploy to. neoHome The path to the neo-java-web-sdk tool that is used for the deployment. Parameters \u00b6 For the detailed description of the relevant parameters, see: mtaBuild neoDeploy","title":"Build and Deploy SAP UI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins"},{"location":"scenarios/ui5-sap-cp/Readme/#build-and-deploy-sapui5-or-sap-fiori-applications-on-sap-cloud-platform-with-jenkins","text":"Build an application based on SAPUI5 or SAP Fiori with Jenkins and deploy the build result into an SAP Cloud Platform account in the Neo environment.","title":"Build and Deploy SAPUI5 or SAP Fiori Applications on SAP Cloud Platform with Jenkins"},{"location":"scenarios/ui5-sap-cp/Readme/#prerequisites","text":"You have installed the Java Runtime Environment 8. You have installed Jenkins 2.60.3 or higher. You have set up Project \u201cPiper\u201d. See README . You have installed the Multi-Target Application (MTA) Archive Builder 1.0.6 or newer. See SAP Development Tools . You have installed Node.js including node and npm. See Node.js . You have installed the SAP Cloud Platform Neo Environment SDK. See SAP Development Tools .","title":"Prerequisites"},{"location":"scenarios/ui5-sap-cp/Readme/#project-prerequisites","text":"This scenario requires additional files in your project and in the execution environment on your Jenkins instance. On the project level, provide and adjust the following template: File Name Description Position .npmrc This file contains a reference to the SAP NPM registry ( @sap:registry https://npm.sap.com ), which is required to fetch the dependencies required to build the application. Place the .npmrc file in the root directory of your project. mta.yaml This file controls the behavior of the MTA toolset. Place the mta.yaml file in your application root folder and adjust the values in brackets with your data. package.json This file lists the required development dependencies for the build. Add the content of the package.json file to your existing package.json file. Gruntfile.js This file controls the grunt build. By default the tasks clean , build , and lint are executed. Place the Gruntfile.js in the root directory of your project.","title":"Project Prerequisites"},{"location":"scenarios/ui5-sap-cp/Readme/#context","text":"This scenario combines various different steps to create a complete pipeline. In this scenario, we want to show how to build an application based on SAPUI5 or SAP Fiori by using the multi-target application (MTA) concept and how to deploy the build result into an SAP Cloud Platform account in the Neo environment. This document comprises the mtaBuild and the neoDeploy steps.","title":"Context"},{"location":"scenarios/ui5-sap-cp/Readme/#screenshot-build-and-deploy-process-in-jenkins","text":"","title":"Screenshot: Build and Deploy Process in Jenkins"},{"location":"scenarios/ui5-sap-cp/Readme/#example","text":"","title":"Example"},{"location":"scenarios/ui5-sap-cp/Readme/#jenkinsfile","text":"Following the convention for pipeline definitions, use a Jenkinsfile which resides in the root directory of your development sources. @Library ( 'piper-lib-os' ) _ fioriOnCloudPlatformPipeline script: this","title":"Jenkinsfile"},{"location":"scenarios/ui5-sap-cp/Readme/#configuration-pipelineconfigyml","text":"This is a basic configuration example, which is also located in the sources of the project. steps : mtaBuild : buildTarget : 'NEO' mtaJarLocation : '/opt/sap/mta.jar' neoDeploy : neoHome : '/opt/sap/neo-sdk/' neo : credentialsId : 'NEO_DEPLOY' account : 'your-account-id' host : 'hana.ondemand.com'","title":"Configuration (.pipeline/config.yml)"},{"location":"scenarios/ui5-sap-cp/Readme/#configuration-for-the-mta-build","text":"Parameter Description buildTarget The target platform to which the mtar can be deployed. Possible values are: CF , NEO , XSA mtaJarLocation The location of the multi-target application archive builder jar file, including file name and extension.","title":"Configuration for the MTA Build"},{"location":"scenarios/ui5-sap-cp/Readme/#configuration-for-the-deployment-to-sap-cloud-platform","text":"Parameter Description account The SAP Cloud Platform account to deploy to. credentialsId The Jenkins credentials that contain the user and password which are used for the deployment on SAP Cloud Platform. host The SAP Cloud Platform host to deploy to. neoHome The path to the neo-java-web-sdk tool that is used for the deployment.","title":"Configuration for the Deployment to SAP Cloud Platform"},{"location":"scenarios/ui5-sap-cp/Readme/#parameters","text":"For the detailed description of the relevant parameters, see: mtaBuild neoDeploy","title":"Parameters"},{"location":"stages/confirm/","text":"Confirm \u00b6 In this stage a manual confirmation is requested before processing subsequent stages like Promote and Release . This stage will be active in two scenarios: - manual activation of this stage - in case of an 'UNSTABLE' build (even when manual confirmation is inactive) Stage Content \u00b6 This stage comprises following steps which are activated depending on your use-case/configuration: step step description Stage Activation \u00b6 This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation . Step Activation \u00b6 For this stage no conditions are assigned to steps. Additional Stage Parameters \u00b6 name mandatory default possible values manualConfirmation no true true , false manualConfirmationMessage no Shall we proceed to Promote & Release? manualConfirmationTimeout no 720 script yes manualConfirmation - Specifies if a manual confirmation is active before running the Promote and Release stages of the pipeline. manualConfirmationMessage - Defines message displayed as default manual confirmation. Please note: only used in case pipeline is in state SUCCESSFUL manualConfirmationTimeout - Defines how many hours a manual confirmation is possible for a dedicated pipeline. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Configuration of Additional Stage Parameters \u00b6 The stage parameters need to be defined in the section stages of config.yml file .","title":"Confirm"},{"location":"stages/confirm/#confirm","text":"In this stage a manual confirmation is requested before processing subsequent stages like Promote and Release . This stage will be active in two scenarios: - manual activation of this stage - in case of an 'UNSTABLE' build (even when manual confirmation is inactive)","title":"Confirm"},{"location":"stages/confirm/#stage-content","text":"This stage comprises following steps which are activated depending on your use-case/configuration: step step description","title":"Stage Content"},{"location":"stages/confirm/#stage-activation","text":"This stage will be active if any one of the following conditions is met: Stage configuration in config.yml file contains entries for this stage. Any of the conditions are met which are explained in the section Step Activation .","title":"Stage Activation"},{"location":"stages/confirm/#step-activation","text":"For this stage no conditions are assigned to steps.","title":"Step Activation"},{"location":"stages/confirm/#additional-stage-parameters","text":"name mandatory default possible values manualConfirmation no true true , false manualConfirmationMessage no Shall we proceed to Promote & Release? manualConfirmationTimeout no 720 script yes manualConfirmation - Specifies if a manual confirmation is active before running the Promote and Release stages of the pipeline. manualConfirmationMessage - Defines message displayed as default manual confirmation. Please note: only used in case pipeline is in state SUCCESSFUL manualConfirmationTimeout - Defines how many hours a manual confirmation is possible for a dedicated pipeline. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Additional Stage Parameters"},{"location":"stages/confirm/#configuration-of-additional-stage-parameters","text":"The stage parameters need to be defined in the section stages of config.yml file .","title":"Configuration of Additional Stage Parameters"},{"location":"steps/artifactSetVersion/","text":"artifactSetVersion \u00b6 Description \u00b6 The continuous delivery process requires that each build is done with a unique version number. The version generated using this step will contain: Version (major.minor.patch) from descriptor file in master repository is preserved. Developers should be able to autonomously decide on increasing either part of this version number. Timestamp CommitId (by default the long version of the hash) Optionally, but enabled by default, the new version is pushed as a new tag into the source code repository (e.g. GitHub). If this option is chosen, git credentials and the repository URL needs to be provided. Since you might not want to configure the git credentials in Jenkins, committing and pushing can be disabled using the commitVersion parameter as described below. If you require strict reproducibility of your builds, this should be used. Prerequsites \u00b6 none Parameters \u00b6 name mandatory default possible values artifactType no appContainer buildTool yes dlang , docker , golang , maven , mta , npm , pip , sbt commitVersion no true true , false dockerVersionSource no FROM, (ENV name),appVersion filePath no buildTool= dlang : dub.json buildTool= docker : Dockerfile buildTool= golang : VERSION buildTool= maven : pom.xml buildTool= mta : mta.yaml buildTool= npm : package.json buildTool= pip : version.txt buildTool= sbt : sbtDescriptor.json gitCommitId no gitSshKeyCredentialsId no `` gitSshUrl yes gitUserEMail no gitUserName no script yes tagPrefix no build_ timestamp no timestampTemplate no %Y%m%d%H%M%S versioningTemplate no buildTool= dlang : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= docker : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= golang : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= maven : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= mta : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= npm : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= pip : ${version}.${timestamp}${commitId?\".\"+commitId:\"\"} buildTool= sbt : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} artifactType - Defines the type of the artifact. buildTool - Defines the tool which is used for building the artifact. commitVersion - Controls if the changed version is committed and pushed to the git repository. If this is enabled (which is the default), you need to provide gitCredentialsId and gitSshUrl . dockerVersionSource - Specifies the source to be used for the main version which is used for generating the automatic version. * This can either be the version of the base image - as retrieved from the FROM statement within the Dockerfile, e.g. FROM jenkins:2.46.2 * Alternatively the name of an environment variable defined in the Docker image can be used which contains the version number, e.g. ENV MY_VERSION 1.2.3 * The third option appVersion applies only to the artifactType appContainer . Here the version of the app which is packaged into the container will be used as version for the container itself. filePath - Defines a custom path to the descriptor file. gitCommitId - Defines the version prefix of the automatically generated version. By default it will take the long commitId hash. You could pass any other string (e.g. the short commitId hash) to be used. In case you don't want to have the gitCommitId added to the automatic versioning string you could set the value to an empty string: '' . gitSshKeyCredentialsId - Defines the ssh git credentials to be used for writing the tag. gitSshUrl - Defines the git ssh url to the source code repository. gitUserEMail - Allows to overwrite the global git setting 'user.email' available on your Jenkins server. gitUserName - Allows to overwrite the global git setting 'user.name' available on your Jenkins server. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tagPrefix - Defines the prefix which is used for the git tag which is written during the versioning run. timestamp - Defines the timestamp to be used in the automatic version string. You could overwrite the default behavior by explicitly setting this string. timestampTemplate - Defines the template for the timestamp which will be part of the created version. versioningTemplate - Defines the template for the automatic version which will be created. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactType X buildTool X commitVersion X dockerVersionSource X filePath X gitCommitId gitSshKeyCredentialsId X gitSshUrl X gitUserEMail X gitUserName X script tagPrefix X timestamp X timestampTemplate X versioningTemplate X Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 artifactSetVersion script: this , buildTool: 'maven'","title":"artifactSetVersion"},{"location":"steps/artifactSetVersion/#artifactsetversion","text":"","title":"artifactSetVersion"},{"location":"steps/artifactSetVersion/#description","text":"The continuous delivery process requires that each build is done with a unique version number. The version generated using this step will contain: Version (major.minor.patch) from descriptor file in master repository is preserved. Developers should be able to autonomously decide on increasing either part of this version number. Timestamp CommitId (by default the long version of the hash) Optionally, but enabled by default, the new version is pushed as a new tag into the source code repository (e.g. GitHub). If this option is chosen, git credentials and the repository URL needs to be provided. Since you might not want to configure the git credentials in Jenkins, committing and pushing can be disabled using the commitVersion parameter as described below. If you require strict reproducibility of your builds, this should be used.","title":"Description"},{"location":"steps/artifactSetVersion/#prerequsites","text":"none","title":"Prerequsites"},{"location":"steps/artifactSetVersion/#parameters","text":"name mandatory default possible values artifactType no appContainer buildTool yes dlang , docker , golang , maven , mta , npm , pip , sbt commitVersion no true true , false dockerVersionSource no FROM, (ENV name),appVersion filePath no buildTool= dlang : dub.json buildTool= docker : Dockerfile buildTool= golang : VERSION buildTool= maven : pom.xml buildTool= mta : mta.yaml buildTool= npm : package.json buildTool= pip : version.txt buildTool= sbt : sbtDescriptor.json gitCommitId no gitSshKeyCredentialsId no `` gitSshUrl yes gitUserEMail no gitUserName no script yes tagPrefix no build_ timestamp no timestampTemplate no %Y%m%d%H%M%S versioningTemplate no buildTool= dlang : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= docker : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= golang : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= maven : ${version}-${timestamp}${commitId?\"_\"+commitId:\"\"} buildTool= mta : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= npm : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} buildTool= pip : ${version}.${timestamp}${commitId?\".\"+commitId:\"\"} buildTool= sbt : ${version}-${timestamp}${commitId?\"+\"+commitId:\"\"} artifactType - Defines the type of the artifact. buildTool - Defines the tool which is used for building the artifact. commitVersion - Controls if the changed version is committed and pushed to the git repository. If this is enabled (which is the default), you need to provide gitCredentialsId and gitSshUrl . dockerVersionSource - Specifies the source to be used for the main version which is used for generating the automatic version. * This can either be the version of the base image - as retrieved from the FROM statement within the Dockerfile, e.g. FROM jenkins:2.46.2 * Alternatively the name of an environment variable defined in the Docker image can be used which contains the version number, e.g. ENV MY_VERSION 1.2.3 * The third option appVersion applies only to the artifactType appContainer . Here the version of the app which is packaged into the container will be used as version for the container itself. filePath - Defines a custom path to the descriptor file. gitCommitId - Defines the version prefix of the automatically generated version. By default it will take the long commitId hash. You could pass any other string (e.g. the short commitId hash) to be used. In case you don't want to have the gitCommitId added to the automatic versioning string you could set the value to an empty string: '' . gitSshKeyCredentialsId - Defines the ssh git credentials to be used for writing the tag. gitSshUrl - Defines the git ssh url to the source code repository. gitUserEMail - Allows to overwrite the global git setting 'user.email' available on your Jenkins server. gitUserName - Allows to overwrite the global git setting 'user.name' available on your Jenkins server. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tagPrefix - Defines the prefix which is used for the git tag which is written during the versioning run. timestamp - Defines the timestamp to be used in the automatic version string. You could overwrite the default behavior by explicitly setting this string. timestampTemplate - Defines the template for the timestamp which will be part of the created version. versioningTemplate - Defines the template for the automatic version which will be created.","title":"Parameters"},{"location":"steps/artifactSetVersion/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactType X buildTool X commitVersion X dockerVersionSource X filePath X gitCommitId gitSshKeyCredentialsId X gitSshUrl X gitUserEMail X gitUserName X script tagPrefix X timestamp X timestampTemplate X versioningTemplate X","title":"Step configuration"},{"location":"steps/artifactSetVersion/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/artifactSetVersion/#example","text":"artifactSetVersion script: this , buildTool: 'maven'","title":"Example"},{"location":"steps/batsExecuteTests/","text":"batsExecuteTests \u00b6 Description \u00b6 This step executes tests using the Bash Automated Testing System - bats-core Prerequsites \u00b6 You need to have a Bats test file. By default you would put this into directory src/test within your source code repository. Parameters \u00b6 name mandatory default possible values dockerImage no node:8-stretch dockerWorkspace no /home/node envVars no [:] failOnError no false gitBranch no gitSshKeyCredentialsId no `` outputFormat no junit tap repository no https://github.com/bats-core/bats-core.git script yes stashContent no [tests] testPackage no piper-bats testPath no src/test testRepository no dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . envVars - Defines the environment variables to pass to the test execution. failOnError - Defines the behavior, in case tests fail. For example, in case of outputFormat: 'junit' you should set it to false . Otherwise test results cannot be recorded using the testsPublishhResults step afterwards. gitBranch - Defines the branch where the tests are located, in case the tests are not located in the master branch. gitSshKeyCredentialsId - Defines the access credentials for protected repositories. Note: In case of using a protected repository, testRepository should include the ssh link to the repository. outputFormat - Defines the format of the test result output. junit would be the standard for automated build environments but you could use also the option tap . repository - Defines the version of bats-core to be used. By default we use the version from the master branch. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testPackage - For the transformation of the test result to xUnit format the node module tap-xunit is used. This parameter defines the name of the test package used in the xUnit result file. testPath - Defines either the directory which contains the test files ( *.bats ) or a single file. You can find further details in the Bats-core documentation . testRepository - Allows to load tests from another repository. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerImage X dockerWorkspace X envVars X failOnError X gitBranch X gitSshKeyCredentialsId X outputFormat X repository X script stashContent X testPackage X testPath X testRepository X Dependencies \u00b6 The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 batsExecuteTests script: this testsPublishResults junit: [ pattern: '**/Test-*.xml' , archive: true ] With `envVars` it is possible to pass either fixed values but also templates using [`commonPipelineEnvironment`](commonPipelineEnvironment.md). Example: ```yaml batsExecuteTests script: this, envVars = [ FIX_VALUE: 'my fixed value', CONTAINER_NAME: '${commonPipelineEnvironment.configuration.steps.executeBatsTests.dockerContainerName}', IMAGE_NAME: '${return commonPipelineEnvironment.getDockerImageNameAndTag()}' ] ``` This means within the test one could refer to environment variables by calling e.g. `run docker run --rm -i --name \\$CONTAINER_NAME --entrypoint /bin/bash \\$IMAGE_NAME echo \"Test\"`","title":"batsExecuteTests"},{"location":"steps/batsExecuteTests/#batsexecutetests","text":"","title":"batsExecuteTests"},{"location":"steps/batsExecuteTests/#description","text":"This step executes tests using the Bash Automated Testing System - bats-core","title":"Description"},{"location":"steps/batsExecuteTests/#prerequsites","text":"You need to have a Bats test file. By default you would put this into directory src/test within your source code repository.","title":"Prerequsites"},{"location":"steps/batsExecuteTests/#parameters","text":"name mandatory default possible values dockerImage no node:8-stretch dockerWorkspace no /home/node envVars no [:] failOnError no false gitBranch no gitSshKeyCredentialsId no `` outputFormat no junit tap repository no https://github.com/bats-core/bats-core.git script yes stashContent no [tests] testPackage no piper-bats testPath no src/test testRepository no dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . envVars - Defines the environment variables to pass to the test execution. failOnError - Defines the behavior, in case tests fail. For example, in case of outputFormat: 'junit' you should set it to false . Otherwise test results cannot be recorded using the testsPublishhResults step afterwards. gitBranch - Defines the branch where the tests are located, in case the tests are not located in the master branch. gitSshKeyCredentialsId - Defines the access credentials for protected repositories. Note: In case of using a protected repository, testRepository should include the ssh link to the repository. outputFormat - Defines the format of the test result output. junit would be the standard for automated build environments but you could use also the option tap . repository - Defines the version of bats-core to be used. By default we use the version from the master branch. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testPackage - For the transformation of the test result to xUnit format the node module tap-xunit is used. This parameter defines the name of the test package used in the xUnit result file. testPath - Defines either the directory which contains the test files ( *.bats ) or a single file. You can find further details in the Bats-core documentation . testRepository - Allows to load tests from another repository.","title":"Parameters"},{"location":"steps/batsExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerImage X dockerWorkspace X envVars X failOnError X gitBranch X gitSshKeyCredentialsId X outputFormat X repository X script stashContent X testPackage X testPath X testRepository X","title":"Step configuration"},{"location":"steps/batsExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/batsExecuteTests/#example","text":"batsExecuteTests script: this testsPublishResults junit: [ pattern: '**/Test-*.xml' , archive: true ] With `envVars` it is possible to pass either fixed values but also templates using [`commonPipelineEnvironment`](commonPipelineEnvironment.md). Example: ```yaml batsExecuteTests script: this, envVars = [ FIX_VALUE: 'my fixed value', CONTAINER_NAME: '${commonPipelineEnvironment.configuration.steps.executeBatsTests.dockerContainerName}', IMAGE_NAME: '${return commonPipelineEnvironment.getDockerImageNameAndTag()}' ] ``` This means within the test one could refer to environment variables by calling e.g. `run docker run --rm -i --name \\$CONTAINER_NAME --entrypoint /bin/bash \\$IMAGE_NAME echo \"Test\"`","title":"Example"},{"location":"steps/checkChangeInDevelopment/","text":"checkChangeInDevelopment \u00b6 Description \u00b6 Checks if a Change Document in SAP Solution Manager is in status 'in development'. The change document id is retrieved from the git commit history. The change document id can also be provided via parameter changeDocumentId . Any value provided as parameter has a higher precedence than a value from the commit history. By default the git commit messages between origin/master and HEAD are scanned for a line like ChangeDocument : <changeDocumentId> . The commit range and the pattern can be configured. For details see 'parameters' table. Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Parameters \u00b6 name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD failIfStatusIsNotInDevelopment no true true , false script yes changeDocumentId - The id of the change document to transport. If not provided, it is retrieved from the git commit history. changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. failIfStatusIsNotInDevelopment - When set to false the step will not fail in case the step is not in status 'in development'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X failIfStatusIsNotInDevelopment X script Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 AbortException : If the change id is not provided via parameter and if the change document id cannot be retrieved from the commit history. If the change is not in status in development . In this case no exception will be thrown when failIfStatusIsNotInDevelopment is set to false . IllegalArgumentException : If a mandatory property is not provided. Examples \u00b6 The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : checkChangeInDevelopment : changeManagement : endpoint : 'https://example.org/cm' [ ... ] failIfStatusIsNotInDevelopment : true The parameters can also be provided when the step is invoked: // simple case. All mandatory parameters provided via // configuration, changeDocumentId provided via commit // history checkChangeInDevelopment script: this // explict endpoint provided, we search for changeDocumentId // starting at the previous commit (HEAD~1) rather than on // 'origin/master' (the default). checkChangeInDevelopment ( script: this changeManagement: [ endpoint: 'https:example.org/cm' git: [ from: 'HEAD~1' ] ] )","title":"checkChangeInDevelopment"},{"location":"steps/checkChangeInDevelopment/#checkchangeindevelopment","text":"","title":"checkChangeInDevelopment"},{"location":"steps/checkChangeInDevelopment/#description","text":"Checks if a Change Document in SAP Solution Manager is in status 'in development'. The change document id is retrieved from the git commit history. The change document id can also be provided via parameter changeDocumentId . Any value provided as parameter has a higher precedence than a value from the commit history. By default the git commit messages between origin/master and HEAD are scanned for a line like ChangeDocument : <changeDocumentId> . The commit range and the pattern can be configured. For details see 'parameters' table.","title":"Description"},{"location":"steps/checkChangeInDevelopment/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central.","title":"Prerequisites"},{"location":"steps/checkChangeInDevelopment/#parameters","text":"name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD failIfStatusIsNotInDevelopment no true true , false script yes changeDocumentId - The id of the change document to transport. If not provided, it is retrieved from the git commit history. changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. failIfStatusIsNotInDevelopment - When set to false the step will not fail in case the step is not in status 'in development'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/checkChangeInDevelopment/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X failIfStatusIsNotInDevelopment X script","title":"Step configuration"},{"location":"steps/checkChangeInDevelopment/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/checkChangeInDevelopment/#exceptions","text":"AbortException : If the change id is not provided via parameter and if the change document id cannot be retrieved from the commit history. If the change is not in status in development . In this case no exception will be thrown when failIfStatusIsNotInDevelopment is set to false . IllegalArgumentException : If a mandatory property is not provided.","title":"Exceptions"},{"location":"steps/checkChangeInDevelopment/#examples","text":"The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : checkChangeInDevelopment : changeManagement : endpoint : 'https://example.org/cm' [ ... ] failIfStatusIsNotInDevelopment : true The parameters can also be provided when the step is invoked: // simple case. All mandatory parameters provided via // configuration, changeDocumentId provided via commit // history checkChangeInDevelopment script: this // explict endpoint provided, we search for changeDocumentId // starting at the previous commit (HEAD~1) rather than on // 'origin/master' (the default). checkChangeInDevelopment ( script: this changeManagement: [ endpoint: 'https:example.org/cm' git: [ from: 'HEAD~1' ] ] )","title":"Examples"},{"location":"steps/checksPublishResults/","text":"checksPublishResults \u00b6 Description \u00b6 This step can publish static check results from various sources. Prerequisites \u00b6 static check result files - To use this step, there must be static check result files available. installed plugins: pmd dry findbugs checkstyle warnings core Parameters \u00b6 name mandatory default possible values aggregation no [active:true, thresholds:[fail:[high:0]]] true , false , Map archive no false checkstyle no [pattern:**/target/checkstyle-result.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map cpd no [pattern:**/target/cpd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map eslint no [pattern:**/eslint.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map findbugs no [pattern:**/target/findbugsXml.xml, **/target/findbugs.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pmd no [pattern:**/target/pmd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pylint no [pattern:**/pylint.log, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map script yes tasks no [pattern:**/*.java, low:, normal:TODO,REVISE,XXX, high:FIXME, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map aggregation - Allows to publish the check results. archive - checkstyle - Publishes Checkstyle findings with the Checkstyle plugin . cpd - Publishes CPD findings with the DRY plugin . eslint - Publishes ESLint findings (in JSLint format ) with the Warnings plugin . findbugs - Publishes Findbugs findings with the Findbugs plugin . pmd - Publishes PMD findings with the PMD plugin . pylint - Publishes PyLint findings with the Warnings plugin , pylint needs to run with --output-format=parseable option. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tasks - Searches and publishes TODOs in files with the Task Scanner Plugin . aggregation \u00b6 parameter mandatory default possible values thresholds no none see thresholds tasks \u00b6 parameter mandatory default possible values pattern no '**/*.java' archive no true true , false high no 'FIXME' normal no 'TODO,REVISE,XXX' low no thresholds no none see thresholds pmd \u00b6 parameter mandatory default possible values pattern no '**/target/pmd.xml' archive no true true , false thresholds no none see thresholds cpd \u00b6 parameter mandatory default possible values pattern no '**/target/cpd.xml' archive no true true , false thresholds no none see thresholds findbugs \u00b6 parameter mandatory default possible values pattern no '**/target/findbugsXml.xml, **/target/findbugs.xml' archive no true true, false thresholds no none see thresholds checkstyle \u00b6 parameter mandatory default possible values pattern no '**/target/checkstyle-result.xml' archive no true true , false thresholds no none see thresholds eslint \u00b6 parameter mandatory default possible values pattern no '**/eslint.jslint.xml' archive no true true , false thresholds no none see thresholds pylint \u00b6 parameter mandatory default possible values pattern no '**/pylint.log' archive no true true , false thresholds no none see thresholds Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage aggregation X archive X checkstyle X cpd X eslint X findbugs X pmd X pylint X script tasks X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Thresholds \u00b6 It is possible to define thresholds to fail the build on a certain count of findings. To achive this, just define your thresholds a followed for the specific check tool: thresholds: [ fail: [ all: 999 , low: 99 , normal: 9 , high: 0 ]] This way, the jenkins will fail the build on 1 high issue, 10 normal issues, 100 low issues or a total issue count of 1000. The thresholds parameter can be set for aggregation , tasks , pmd , cpd , findbugs , checkstyle , eslint and pylint . checksPublishResults ( tasks: true , pmd: [ pattern: '**/target/pmd-results.xml' , thresholds: [ fail: [ low: 100 ]]], cpd: [ archive: false ], aggregation: [ thresholds: [ fail: [ high: 0 ]]], archive: true ) Side effects \u00b6 If both ESLint and PyLint results are published, they are not correctly aggregated in the aggregator plugin. Exceptions \u00b6 none Example \u00b6 // publish java results from pmd, cpd, checkstyle & findbugs checksPublishResults archive: true , pmd: true , cpd: true , findbugs: true , checkstyle: true , aggregation: [ thresholds: [ fail: [ high: 0 ]]] // publish javascript results from ESLint checksPublishResults archive: true , eslint: [ pattern: '**/result-file-with-fancy-name.xml' ], aggregation: [ thresholds: [ fail: [ high: 0 , normal: 10 ]]] // publish scala results from scalastyle checksPublishResults archive: true , checkstyle: [ pattern: '**/target/scalastyle-result.xml' ] // publish python results from pylint checksPublishResults archive: true , pylint: [ pattern: '**/target/pylint.log' ]","title":"checksPublishResults"},{"location":"steps/checksPublishResults/#checkspublishresults","text":"","title":"checksPublishResults"},{"location":"steps/checksPublishResults/#description","text":"This step can publish static check results from various sources.","title":"Description"},{"location":"steps/checksPublishResults/#prerequisites","text":"static check result files - To use this step, there must be static check result files available. installed plugins: pmd dry findbugs checkstyle warnings core","title":"Prerequisites"},{"location":"steps/checksPublishResults/#parameters","text":"name mandatory default possible values aggregation no [active:true, thresholds:[fail:[high:0]]] true , false , Map archive no false checkstyle no [pattern:**/target/checkstyle-result.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map cpd no [pattern:**/target/cpd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map eslint no [pattern:**/eslint.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map findbugs no [pattern:**/target/findbugsXml.xml, **/target/findbugs.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pmd no [pattern:**/target/pmd.xml, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map pylint no [pattern:**/pylint.log, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map script yes tasks no [pattern:**/*.java, low:, normal:TODO,REVISE,XXX, high:FIXME, archive:true, active:false, thresholds:[fail:[high:0]]] true , false , Map aggregation - Allows to publish the check results. archive - checkstyle - Publishes Checkstyle findings with the Checkstyle plugin . cpd - Publishes CPD findings with the DRY plugin . eslint - Publishes ESLint findings (in JSLint format ) with the Warnings plugin . findbugs - Publishes Findbugs findings with the Findbugs plugin . pmd - Publishes PMD findings with the PMD plugin . pylint - Publishes PyLint findings with the Warnings plugin , pylint needs to run with --output-format=parseable option. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. tasks - Searches and publishes TODOs in files with the Task Scanner Plugin .","title":"Parameters"},{"location":"steps/checksPublishResults/#aggregation","text":"parameter mandatory default possible values thresholds no none see thresholds","title":"aggregation"},{"location":"steps/checksPublishResults/#tasks","text":"parameter mandatory default possible values pattern no '**/*.java' archive no true true , false high no 'FIXME' normal no 'TODO,REVISE,XXX' low no thresholds no none see thresholds","title":"tasks"},{"location":"steps/checksPublishResults/#pmd","text":"parameter mandatory default possible values pattern no '**/target/pmd.xml' archive no true true , false thresholds no none see thresholds","title":"pmd"},{"location":"steps/checksPublishResults/#cpd","text":"parameter mandatory default possible values pattern no '**/target/cpd.xml' archive no true true , false thresholds no none see thresholds","title":"cpd"},{"location":"steps/checksPublishResults/#findbugs","text":"parameter mandatory default possible values pattern no '**/target/findbugsXml.xml, **/target/findbugs.xml' archive no true true, false thresholds no none see thresholds","title":"findbugs"},{"location":"steps/checksPublishResults/#checkstyle","text":"parameter mandatory default possible values pattern no '**/target/checkstyle-result.xml' archive no true true , false thresholds no none see thresholds","title":"checkstyle"},{"location":"steps/checksPublishResults/#eslint","text":"parameter mandatory default possible values pattern no '**/eslint.jslint.xml' archive no true true , false thresholds no none see thresholds","title":"eslint"},{"location":"steps/checksPublishResults/#pylint","text":"parameter mandatory default possible values pattern no '**/pylint.log' archive no true true , false thresholds no none see thresholds","title":"pylint"},{"location":"steps/checksPublishResults/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage aggregation X archive X checkstyle X cpd X eslint X findbugs X pmd X pylint X script tasks X","title":"Step configuration"},{"location":"steps/checksPublishResults/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/checksPublishResults/#thresholds","text":"It is possible to define thresholds to fail the build on a certain count of findings. To achive this, just define your thresholds a followed for the specific check tool: thresholds: [ fail: [ all: 999 , low: 99 , normal: 9 , high: 0 ]] This way, the jenkins will fail the build on 1 high issue, 10 normal issues, 100 low issues or a total issue count of 1000. The thresholds parameter can be set for aggregation , tasks , pmd , cpd , findbugs , checkstyle , eslint and pylint . checksPublishResults ( tasks: true , pmd: [ pattern: '**/target/pmd-results.xml' , thresholds: [ fail: [ low: 100 ]]], cpd: [ archive: false ], aggregation: [ thresholds: [ fail: [ high: 0 ]]], archive: true )","title":"Thresholds"},{"location":"steps/checksPublishResults/#side-effects","text":"If both ESLint and PyLint results are published, they are not correctly aggregated in the aggregator plugin.","title":"Side effects"},{"location":"steps/checksPublishResults/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/checksPublishResults/#example","text":"// publish java results from pmd, cpd, checkstyle & findbugs checksPublishResults archive: true , pmd: true , cpd: true , findbugs: true , checkstyle: true , aggregation: [ thresholds: [ fail: [ high: 0 ]]] // publish javascript results from ESLint checksPublishResults archive: true , eslint: [ pattern: '**/result-file-with-fancy-name.xml' ], aggregation: [ thresholds: [ fail: [ high: 0 , normal: 10 ]]] // publish scala results from scalastyle checksPublishResults archive: true , checkstyle: [ pattern: '**/target/scalastyle-result.xml' ] // publish python results from pylint checksPublishResults archive: true , pylint: [ pattern: '**/target/pylint.log' ]","title":"Example"},{"location":"steps/cloudFoundryDeploy/","text":"cloudFoundryDeploy \u00b6 Description \u00b6 Deploys an application to a test or production space within Cloud Foundry. Deployment can be done in a standard way in a zero downtime manner (using a blue-green deployment approach ) Deployment supports multiple deployment tools Currently the following are supported: Standard cf push and Bluemix blue-green plugin MTA CF CLI Plugin Note Due to an incompatible change in the Cloud Foundry CLI, multiple buildpacks are not supported by this step. If your application contains a list of buildpacks instead a single buildpack , this will be automatically re-written by the step when blue-green deployment is used. Note Cloud Foundry supports the deployment of multiple applications using a single manifest file. This option is supported with Piper. In this case define appName: '' since the app name for the individual applications have to be defined via the manifest. You can find details in the Cloud Foundry Documentation Prerequisites \u00b6 Cloud Foundry organization, space and deployment user are available Credentials for deployment have been configured in Jenkins with a dedicated Id Parameters \u00b6 name mandatory default possible values cloudFoundry/apiEndpoint no https://api.cf.eu10.hana.ondemand.com cloudFoundry/appName no cloudFoundry/credentialsId yes cloudFoundry/manifest no cloudFoundry/org yes cloudFoundry/space yes deployTool no cf_native 'cf_native', 'mtaDeployPlugin' deployType no standard 'standard', 'blue-green' dockerImage no deployTool= cf_native : s4sdk/docker-cf-cli deployTool= mtaDeployPlugin : s4sdk/docker-cf-cli dockerWorkspace no deployTool= cf_native : /home/piper deployTool= mtaDeployPlugin : /home/piper keepOldInstance no false true, false mtaDeployParameters no -f mtaExtensionDescriptor no `` mtaPath no `` script yes smokeTestScript no blueGreenCheckScript.sh smokeTestStatusCode no 200 stashContent no [deployDescriptor, pipelineConfigAndTests] cloudFoundry/apiEndpoint - Cloud Foundry API endpoint. cloudFoundry/appName - Defines the name of the application to be deployed to the Cloud Foundry space. cloudFoundry/credentialsId - Credentials to be used for deployment. cloudFoundry/manifest - Defines the manifest to be used for deployment to Cloud Foundry. cloudFoundry/org - Cloud Foundry target organization. cloudFoundry/space - Cloud Foundry target space. deployTool - Defines the tool which should be used for deployment. deployType - Defines the type of deployment, either standard deployment which results in a system downtime or a zero-downtime blue-green deployment. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . keepOldInstance - In case of a blue-green deployment the old instance will be deleted by default. If this option is set to true the old instance will remain stopped in the Cloud Foundry space. mtaDeployParameters - Defines additional parameters passed to mta for deployment with the mtaDeployPlugin. mtaExtensionDescriptor - Defines additional extension descriptor file for deployment with the mtaDeployPlugin. mtaPath - Defines the path to *.mtar for deployment with the mtaDeployPlugin. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. smokeTestScript - Allows to specify a script which performs a check during blue-green deployment. The script gets the FQDN as parameter and returns exit code 0 in case check returned smokeTestStatusCode . More details can be found here Currently this option is only considered for deployTool cf_native . smokeTestStatusCode - Expected status code returned by the check. stashContent - Specific stashes that should be considered for the step execution. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cloudFoundry/apiEndpoint X cloudFoundry/appName X cloudFoundry/credentialsId X cloudFoundry/manifest X cloudFoundry/org X cloudFoundry/space X deployTool X deployType X dockerImage X dockerWorkspace X keepOldInstance X mtaDeployParameters X mtaExtensionDescriptor X mtaPath X script smokeTestScript X smokeTestStatusCode X stashContent X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 cloudFoundryDeploy ( script: script , deployType: 'blue-green' , cloudFoundry: [ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ], deployTool: 'cf_native' )","title":"cloudFoundryDeploy"},{"location":"steps/cloudFoundryDeploy/#cloudfoundrydeploy","text":"","title":"cloudFoundryDeploy"},{"location":"steps/cloudFoundryDeploy/#description","text":"Deploys an application to a test or production space within Cloud Foundry. Deployment can be done in a standard way in a zero downtime manner (using a blue-green deployment approach ) Deployment supports multiple deployment tools Currently the following are supported: Standard cf push and Bluemix blue-green plugin MTA CF CLI Plugin Note Due to an incompatible change in the Cloud Foundry CLI, multiple buildpacks are not supported by this step. If your application contains a list of buildpacks instead a single buildpack , this will be automatically re-written by the step when blue-green deployment is used. Note Cloud Foundry supports the deployment of multiple applications using a single manifest file. This option is supported with Piper. In this case define appName: '' since the app name for the individual applications have to be defined via the manifest. You can find details in the Cloud Foundry Documentation","title":"Description"},{"location":"steps/cloudFoundryDeploy/#prerequisites","text":"Cloud Foundry organization, space and deployment user are available Credentials for deployment have been configured in Jenkins with a dedicated Id","title":"Prerequisites"},{"location":"steps/cloudFoundryDeploy/#parameters","text":"name mandatory default possible values cloudFoundry/apiEndpoint no https://api.cf.eu10.hana.ondemand.com cloudFoundry/appName no cloudFoundry/credentialsId yes cloudFoundry/manifest no cloudFoundry/org yes cloudFoundry/space yes deployTool no cf_native 'cf_native', 'mtaDeployPlugin' deployType no standard 'standard', 'blue-green' dockerImage no deployTool= cf_native : s4sdk/docker-cf-cli deployTool= mtaDeployPlugin : s4sdk/docker-cf-cli dockerWorkspace no deployTool= cf_native : /home/piper deployTool= mtaDeployPlugin : /home/piper keepOldInstance no false true, false mtaDeployParameters no -f mtaExtensionDescriptor no `` mtaPath no `` script yes smokeTestScript no blueGreenCheckScript.sh smokeTestStatusCode no 200 stashContent no [deployDescriptor, pipelineConfigAndTests] cloudFoundry/apiEndpoint - Cloud Foundry API endpoint. cloudFoundry/appName - Defines the name of the application to be deployed to the Cloud Foundry space. cloudFoundry/credentialsId - Credentials to be used for deployment. cloudFoundry/manifest - Defines the manifest to be used for deployment to Cloud Foundry. cloudFoundry/org - Cloud Foundry target organization. cloudFoundry/space - Cloud Foundry target space. deployTool - Defines the tool which should be used for deployment. deployType - Defines the type of deployment, either standard deployment which results in a system downtime or a zero-downtime blue-green deployment. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . keepOldInstance - In case of a blue-green deployment the old instance will be deleted by default. If this option is set to true the old instance will remain stopped in the Cloud Foundry space. mtaDeployParameters - Defines additional parameters passed to mta for deployment with the mtaDeployPlugin. mtaExtensionDescriptor - Defines additional extension descriptor file for deployment with the mtaDeployPlugin. mtaPath - Defines the path to *.mtar for deployment with the mtaDeployPlugin. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. smokeTestScript - Allows to specify a script which performs a check during blue-green deployment. The script gets the FQDN as parameter and returns exit code 0 in case check returned smokeTestStatusCode . More details can be found here Currently this option is only considered for deployTool cf_native . smokeTestStatusCode - Expected status code returned by the check. stashContent - Specific stashes that should be considered for the step execution.","title":"Parameters"},{"location":"steps/cloudFoundryDeploy/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cloudFoundry/apiEndpoint X cloudFoundry/appName X cloudFoundry/credentialsId X cloudFoundry/manifest X cloudFoundry/org X cloudFoundry/space X deployTool X deployType X dockerImage X dockerWorkspace X keepOldInstance X mtaDeployParameters X mtaExtensionDescriptor X mtaPath X script smokeTestScript X smokeTestStatusCode X stashContent X","title":"Step configuration"},{"location":"steps/cloudFoundryDeploy/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/cloudFoundryDeploy/#example","text":"cloudFoundryDeploy ( script: script , deployType: 'blue-green' , cloudFoundry: [ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ], deployTool: 'cf_native' )","title":"Example"},{"location":"steps/commonPipelineEnvironment/","text":"commonPipelineEnvironment \u00b6 Description \u00b6 Provides project specific settings. Prerequisites \u00b6 none Method details \u00b6 getInfluxCustomData() \u00b6 Description \u00b6 Returns the Influx custom data which can be collected during pipeline run. Parameters \u00b6 none Return value \u00b6 A Map containing the data collected. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 def myInfluxData = commonPipelineEnvironment . getInfluxCustomData () getInfluxCustomDataMap() \u00b6 Description \u00b6 Returns the Influx custom data map which can be collected during pipeline run. It is used for example by step influxWriteData . The data map is a map of maps, like [pipeline_data: [:], my_measurement: [:]] Each map inside the map represents a dedicated measurement in the InfluxDB. Parameters \u00b6 none Return value \u00b6 A Map containing a Map s with data collected. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 def myInfluxDataMap = commonPipelineEnvironment . getInfluxCustomDataMap () getPipelineMeasurement(measurementName) \u00b6 Description \u00b6 Returns the value of a specific pipeline measurement. The measurements are collected with step durationMeasure Parameters \u00b6 Name of the measurement Return value \u00b6 Value of the measurement Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 def myMeasurementValue = commonPipelineEnvironment . getPipelineMeasurement ( 'build_stage_duration' ) setPipelineMeasurement(measurementName, value) \u00b6 Description \u00b6 This is an internal function! Sets the value of a specific pipeline measurement. Please use the step durationMeasure in a pipeline, instead. Parameters \u00b6 Name of the measurement and its value. Return value \u00b6 none Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 commonPipelineEnvironment . setPipelineMeasurement ( 'build_stage_duration' , 2345 )","title":"commonPipelineEnvironment"},{"location":"steps/commonPipelineEnvironment/#commonpipelineenvironment","text":"","title":"commonPipelineEnvironment"},{"location":"steps/commonPipelineEnvironment/#description","text":"Provides project specific settings.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/commonPipelineEnvironment/#method-details","text":"","title":"Method details"},{"location":"steps/commonPipelineEnvironment/#getinfluxcustomdata","text":"","title":"getInfluxCustomData()"},{"location":"steps/commonPipelineEnvironment/#description_1","text":"Returns the Influx custom data which can be collected during pipeline run.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters","text":"none","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value","text":"A Map containing the data collected.","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example","text":"def myInfluxData = commonPipelineEnvironment . getInfluxCustomData ()","title":"Example"},{"location":"steps/commonPipelineEnvironment/#getinfluxcustomdatamap","text":"","title":"getInfluxCustomDataMap()"},{"location":"steps/commonPipelineEnvironment/#description_2","text":"Returns the Influx custom data map which can be collected during pipeline run. It is used for example by step influxWriteData . The data map is a map of maps, like [pipeline_data: [:], my_measurement: [:]] Each map inside the map represents a dedicated measurement in the InfluxDB.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters_1","text":"none","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value_1","text":"A Map containing a Map s with data collected.","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects_1","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions_1","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example_1","text":"def myInfluxDataMap = commonPipelineEnvironment . getInfluxCustomDataMap ()","title":"Example"},{"location":"steps/commonPipelineEnvironment/#getpipelinemeasurementmeasurementname","text":"","title":"getPipelineMeasurement(measurementName)"},{"location":"steps/commonPipelineEnvironment/#description_3","text":"Returns the value of a specific pipeline measurement. The measurements are collected with step durationMeasure","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters_2","text":"Name of the measurement","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value_2","text":"Value of the measurement","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects_2","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions_2","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example_2","text":"def myMeasurementValue = commonPipelineEnvironment . getPipelineMeasurement ( 'build_stage_duration' )","title":"Example"},{"location":"steps/commonPipelineEnvironment/#setpipelinemeasurementmeasurementname-value","text":"","title":"setPipelineMeasurement(measurementName, value)"},{"location":"steps/commonPipelineEnvironment/#description_4","text":"This is an internal function! Sets the value of a specific pipeline measurement. Please use the step durationMeasure in a pipeline, instead.","title":"Description"},{"location":"steps/commonPipelineEnvironment/#parameters_3","text":"Name of the measurement and its value.","title":"Parameters"},{"location":"steps/commonPipelineEnvironment/#return-value_3","text":"none","title":"Return value"},{"location":"steps/commonPipelineEnvironment/#side-effects_3","text":"none","title":"Side effects"},{"location":"steps/commonPipelineEnvironment/#exceptions_3","text":"none","title":"Exceptions"},{"location":"steps/commonPipelineEnvironment/#example_3","text":"commonPipelineEnvironment . setPipelineMeasurement ( 'build_stage_duration' , 2345 )","title":"Example"},{"location":"steps/containerExecuteStructureTests/","text":"containerExecuteStructureTests \u00b6 Description \u00b6 In this step Container Structure Tests are executed. This testing framework allows you to execute different test types against a Docker container, for example: Command tests (only if a Docker Deamon is available) File existence tests File content tests Metadata test Prerequisites \u00b6 Test configuration is available. Parameters \u00b6 name mandatory default possible values containerCommand no /busybox/tail -f /dev/null containerShell no /busybox/sh dockerImage no ppiper/container-structure-test dockerOptions no -u 0 --entrypoint='' failOnError no true true , false pullImage no true , false script yes stashContent no [tests] testConfiguration no testDriver no testImage no testReportFilePath no cst-report.json verbose no true , false containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). failOnError - Defines the behavior, in case tests fail. pullImage - Only relevant for testDriver 'docker'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testConfiguration - Container structure test configuration in yml or json format. You can pass a pattern in order to execute multiple tests. testDriver - Container structure test driver to be used for testing, please see https://github.com/GoogleContainerTools/container-structure-test for details. testImage - Image to be tested testReportFilePath - Path and name of the test report which will be generated verbose - Print more detailed information into the log. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerShell X dockerImage X dockerOptions X failOnError X pullImage X script stashContent X testConfiguration X testDriver X testImage X testReportFilePath X verbose X X Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 containerExecuteStructureTests( script: this, testConfiguration: 'config.yml', testImage: 'node:latest' )","title":"containerExecuteStructureTests"},{"location":"steps/containerExecuteStructureTests/#containerexecutestructuretests","text":"","title":"containerExecuteStructureTests"},{"location":"steps/containerExecuteStructureTests/#description","text":"In this step Container Structure Tests are executed. This testing framework allows you to execute different test types against a Docker container, for example: Command tests (only if a Docker Deamon is available) File existence tests File content tests Metadata test","title":"Description"},{"location":"steps/containerExecuteStructureTests/#prerequisites","text":"Test configuration is available.","title":"Prerequisites"},{"location":"steps/containerExecuteStructureTests/#parameters","text":"name mandatory default possible values containerCommand no /busybox/tail -f /dev/null containerShell no /busybox/sh dockerImage no ppiper/container-structure-test dockerOptions no -u 0 --entrypoint='' failOnError no true true , false pullImage no true , false script yes stashContent no [tests] testConfiguration no testDriver no testImage no testReportFilePath no cst-report.json verbose no true , false containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). failOnError - Defines the behavior, in case tests fail. pullImage - Only relevant for testDriver 'docker'. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Specific stashes that should be considered for the step execution. testConfiguration - Container structure test configuration in yml or json format. You can pass a pattern in order to execute multiple tests. testDriver - Container structure test driver to be used for testing, please see https://github.com/GoogleContainerTools/container-structure-test for details. testImage - Image to be tested testReportFilePath - Path and name of the test report which will be generated verbose - Print more detailed information into the log.","title":"Parameters"},{"location":"steps/containerExecuteStructureTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerShell X dockerImage X dockerOptions X failOnError X pullImage X script stashContent X testConfiguration X testDriver X testImage X testReportFilePath X verbose X X","title":"Step configuration"},{"location":"steps/containerExecuteStructureTests/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/containerExecuteStructureTests/#example","text":"containerExecuteStructureTests( script: this, testConfiguration: 'config.yml', testImage: 'node:latest' )","title":"Example"},{"location":"steps/detectExecuteScan/","text":"detectExecuteScan \u00b6 Description \u00b6 This step executes Synopsis Detect scans. Prerequsites \u00b6 You need to store the API token for the Detect service as 'Secret text' credential in your Jenkins system. minimum plugin requirement This step requires synopsys-detect-plugin with at least version 2.0.0 . Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 detectExecuteScan script: this , scanProperties: [ '--logging.level.com.synopsys.integration=TRACE' ] Parameters \u00b6 name mandatory default possible values buildTool no golang , any other build tool detect/apiTokenCredentialsId yes detect/projectName yes detect/projectVersion no 1 detect/scanPaths no [.] detect/scanProperties no [--blackduck.signature.scanner.memory=4096, --blackduck.timeout=6000, --blackduck.trust.cert=true, --detect.policy.check.fail.on.severities=BLOCKER,CRITICAL,MAJOR, --detect.report.timeout=4800, --logging.level.com.synopsys.integration=DEBUG] detect/scanners no [signature] ['signature'] detect/serverUrl no dockerImage no buildTool= golang : golang:1.12-stretch dockerWorkspace no buildTool= golang : <empty> script yes stashContent no [buildDescriptor, checkmarx] buildTool - Defines the tool which is used for building the artifact. Currently, it is possible to select two behaviors of the step: 1. Golang-specific behavior ( buildTool: golang ). Assumption here is that project uses the dependency management tool dep 2. Custom-specific behavior for all other values of buildTool detect/apiTokenCredentialsId - Jenkins 'Secret text' credentials ID containing the API token used to authenticate with the Synopsis Detect (formerly BlackDuck) Server. detect/projectName - Name of the Synopsis Detect (formerly BlackDuck) project. detect/projectVersion - Version of the Synopsis Detect (formerly BlackDuck) project. detect/scanPaths - List of paths which should be scanned by the Synopsis Detect (formerly BlackDuck) scan. detect/scanProperties - Properties passed to the Synopsis Detect (formerly BlackDuck) scan. You can find details in the Synopsis Detect documentation detect/scanners - List of scanners to be used for Synopsis Detect (formerly BlackDuck) scan. detect/serverUrl - Server url to the Synopsis Detect (formerly BlackDuck) Server. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered for the scan, their names need to be passed via the parameter stashContent . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X detect/apiTokenCredentialsId X X detect/projectName X X detect/projectVersion X X detect/scanPaths X X detect/scanProperties X X detect/scanners X X detect/serverUrl X X dockerImage X dockerWorkspace X script stashContent X","title":"detectExecuteScan"},{"location":"steps/detectExecuteScan/#detectexecutescan","text":"","title":"detectExecuteScan"},{"location":"steps/detectExecuteScan/#description","text":"This step executes Synopsis Detect scans.","title":"Description"},{"location":"steps/detectExecuteScan/#prerequsites","text":"You need to store the API token for the Detect service as 'Secret text' credential in your Jenkins system. minimum plugin requirement This step requires synopsys-detect-plugin with at least version 2.0.0 .","title":"Prerequsites"},{"location":"steps/detectExecuteScan/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/detectExecuteScan/#example","text":"detectExecuteScan script: this , scanProperties: [ '--logging.level.com.synopsys.integration=TRACE' ]","title":"Example"},{"location":"steps/detectExecuteScan/#parameters","text":"name mandatory default possible values buildTool no golang , any other build tool detect/apiTokenCredentialsId yes detect/projectName yes detect/projectVersion no 1 detect/scanPaths no [.] detect/scanProperties no [--blackduck.signature.scanner.memory=4096, --blackduck.timeout=6000, --blackduck.trust.cert=true, --detect.policy.check.fail.on.severities=BLOCKER,CRITICAL,MAJOR, --detect.report.timeout=4800, --logging.level.com.synopsys.integration=DEBUG] detect/scanners no [signature] ['signature'] detect/serverUrl no dockerImage no buildTool= golang : golang:1.12-stretch dockerWorkspace no buildTool= golang : <empty> script yes stashContent no [buildDescriptor, checkmarx] buildTool - Defines the tool which is used for building the artifact. Currently, it is possible to select two behaviors of the step: 1. Golang-specific behavior ( buildTool: golang ). Assumption here is that project uses the dependency management tool dep 2. Custom-specific behavior for all other values of buildTool detect/apiTokenCredentialsId - Jenkins 'Secret text' credentials ID containing the API token used to authenticate with the Synopsis Detect (formerly BlackDuck) Server. detect/projectName - Name of the Synopsis Detect (formerly BlackDuck) project. detect/projectVersion - Version of the Synopsis Detect (formerly BlackDuck) project. detect/scanPaths - List of paths which should be scanned by the Synopsis Detect (formerly BlackDuck) scan. detect/scanProperties - Properties passed to the Synopsis Detect (formerly BlackDuck) scan. You can find details in the Synopsis Detect documentation detect/scanners - List of scanners to be used for Synopsis Detect (formerly BlackDuck) scan. detect/serverUrl - Server url to the Synopsis Detect (formerly BlackDuck) Server. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered for the scan, their names need to be passed via the parameter stashContent .","title":"Parameters"},{"location":"steps/detectExecuteScan/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X detect/apiTokenCredentialsId X X detect/projectName X X detect/projectVersion X X detect/scanPaths X X detect/scanProperties X X detect/scanners X X detect/serverUrl X X dockerImage X dockerWorkspace X script stashContent X","title":"Step configuration"},{"location":"steps/dockerExecute/","text":"dockerExecute \u00b6 Description \u00b6 Executes a closure inside a docker container with the specified docker image. The workspace is mounted into the docker image. Proxy environment variables defined on the Jenkins machine are also available in the Docker container. Parameters \u00b6 name mandatory default possible values containerCommand no containerPortMappings no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no true dockerVolumeBind no dockerWorkspace no jenkinsKubernetes no [jnlpAgent:s4sdk/jenkins-agent-k8s:latest] script yes sidecarEnvVars no sidecarImage no sidecarName no sidecarOptions no sidecarPullImage no true sidecarReadyCommand no sidecarVolumeBind no sidecarWorkspace no stashContent no [] containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker options to be set when starting the container (List or String). dockerPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. dockerVolumeBind - Volumes that should be mounted into the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . jenkinsKubernetes - script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarOptions - as dockerOptions for the sidecar container sidecarPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. sidecarReadyCommand - Command executed inside the container which returns exit code 0 when the container is ready to be used. sidecarVolumeBind - as dockerVolumeBind for the sidecar container sidecarWorkspace - as dockerWorkspace for the sidecar container stashContent - Specific stashes that should be considered for the step execution. Kubernetes support \u00b6 If the Jenkins is setup on a Kubernetes cluster, then you can execute the closure inside a container of a pod by setting an environment variable ON_K8S to true . However, it will ignore containerPortMappings , dockerOptions and dockerVolumeBind values. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerPortMappings X containerShell X dockerEnvVars X dockerImage X dockerName X dockerOptions X dockerPullImage X dockerVolumeBind X dockerWorkspace X jenkinsKubernetes X X script sidecarEnvVars X sidecarImage X sidecarName X sidecarOptions X sidecarPullImage X sidecarReadyCommand X sidecarVolumeBind X sidecarWorkspace X stashContent X Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example 1: Run closure inside a docker container \u00b6 dockerExecute ( dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } Example 2: Run closure inside a container in a kubernetes pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecute ( script: this , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, the dockerEcecute step will internally invoke dockerExecuteOnKubernetes step and execute the closure inside a pod. Example 3: Run closure inside a container which is attached to a sidecar container (as for example used in seleniumExecuteTests \u00b6 dockerExecute ( script: script , containerPortMappings: [ containerPortMappings: 'selenium/standalone-chrome' :[ containerPort: 4444 , hostPort: 4444 ]], dockerImage: 'node:8-stretch' , dockerName: 'node' , dockerWorkspace: '/home/node' , sidecarImage: 'selenium/standalone-chrome' , sidecarName: 'selenium' , ) { git url: 'https://github.wdf.sap.corp/XXXXX/WebDriverIOTest.git' sh '''npm install node index.js ''' }","title":"dockerExecute"},{"location":"steps/dockerExecute/#dockerexecute","text":"","title":"dockerExecute"},{"location":"steps/dockerExecute/#description","text":"Executes a closure inside a docker container with the specified docker image. The workspace is mounted into the docker image. Proxy environment variables defined on the Jenkins machine are also available in the Docker container.","title":"Description"},{"location":"steps/dockerExecute/#parameters","text":"name mandatory default possible values containerCommand no containerPortMappings no containerShell no dockerEnvVars no dockerImage no dockerName no dockerOptions no dockerPullImage no true dockerVolumeBind no dockerWorkspace no jenkinsKubernetes no [jnlpAgent:s4sdk/jenkins-agent-k8s:latest] script yes sidecarEnvVars no sidecarImage no sidecarName no sidecarOptions no sidecarPullImage no true sidecarReadyCommand no sidecarVolumeBind no sidecarWorkspace no stashContent no [] containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerOptions - Docker options to be set when starting the container (List or String). dockerPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. dockerVolumeBind - Volumes that should be mounted into the container. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . jenkinsKubernetes - script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarOptions - as dockerOptions for the sidecar container sidecarPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. sidecarReadyCommand - Command executed inside the container which returns exit code 0 when the container is ready to be used. sidecarVolumeBind - as dockerVolumeBind for the sidecar container sidecarWorkspace - as dockerWorkspace for the sidecar container stashContent - Specific stashes that should be considered for the step execution.","title":"Parameters"},{"location":"steps/dockerExecute/#kubernetes-support","text":"If the Jenkins is setup on a Kubernetes cluster, then you can execute the closure inside a container of a pod by setting an environment variable ON_K8S to true . However, it will ignore containerPortMappings , dockerOptions and dockerVolumeBind values.","title":"Kubernetes support"},{"location":"steps/dockerExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerPortMappings X containerShell X dockerEnvVars X dockerImage X dockerName X dockerOptions X dockerPullImage X dockerVolumeBind X dockerWorkspace X jenkinsKubernetes X X script sidecarEnvVars X sidecarImage X sidecarName X sidecarOptions X sidecarPullImage X sidecarReadyCommand X sidecarVolumeBind X sidecarWorkspace X stashContent X","title":"Step configuration"},{"location":"steps/dockerExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/dockerExecute/#side-effects","text":"none","title":"Side effects"},{"location":"steps/dockerExecute/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/dockerExecute/#example-1-run-closure-inside-a-docker-container","text":"dockerExecute ( dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" }","title":"Example 1: Run closure inside a docker container"},{"location":"steps/dockerExecute/#example-2-run-closure-inside-a-container-in-a-kubernetes-pod","text":"# set environment variable export ON_K8S = true \" dockerExecute ( script: this , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, the dockerEcecute step will internally invoke dockerExecuteOnKubernetes step and execute the closure inside a pod.","title":"Example 2: Run closure inside a container in a kubernetes pod"},{"location":"steps/dockerExecute/#example-3-run-closure-inside-a-container-which-is-attached-to-a-sidecar-container-as-for-example-used-in-seleniumexecutetests","text":"dockerExecute ( script: script , containerPortMappings: [ containerPortMappings: 'selenium/standalone-chrome' :[ containerPort: 4444 , hostPort: 4444 ]], dockerImage: 'node:8-stretch' , dockerName: 'node' , dockerWorkspace: '/home/node' , sidecarImage: 'selenium/standalone-chrome' , sidecarName: 'selenium' , ) { git url: 'https://github.wdf.sap.corp/XXXXX/WebDriverIOTest.git' sh '''npm install node index.js ''' }","title":"Example 3: Run closure inside a container which is attached to a sidecar container (as for example used in seleniumExecuteTests"},{"location":"steps/dockerExecuteOnKubernetes/","text":"dockerExecuteOnKubernetes \u00b6 Description \u00b6 Executes a closure inside a container in a kubernetes pod. Proxy environment variables defined on the Jenkins machine are also available in the container. Prerequisites \u00b6 The Jenkins should be running on kubernetes. An environment variable ON_K8S should be created on Jenkins and initialized to true . This could for example be done via Jenkins - Manage Jenkins - Configure System - Global properties - Environment variables Parameters \u00b6 name mandatory default possible values containerCommand no containerCommands no containerEnvVars no containerMap no containerName no containerPortMappings no containerPullImageFlags no containerShell no containerWorkspaces no dockerEnvVars no dockerImage yes dockerPullImage no true dockerWorkspace no jenkinsKubernetes no [jnlpAgent:s4sdk/jenkins-agent-k8s:latest] script yes securityContext no stashContent no [] stashExcludes no [workspace:nohup.out] stashIncludes no [workspace:**/*] containerCommand - Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerCommands - Specifies start command for containers to overwrite Piper default ( /usr/bin/tail -f /dev/null ). If container's defaultstart command should be used provide empty string like: ['selenium/standalone-chrome': ''] . containerEnvVars - Specifies environment variables per container. If not provided dockerEnvVars will be used. containerMap - A map of docker image to the name of the container. The pod will be created with all the images from this map and they are labled based on the value field of each map entry. Example: ['maven:3.5-jdk-8-alpine': 'mavenExecute', 'selenium/standalone-chrome': 'selenium', 'famiko/jmeter-base': 'checkJMeter', 's4sdk/docker-cf-cli': 'cloudfoundry'] containerName - Optional configuration in combination with containerMap to define the container where the commands should be executed in. containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerPullImageFlags - Specifies the pullImage flag per container. containerShell - Allows to specify the shell to be executed for container with containerName. containerWorkspaces - Specifies a dedicated user home directory per container which will be passed as value for environment variable HOME . If not provided dockerWorkspace will be used. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used. dockerPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. dockerWorkspace - Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . jenkinsKubernetes - script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityContext - Kubernetes Security Context used for the pod. Can be used to specify uid and fsGroup. See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ stashContent - Specific stashes that should be considered for the step execution. stashExcludes - stashIncludes - Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerCommands X containerEnvVars X containerMap X containerName X containerPortMappings X containerPullImageFlags X containerShell X containerWorkspaces X dockerEnvVars X dockerImage X dockerPullImage X dockerWorkspace X jenkinsKubernetes X X script securityContext X stashContent X stashExcludes X stashIncludes X Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example 1: Run a closure in a single container pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, a pod will be created with a docker container of image maven:3.5-jdk-7 . The closure will be then executed inside the container. Example 2: Run a closure in a multi-container pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 's4sdk/docker-cf-cli' : 'cfcli' ]){ container ( 'maven' ){ sh \"mvn clean install\" } container ( 'cfcli' ){ sh \"cf plugins\" } } In the above example, a pod will be created with multiple Docker containers that are passed as a containerMap . The containers can be chosen for executing by referring their labels as shown in the example. Example 3: Running a closure in a dedicated container of a multi-container pod \u00b6 # set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerCommands: [ 'selenium/standalone-chrome' : '' ], containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 'selenium/standalone-chrome' : 'selenium' ], containerName: 'maven' , containerPortMappings: [ 'selenium/standalone-chrome' : [ containerPort: 4444 , hostPort: 4444 ]] containerWorkspaces: [ 'selenium/standalone-chrome' : '' ] ){ echo \"Executing inside a Kubernetes Pod inside 'maven' container to run Selenium tests\" sh \"mvn clean install\" }","title":"dockerExecuteOnKubernetes"},{"location":"steps/dockerExecuteOnKubernetes/#dockerexecuteonkubernetes","text":"","title":"dockerExecuteOnKubernetes"},{"location":"steps/dockerExecuteOnKubernetes/#description","text":"Executes a closure inside a container in a kubernetes pod. Proxy environment variables defined on the Jenkins machine are also available in the container.","title":"Description"},{"location":"steps/dockerExecuteOnKubernetes/#prerequisites","text":"The Jenkins should be running on kubernetes. An environment variable ON_K8S should be created on Jenkins and initialized to true . This could for example be done via Jenkins - Manage Jenkins - Configure System - Global properties - Environment variables","title":"Prerequisites"},{"location":"steps/dockerExecuteOnKubernetes/#parameters","text":"name mandatory default possible values containerCommand no containerCommands no containerEnvVars no containerMap no containerName no containerPortMappings no containerPullImageFlags no containerShell no containerWorkspaces no dockerEnvVars no dockerImage yes dockerPullImage no true dockerWorkspace no jenkinsKubernetes no [jnlpAgent:s4sdk/jenkins-agent-k8s:latest] script yes securityContext no stashContent no [] stashExcludes no [workspace:nohup.out] stashIncludes no [workspace:**/*] containerCommand - Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerCommands - Specifies start command for containers to overwrite Piper default ( /usr/bin/tail -f /dev/null ). If container's defaultstart command should be used provide empty string like: ['selenium/standalone-chrome': ''] . containerEnvVars - Specifies environment variables per container. If not provided dockerEnvVars will be used. containerMap - A map of docker image to the name of the container. The pod will be created with all the images from this map and they are labled based on the value field of each map entry. Example: ['maven:3.5-jdk-8-alpine': 'mavenExecute', 'selenium/standalone-chrome': 'selenium', 'famiko/jmeter-base': 'checkJMeter', 's4sdk/docker-cf-cli': 'cloudfoundry'] containerName - Optional configuration in combination with containerMap to define the container where the commands should be executed in. containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . containerPullImageFlags - Specifies the pullImage flag per container. containerShell - Allows to specify the shell to be executed for container with containerName. containerWorkspaces - Specifies a dedicated user home directory per container which will be passed as value for environment variable HOME . If not provided dockerWorkspace will be used. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used. dockerPullImage - Set this to 'false' to bypass a docker image pull. Usefull during development process. Allows testing of images which are available in the local registry only. dockerWorkspace - Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . jenkinsKubernetes - script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityContext - Kubernetes Security Context used for the pod. Can be used to specify uid and fsGroup. See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/ stashContent - Specific stashes that should be considered for the step execution. stashExcludes - stashIncludes -","title":"Parameters"},{"location":"steps/dockerExecuteOnKubernetes/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerCommand X containerCommands X containerEnvVars X containerMap X containerName X containerPortMappings X containerPullImageFlags X containerShell X containerWorkspaces X dockerEnvVars X dockerImage X dockerPullImage X dockerWorkspace X jenkinsKubernetes X X script securityContext X stashContent X stashExcludes X stashIncludes X","title":"Step configuration"},{"location":"steps/dockerExecuteOnKubernetes/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/dockerExecuteOnKubernetes/#side-effects","text":"none","title":"Side effects"},{"location":"steps/dockerExecuteOnKubernetes/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/dockerExecuteOnKubernetes/#example-1-run-a-closure-in-a-single-container-pod","text":"# set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , dockerImage: 'maven:3.5-jdk-7' ){ sh \"mvn clean install\" } In the above example, a pod will be created with a docker container of image maven:3.5-jdk-7 . The closure will be then executed inside the container.","title":"Example 1: Run a closure in a single container pod"},{"location":"steps/dockerExecuteOnKubernetes/#example-2-run-a-closure-in-a-multi-container-pod","text":"# set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 's4sdk/docker-cf-cli' : 'cfcli' ]){ container ( 'maven' ){ sh \"mvn clean install\" } container ( 'cfcli' ){ sh \"cf plugins\" } } In the above example, a pod will be created with multiple Docker containers that are passed as a containerMap . The containers can be chosen for executing by referring their labels as shown in the example.","title":"Example 2: Run a closure in a multi-container pod"},{"location":"steps/dockerExecuteOnKubernetes/#example-3-running-a-closure-in-a-dedicated-container-of-a-multi-container-pod","text":"# set environment variable export ON_K8S = true \" dockerExecuteOnKubernetes ( script: script , containerCommands: [ 'selenium/standalone-chrome' : '' ], containerMap: [ 'maven:3.5-jdk-8-alpine' : 'maven' , 'selenium/standalone-chrome' : 'selenium' ], containerName: 'maven' , containerPortMappings: [ 'selenium/standalone-chrome' : [ containerPort: 4444 , hostPort: 4444 ]] containerWorkspaces: [ 'selenium/standalone-chrome' : '' ] ){ echo \"Executing inside a Kubernetes Pod inside 'maven' container to run Selenium tests\" sh \"mvn clean install\" }","title":"Example 3: Running a closure in a dedicated container of a multi-container pod"},{"location":"steps/durationMeasure/","text":"durationMeasure \u00b6 Description \u00b6 This step is used to measure the duration of a set of steps, e.g. a certain stage. The duration is stored in a Map. The measurement data can then be written to an Influx database using step influxWriteData . Tip Measuring for example the duration of pipeline stages helps to identify potential bottlenecks within the deployment pipeline. This then helps to counter identified issues with respective optimization measures, e.g parallelization of tests. Parameters \u00b6 name mandatory default possible values measurementName no script yes measurementName - Defines the name of the measurement which is written to the Influx database. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage measurementName script Dependencies \u00b6 The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 durationMeasure ( script: this , measurementName: 'build_duration' ) { //execute your build }","title":"durationMeasure"},{"location":"steps/durationMeasure/#durationmeasure","text":"","title":"durationMeasure"},{"location":"steps/durationMeasure/#description","text":"This step is used to measure the duration of a set of steps, e.g. a certain stage. The duration is stored in a Map. The measurement data can then be written to an Influx database using step influxWriteData . Tip Measuring for example the duration of pipeline stages helps to identify potential bottlenecks within the deployment pipeline. This then helps to counter identified issues with respective optimization measures, e.g parallelization of tests.","title":"Description"},{"location":"steps/durationMeasure/#parameters","text":"name mandatory default possible values measurementName no script yes measurementName - Defines the name of the measurement which is written to the Influx database. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/durationMeasure/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage measurementName script","title":"Step configuration"},{"location":"steps/durationMeasure/#dependencies","text":"The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/durationMeasure/#example","text":"durationMeasure ( script: this , measurementName: 'build_duration' ) { //execute your build }","title":"Example"},{"location":"steps/gaugeExecuteTests/","text":"gaugeExecuteTests \u00b6 Description \u00b6 In this step Gauge ( getgauge.io ) acceptance tests are executed. Using Gauge it will be possible to have a three-tier test layout: Acceptance Criteria Test implemenation layer Application driver layer This layout is propagated by Jez Humble and Dave Farley in their book \"Continuous Delivery\" as a way to create maintainable acceptance test suites (see \"Continuous Delivery\", p. 190ff). Using Gauge it is possible to write test specifications in Markdown syntax and therefore allow e.g. product owners to write the relevant acceptance test specifications. At the same time it allows the developer to implement the steps described in the specification in her development environment. You can use the sample projects of Gauge. Make sure to run against a Selenium Hub configuration In the test example of gauge-archetype-selenium please make sure to allow it to run against a Selenium hub: Please extend DriverFactory.java for example in following way: String hubUrl = System . getenv ( \"HUB_URL\" ); //when running on a Docker deamon (and not using Kubernetes plugin), Docker images will be linked //in this case hubUrl will be http://selenium:4444/wd/hub due to the linking of the containers hubUrl = ( hubUrl == null ) ? \"http://localhost:4444/wd/hub\" : hubUrl ; Capabilities chromeCapabilities = DesiredCapabilities . chrome (); System . out . println ( \"Running on Selenium Hub: \" + hubUrl ); return new RemoteWebDriver ( new URL ( hubUrl ), chromeCapabilities ); Prerequsites \u00b6 none Parameters \u00b6 name mandatory default possible values buildTool no maven maven , npm , bundler dockerEnvVars no [HUB:TRUE, HUB_URL:http://localhost:4444/wd/hub] dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:8-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` installCommand no curl -SsL https://downloads.gauge.org/stable | sh -s -- --location=$HOME/bin/gauge languageRunner no buildTool= maven : java buildTool= npm : js buildTool= bundler : ruby runCommand no buildTool= maven : mvn test-compile gauge:execute buildTool= npm : gauge run buildTool= bundler : bundle install && bundle exec gauge run script yes stashContent no [buildDescriptor, tests] testOptions no buildTool= maven : -DspecsDir=specs buildTool= npm : specs buildTool= bundler : specs testRepository no testServerUrl no buildTool - Defines the build tool to be used for the test execution. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - Defines the behavior in case tests fail. When this is set to true test results cannot be recorded using the publishTestResults step afterwards. gitBranch - Defines the branch containing the tests, in case the test implementation is stored in a different repository and a different branch than master. gitSshKeyCredentialsId - Defines the credentials for the repository containing the tests, in case the test implementation is stored in a different and protected repository than the code itself. For protected repositories the testRepository needs to contain the ssh git url. installCommand - Defines the command for installing Gauge. In case the dockerImage already contains Gauge it can be set to empty: ``. languageRunner - Defines the Gauge language runner to be used. runCommand - Defines the command which is used for executing Gauge. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Defines if specific stashes should be considered for the tests. testOptions - Allows to set specific options for the Gauge execution. Details can be found for example in the Gauge Maven plugin documentation testRepository - Defines the repository containing the tests, in case the test implementation is stored in a different repository than the code itself. testServerUrl - It is passed as environment variable TARGET_SERVER_URL to the test execution. Tests running against the system should read the host information from this environment variable in order to be infrastructure agnostic. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X dockerEnvVars X dockerImage X dockerName X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X installCommand X languageRunner X runCommand X script stashContent X testOptions X testRepository X testServerUrl X We recommend to define values of step parameters via config.yml file . Dependencies \u00b6 The step depends on the following Jenkins plugins git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 Pipeline step: gaugeExecuteTests script: this , testServerUrl: 'http://test.url'","title":"gaugeExecuteTests"},{"location":"steps/gaugeExecuteTests/#gaugeexecutetests","text":"","title":"gaugeExecuteTests"},{"location":"steps/gaugeExecuteTests/#description","text":"In this step Gauge ( getgauge.io ) acceptance tests are executed. Using Gauge it will be possible to have a three-tier test layout: Acceptance Criteria Test implemenation layer Application driver layer This layout is propagated by Jez Humble and Dave Farley in their book \"Continuous Delivery\" as a way to create maintainable acceptance test suites (see \"Continuous Delivery\", p. 190ff). Using Gauge it is possible to write test specifications in Markdown syntax and therefore allow e.g. product owners to write the relevant acceptance test specifications. At the same time it allows the developer to implement the steps described in the specification in her development environment. You can use the sample projects of Gauge. Make sure to run against a Selenium Hub configuration In the test example of gauge-archetype-selenium please make sure to allow it to run against a Selenium hub: Please extend DriverFactory.java for example in following way: String hubUrl = System . getenv ( \"HUB_URL\" ); //when running on a Docker deamon (and not using Kubernetes plugin), Docker images will be linked //in this case hubUrl will be http://selenium:4444/wd/hub due to the linking of the containers hubUrl = ( hubUrl == null ) ? \"http://localhost:4444/wd/hub\" : hubUrl ; Capabilities chromeCapabilities = DesiredCapabilities . chrome (); System . out . println ( \"Running on Selenium Hub: \" + hubUrl ); return new RemoteWebDriver ( new URL ( hubUrl ), chromeCapabilities );","title":"Description"},{"location":"steps/gaugeExecuteTests/#prerequsites","text":"none","title":"Prerequsites"},{"location":"steps/gaugeExecuteTests/#parameters","text":"name mandatory default possible values buildTool no maven maven , npm , bundler dockerEnvVars no [HUB:TRUE, HUB_URL:http://localhost:4444/wd/hub] dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:8-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` installCommand no curl -SsL https://downloads.gauge.org/stable | sh -s -- --location=$HOME/bin/gauge languageRunner no buildTool= maven : java buildTool= npm : js buildTool= bundler : ruby runCommand no buildTool= maven : mvn test-compile gauge:execute buildTool= npm : gauge run buildTool= bundler : bundle install && bundle exec gauge run script yes stashContent no [buildDescriptor, tests] testOptions no buildTool= maven : -DspecsDir=specs buildTool= npm : specs buildTool= bundler : specs testRepository no testServerUrl no buildTool - Defines the build tool to be used for the test execution. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - Defines the behavior in case tests fail. When this is set to true test results cannot be recorded using the publishTestResults step afterwards. gitBranch - Defines the branch containing the tests, in case the test implementation is stored in a different repository and a different branch than master. gitSshKeyCredentialsId - Defines the credentials for the repository containing the tests, in case the test implementation is stored in a different and protected repository than the code itself. For protected repositories the testRepository needs to contain the ssh git url. installCommand - Defines the command for installing Gauge. In case the dockerImage already contains Gauge it can be set to empty: ``. languageRunner - Defines the Gauge language runner to be used. runCommand - Defines the command which is used for executing Gauge. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - Defines if specific stashes should be considered for the tests. testOptions - Allows to set specific options for the Gauge execution. Details can be found for example in the Gauge Maven plugin documentation testRepository - Defines the repository containing the tests, in case the test implementation is stored in a different repository than the code itself. testServerUrl - It is passed as environment variable TARGET_SERVER_URL to the test execution. Tests running against the system should read the host information from this environment variable in order to be infrastructure agnostic.","title":"Parameters"},{"location":"steps/gaugeExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X dockerEnvVars X dockerImage X dockerName X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X installCommand X languageRunner X runCommand X script stashContent X testOptions X testRepository X testServerUrl X We recommend to define values of step parameters via config.yml file .","title":"Step configuration"},{"location":"steps/gaugeExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/gaugeExecuteTests/#example","text":"Pipeline step: gaugeExecuteTests script: this , testServerUrl: 'http://test.url'","title":"Example"},{"location":"steps/githubPublishRelease/","text":"githubPublishRelease \u00b6 Prerequisites \u00b6 You need to create a personal access token within GitHub and add this to the Jenkins credentials store. Please see GitHub documentation for details about creating the personal access token . Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding http_request pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Parameters \u00b6 name mandatory default possible values addClosedIssues no false true , false addDeltaToLastRelease no false true , false customFilterExtension no `` excludeLabels no [duplicate, invalid, question, wontfix] githubApiUrl no https://api.github.com githubOrg yes githubRepo yes githubServerUrl no https://github.com githubTokenCredentialsId yes Jenkins credential id releaseBodyHeader no script yes version yes addClosedIssues - If it is set to true , a list of all closed issues and merged pull-requests since the last release will added below the releaseBodyHeader . addDeltaToLastRelease - If you set addDeltaToLastRelease to true , a link will be added to the relese information that brings up all commits since the last release. customFilterExtension - Allows to pass additional filter criteria for retrieving closed issues since the last release. Additional criteria could be for example specific label , or filter according to GitHub API documentation . excludeLabels - Allows to exclude issues with dedicated labels. Usage is like excludeLabels: ['label1', 'label2'] . githubApiUrl - Allows to overwrite the GitHub API url. githubOrg - Allows to overwrite the GitHub organitation. githubRepo - Allows to overwrite the GitHub repository. githubServerUrl - Allows to overwrite the GitHub url. githubTokenCredentialsId - Allows to overwrite the GitHub token credentials id. releaseBodyHeader - Allows to specify the content which will appear for the release. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. version - Defines the version number which will be written as tag as well as release name. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage addClosedIssues X addDeltaToLastRelease X customFilterExtension X excludeLabels X githubApiUrl X X githubOrg X githubRepo X githubServerUrl X X githubTokenCredentialsId X X releaseBodyHeader X script version X Description \u00b6 This step creates a tag in your GitHub repository together with a release. The release can be filled with text plus additional information like: Closed pull request since last release Closed issues since last release link to delta information showing all commits since last release The result looks like Example \u00b6 Usage of pipeline step: githubPublishRelease script: this , releaseBodyHeader: \"**This is the latest success!**<br />\"","title":"githubPublishRelease"},{"location":"steps/githubPublishRelease/#githubpublishrelease","text":"","title":"githubPublishRelease"},{"location":"steps/githubPublishRelease/#prerequisites","text":"You need to create a personal access token within GitHub and add this to the Jenkins credentials store. Please see GitHub documentation for details about creating the personal access token .","title":"Prerequisites"},{"location":"steps/githubPublishRelease/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding http_request pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/githubPublishRelease/#parameters","text":"name mandatory default possible values addClosedIssues no false true , false addDeltaToLastRelease no false true , false customFilterExtension no `` excludeLabels no [duplicate, invalid, question, wontfix] githubApiUrl no https://api.github.com githubOrg yes githubRepo yes githubServerUrl no https://github.com githubTokenCredentialsId yes Jenkins credential id releaseBodyHeader no script yes version yes addClosedIssues - If it is set to true , a list of all closed issues and merged pull-requests since the last release will added below the releaseBodyHeader . addDeltaToLastRelease - If you set addDeltaToLastRelease to true , a link will be added to the relese information that brings up all commits since the last release. customFilterExtension - Allows to pass additional filter criteria for retrieving closed issues since the last release. Additional criteria could be for example specific label , or filter according to GitHub API documentation . excludeLabels - Allows to exclude issues with dedicated labels. Usage is like excludeLabels: ['label1', 'label2'] . githubApiUrl - Allows to overwrite the GitHub API url. githubOrg - Allows to overwrite the GitHub organitation. githubRepo - Allows to overwrite the GitHub repository. githubServerUrl - Allows to overwrite the GitHub url. githubTokenCredentialsId - Allows to overwrite the GitHub token credentials id. releaseBodyHeader - Allows to specify the content which will appear for the release. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. version - Defines the version number which will be written as tag as well as release name.","title":"Parameters"},{"location":"steps/githubPublishRelease/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage addClosedIssues X addDeltaToLastRelease X customFilterExtension X excludeLabels X githubApiUrl X X githubOrg X githubRepo X githubServerUrl X X githubTokenCredentialsId X X releaseBodyHeader X script version X","title":"Step configuration"},{"location":"steps/githubPublishRelease/#description","text":"This step creates a tag in your GitHub repository together with a release. The release can be filled with text plus additional information like: Closed pull request since last release Closed issues since last release link to delta information showing all commits since last release The result looks like","title":"Description"},{"location":"steps/githubPublishRelease/#example","text":"Usage of pipeline step: githubPublishRelease script: this , releaseBodyHeader: \"**This is the latest success!**<br />\"","title":"Example"},{"location":"steps/hadolintExecute/","text":"hadolintExecute \u00b6 Description \u00b6 Executes the Haskell Dockerfile Linter which is a smarter Dockerfile linter that helps you build best practice Docker images. The linter is parsing the Dockerfile into an abstract syntax tree (AST) and performs rules on top of the AST. Parameters \u00b6 name mandatory default possible values configurationFile no .hadolint.yaml configurationUrl no `` dockerFile no ./Dockerfile dockerImage no hadolint/hadolint:latest-debian dockerOptions no qualityGates no [[threshold:1, type:TOTAL_ERROR, unstable:false]] reportFile no hadolint.xml script yes configurationFile - Name of the configuration file used locally within the step. If a file with this name is detected as part of your repo downloading the central configuration via configurationUrl will be skipped. If you change the file's name make sure your stashing configuration also reflects this. configurationUrl - URL pointing to the .hadolint.yaml exclude configuration to be used for linting. Also have a look at configurationFile which could avoid central configuration download in case the file is part of your repository. dockerFile - Dockerfile to be used for the assessment. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'hadolint/hadolint:latest-debian'. dockerOptions - Docker options to be set when starting the container. qualityGates - Quality Gates to fail the build, see warnings-ng plugin documentation . reportFile - Name of the result file used locally within the step. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage configurationFile X configurationUrl X dockerFile X X dockerImage X X dockerOptions X qualityGates X reportFile X script Exceptions \u00b6 None Examples \u00b6 hadolintExecute script: this","title":"hadolintExecute"},{"location":"steps/hadolintExecute/#hadolintexecute","text":"","title":"hadolintExecute"},{"location":"steps/hadolintExecute/#description","text":"Executes the Haskell Dockerfile Linter which is a smarter Dockerfile linter that helps you build best practice Docker images. The linter is parsing the Dockerfile into an abstract syntax tree (AST) and performs rules on top of the AST.","title":"Description"},{"location":"steps/hadolintExecute/#parameters","text":"name mandatory default possible values configurationFile no .hadolint.yaml configurationUrl no `` dockerFile no ./Dockerfile dockerImage no hadolint/hadolint:latest-debian dockerOptions no qualityGates no [[threshold:1, type:TOTAL_ERROR, unstable:false]] reportFile no hadolint.xml script yes configurationFile - Name of the configuration file used locally within the step. If a file with this name is detected as part of your repo downloading the central configuration via configurationUrl will be skipped. If you change the file's name make sure your stashing configuration also reflects this. configurationUrl - URL pointing to the .hadolint.yaml exclude configuration to be used for linting. Also have a look at configurationFile which could avoid central configuration download in case the file is part of your repository. dockerFile - Dockerfile to be used for the assessment. dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'hadolint/hadolint:latest-debian'. dockerOptions - Docker options to be set when starting the container. qualityGates - Quality Gates to fail the build, see warnings-ng plugin documentation . reportFile - Name of the result file used locally within the step. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/hadolintExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage configurationFile X configurationUrl X dockerFile X X dockerImage X X dockerOptions X qualityGates X reportFile X script","title":"Step configuration"},{"location":"steps/hadolintExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/hadolintExecute/#examples","text":"hadolintExecute script: this","title":"Examples"},{"location":"steps/handlePipelineStepErrors/","text":"handlePipelineStepErrors \u00b6 Description \u00b6 Used by other steps to make error analysis easier. Lists parameters and other data available to the step in which the error occurs. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values echoDetails no true true , false failOnError no true true , false libraryDocumentationUrl no https://sap.github.io/jenkins-library/ libraryRepositoryUrl no https://github.com/SAP/jenkins-library/ mandatorySteps no [] script yes stepName yes stepNameDoc no stepParameters yes stepTimeouts no [:] echoDetails - If it is set to true details will be output to the console. See example below. failOnError - Defines the behavior, in case an error occurs which is handled by this step. When set to false an error results in an \"UNSTABLE\" build result and the pipeline can continue. libraryDocumentationUrl - Defines the url of the library's documentation that will be used to generate the corresponding links to the step documentation. libraryRepositoryUrl - Defines the url of the library's repository that will be used to generate the corresponding links to the step implementation. mandatorySteps - Defines a list of mandatory steps (step names) which have to be successful (=stop the pipeline), even if failOnError: false script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stepName - Defines the name of the step for which the error handling is active. It will be shown in the console log. stepNameDoc - Defines the documented step, in case the documentation reference should point to a different step. stepParameters - Passes the parameters of the step which uses the error handling onto the error handling. The list of parameters is then shown in the console output. stepTimeouts - Defines a Map containing step name as key and timout in minutes in order to stop an execution after a certain timeout. This helps to make pipeline runs more resilient with respect to long running steps. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage echoDetails failOnError X libraryDocumentationUrl libraryRepositoryUrl mandatorySteps X script stepName stepNameDoc stepParameters stepTimeouts X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 handlePipelineStepErrors ( stepName: 'executeHealthCheck' , stepParameters: parameters ) { def url = new Utils (). getMandatoryParameter ( parameters , 'url' , null ) def statusCode = curl ( url ) if ( statusCode != '200' ) error \"Health Check failed: ${statusCode}\" } Example console output \u00b6 If echoDetails is set to true the following information will be output to the console: Step beginning: --- Begin library step: ${stepName}.groovy --- Step end: --- End library step: ${stepName}.groovy --- Step errors: ---------------------------------------------------------- --- An error occurred in the library step: ${stepName} ---------------------------------------------------------- The following parameters were available to the step: *** ${stepParameters} *** The error was: *** ${err} *** Further information: * Documentation of step ${stepName}: .../${stepName}/ * Pipeline documentation: https://... * GitHub repository for pipeline steps: https://... ----------------------------------------------------------","title":"handlePipelineStepErrors"},{"location":"steps/handlePipelineStepErrors/#handlepipelinesteperrors","text":"","title":"handlePipelineStepErrors"},{"location":"steps/handlePipelineStepErrors/#description","text":"Used by other steps to make error analysis easier. Lists parameters and other data available to the step in which the error occurs.","title":"Description"},{"location":"steps/handlePipelineStepErrors/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/handlePipelineStepErrors/#parameters","text":"name mandatory default possible values echoDetails no true true , false failOnError no true true , false libraryDocumentationUrl no https://sap.github.io/jenkins-library/ libraryRepositoryUrl no https://github.com/SAP/jenkins-library/ mandatorySteps no [] script yes stepName yes stepNameDoc no stepParameters yes stepTimeouts no [:] echoDetails - If it is set to true details will be output to the console. See example below. failOnError - Defines the behavior, in case an error occurs which is handled by this step. When set to false an error results in an \"UNSTABLE\" build result and the pipeline can continue. libraryDocumentationUrl - Defines the url of the library's documentation that will be used to generate the corresponding links to the step documentation. libraryRepositoryUrl - Defines the url of the library's repository that will be used to generate the corresponding links to the step implementation. mandatorySteps - Defines a list of mandatory steps (step names) which have to be successful (=stop the pipeline), even if failOnError: false script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stepName - Defines the name of the step for which the error handling is active. It will be shown in the console log. stepNameDoc - Defines the documented step, in case the documentation reference should point to a different step. stepParameters - Passes the parameters of the step which uses the error handling onto the error handling. The list of parameters is then shown in the console output. stepTimeouts - Defines a Map containing step name as key and timout in minutes in order to stop an execution after a certain timeout. This helps to make pipeline runs more resilient with respect to long running steps.","title":"Parameters"},{"location":"steps/handlePipelineStepErrors/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage echoDetails failOnError X libraryDocumentationUrl libraryRepositoryUrl mandatorySteps X script stepName stepNameDoc stepParameters stepTimeouts X","title":"Step configuration"},{"location":"steps/handlePipelineStepErrors/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/handlePipelineStepErrors/#example","text":"handlePipelineStepErrors ( stepName: 'executeHealthCheck' , stepParameters: parameters ) { def url = new Utils (). getMandatoryParameter ( parameters , 'url' , null ) def statusCode = curl ( url ) if ( statusCode != '200' ) error \"Health Check failed: ${statusCode}\" }","title":"Example"},{"location":"steps/handlePipelineStepErrors/#example-console-output","text":"If echoDetails is set to true the following information will be output to the console: Step beginning: --- Begin library step: ${stepName}.groovy --- Step end: --- End library step: ${stepName}.groovy --- Step errors: ---------------------------------------------------------- --- An error occurred in the library step: ${stepName} ---------------------------------------------------------- The following parameters were available to the step: *** ${stepParameters} *** The error was: *** ${err} *** Further information: * Documentation of step ${stepName}: .../${stepName}/ * Pipeline documentation: https://... * GitHub repository for pipeline steps: https://... ----------------------------------------------------------","title":"Example console output"},{"location":"steps/healthExecuteCheck/","text":"healthExecuteCheck \u00b6 Description \u00b6 Calls the health endpoint url of the application. The intention of the check is to verify that a suitable health endpoint is available. Such a health endpoint is required for operation purposes. This check is used as a real-life test for your productive health endpoints. Check Depth Typically, tools performing simple health checks are not too smart. Therefore it is important to choose an endpoint for checking wisely. This check therefore only checks if the application/service url returns HTTP 200 . This is in line with health check capabilities of platforms which are used for example in load balancing scenarios. Here you can find an example for Amazon AWS . Prerequisites \u00b6 Endpoint for health check is configured. Warning The health endpoint needs to be available without authentication! Tip If using Spring Boot framework, ideally the provided /health endpoint is used and extended by development. Further information can be found in the Spring Boot documenation for Endpoints Parameters \u00b6 name mandatory default possible values healthEndpoint no `` script yes testServerUrl yes healthEndpoint - Optionally with healthEndpoint the health function is called if endpoint is not the standard url. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. testServerUrl - Health check function is called providing full qualified testServerUrl to the health check. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage healthEndpoint X script testServerUrl X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 Pipeline step: healthExecuteCheck testServerUrl: 'https://testserver.com'","title":"healthExecuteCheck"},{"location":"steps/healthExecuteCheck/#healthexecutecheck","text":"","title":"healthExecuteCheck"},{"location":"steps/healthExecuteCheck/#description","text":"Calls the health endpoint url of the application. The intention of the check is to verify that a suitable health endpoint is available. Such a health endpoint is required for operation purposes. This check is used as a real-life test for your productive health endpoints. Check Depth Typically, tools performing simple health checks are not too smart. Therefore it is important to choose an endpoint for checking wisely. This check therefore only checks if the application/service url returns HTTP 200 . This is in line with health check capabilities of platforms which are used for example in load balancing scenarios. Here you can find an example for Amazon AWS .","title":"Description"},{"location":"steps/healthExecuteCheck/#prerequisites","text":"Endpoint for health check is configured. Warning The health endpoint needs to be available without authentication! Tip If using Spring Boot framework, ideally the provided /health endpoint is used and extended by development. Further information can be found in the Spring Boot documenation for Endpoints","title":"Prerequisites"},{"location":"steps/healthExecuteCheck/#parameters","text":"name mandatory default possible values healthEndpoint no `` script yes testServerUrl yes healthEndpoint - Optionally with healthEndpoint the health function is called if endpoint is not the standard url. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. testServerUrl - Health check function is called providing full qualified testServerUrl to the health check.","title":"Parameters"},{"location":"steps/healthExecuteCheck/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage healthEndpoint X script testServerUrl X","title":"Step configuration"},{"location":"steps/healthExecuteCheck/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/healthExecuteCheck/#example","text":"Pipeline step: healthExecuteCheck testServerUrl: 'https://testserver.com'","title":"Example"},{"location":"steps/influxWriteData/","text":"influxWriteData \u00b6 Description \u00b6 Since your Continuous Delivery Pipeline in Jenkins provides your productive development and delivery infrastructure you should monitor the pipeline to ensure it runs as expected. How to setup this monitoring is described in the following. You basically need three components: The InfluxDB Jenkins plugin which allows you to send build metrics to InfluxDB servers The InfluxDB to store this data (Docker available) A Grafana dashboard to visualize the data stored in InfluxDB (Docker available) no InfluxDB available? If you don't have an InfluxDB available yet this step will still provide you some benefit. It will create following files for you and archive them into your build: jenkins_data.json : This file gives you build-specific information, like e.g. build result, stage where the build failed influx_data.json : This file gives you detailed information about your pipeline, e.g. stage durations, steps executed, ... Prerequisites \u00b6 Setting up InfluxDB with Grafana \u00b6 The easiest way to start with is using the available official docker images. You can either run these docker containers on the same host on which you run your Jenkins or each docker on individual VMs (hosts). Very basic setup can be done like that (with user \"admin\" and password \"adminPwd\" for both InfluxDB and Grafana): docker run -d -p 8083:8083 -p 8086:8086 --restart=always --name influxdb -v /var/influx_data:/var/lib/influxdb influxdb docker run -d -p 3000:3000 --name grafana --restart=always --link influxdb:influxdb -e \"GF_SECURITY_ADMIN_PASSWORD=adminPwd\" grafana/grafana For more advanced setup please reach out to the respective documentation: InfluxDB ( Docker Hub GitHub ) Grafana ( Docker Hub GitHub ) After you have started your InfluxDB docker you need to create a database: in a Webbrowser open the InfluxDB Web-UI using the following URL: <host of your docker>:8083 (port 8083 is used for access via Web-UI, for Jenkins you use port 8086 to access the DB) create new DB (the name of this DB you need to provide later to Jenkins) create Admin user (this user you need to provide later to Jenkins) With InfluxDB version 1.1 the InfluxDB Web-UI is deprecated You can perform the above steps via commandline: The following command will create a database with name <databasename> curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE \\<databasename\\>\" The admin user with the name <adminusername> and the password <adminuserpwd> can be created with curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE USER \\<adminusername\\> WITH PASSWORD '\\<adminuserpwd\\>' WITH ALL PRIVILEGES\" Once you have started both docker containers and Influx and Grafana are running you need to configure the Jenkins Plugin according to your settings. Pipeline configuration \u00b6 To setup your Jenkins you need to do two configuration steps: Configure Jenkins (via Manage Jenkins) Adapt pipeline configuration Configure Jenkins \u00b6 Once the plugin is available in your Jenkins: go to \"Manage Jenkins\" > \"Configure System\" > scroll down to section \"influxdb target\" maintain Influx data Jenkins as a Service For Jenkins as a Service instances this is already preset to the local InfluxDB with the name jenkins . In this case there is not need to do any additional configuration. Adapt pipeline configuration \u00b6 You need to define the influxDB server in your pipeline as it is defined in the InfluxDb plugin configuration (see above). influxDBServer = jenkins Parameters \u00b6 name mandatory default possible values artifactVersion no customData no customDataMap no customDataMapTags no customDataTags no influxPrefix no influxServer no `` script yes wrapInNode no artifactVersion - Defines the version of the current artifact. Defaults to commonPipelineEnvironment.getArtifactVersion() customData - Defines custom data (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomData() customDataMap - Defines a map of measurement names containing custom data (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataMap() customDataMapTags - Defines a map of measurement names containing tags (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() customDataTags - Defines tags (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() influxPrefix - Defines a custom prefix. For example in multi branch pipelines, where every build is named after the branch built and thus you have different builds called 'master' that report different metrics. influxServer - Defines the name of the Influx server as configured in Jenkins global configuration. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. wrapInNode - Defines if a dedicated node/executor should be created in the pipeline run. This is especially relevant when running the step in a declarative POST stage where by default no executor is available. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactVersion X customData X customDataMap X customDataMapTags X customDataTags X influxPrefix X influxServer X script wrapInNode X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 influxWriteData script: this Work with InfluxDB and Grafana \u00b6 You can access your Grafana via Web-UI: <host of your grafana(-docker)>:<port3000> (or another port in case you have defined another one when starting your docker) As a first step you need to add your InfluxDB as Data source to your Grafana: Login as user admin (PW as defined when starting your docker) in the navigation go to data sources -> add data source: name type: InfluxDB Url: http://<host of your InfluxDB server>:<port> Access: direct (not via proxy) database: <name of the DB as specified above> User: <name of the admin user as specified in step above> Password: <password of the admin user as specified in step above> Jenkins as a Service For Jenkins as a Service the data source configuration is already available. Therefore no need to go through the data source configuration step unless you want to add addtional data sources. Data collected in InfluxDB \u00b6 The Influx plugin collects following data in the Piper context: All data as per default InfluxDB plugin capabilities Additional data collected via InfluxData.addField(measurement, key, value) Add custom information to your InfluxDB You can simply add custom data collected during your pipeline runs via available data objects. Example: //add data to measurement jenkins_custom_data - value can be a String or a Number commonPipelineEnvironment . setInfluxCustomDataProperty ( 'myProperty' , 2018 ) Collected InfluxDB measurements \u00b6 Measurements are potentially pre-fixed - see parameter influxPrefix above. Measurement name data column description All measurements build_number project_name All below measurements will have these columns. Details see InfluxDB plugin documentation jenkins_data build_result build_time last_successful_build tests_failed tests_skipped tests_total ... Details see InfluxDB plugin documentation cobertura_data cobertura_branch_coverage_rate cobertura_class_coverage_rate cobertura_line_coverage_rate cobertura_package_coverage_rate ... Details see InfluxDB plugin documentation jacoco_data jacoco_branch_coverage_rate jacoco_class_coverage_rate jacoco_instruction_coverage_rate jacoco_line_coverage_rate jacoco_method_coverage_rate Details see InfluxDB plugin documentation performance_data 90Percentile average max median min error_count error_percent ... Details see InfluxDB plugin documentation sonarqube_data blocker_issues critical_issues info_issues major_issues minor_issues lines_of_code ... Details see InfluxDB plugin documentation jenkins_custom_data Piper fills following colums by default: build_result build_result_key build_step (->step in case of error) build_error (->error message in case of error) filled by commonPipelineEnvironment.setInfluxCustomDataProperty() pipeline_data Examples from the Piper templates: build_duration opa_duration deploy_test_duration deploy_test_duration fortify_duration release_duration ... filled by step measureDuration using parameter measurementName step_data Considered, e.g.: build_url bats checkmarx fortify gauge nsp snyk sonar ... filled by InfluxData.addField('step_data', key, value) Examples for InfluxDB queries which can be used in Grafana \u00b6 Project Names containing dashes (-) The InfluxDB plugin replaces dashes (-) with underscores (_). Please keep this in mind when specifying your project_name for a InfluxDB query. Example 1: Select last 10 successful builds \u00b6 select top ( build_number , 10 ), build_result from jenkins_data WHERE build_result = 'SUCCESS' Example 2: Select last 10 step names of failed builds \u00b6 select top ( build_number , 10 ), build_result , build_step from jenkins_custom_data WHERE build_result = 'FAILURE' Example 3: Select build duration of step for a specific project \u00b6 select build_duration / 1000 from \"pipeline_data\" WHERE project_name = 'PiperTestOrg_piper_test_master' Example 4: Get transparency about successful/failed steps for a specific project \u00b6 select top ( build_number , 10 ) AS \"Build\" , build_url , build_quality , fortify , gauge , vulas , opa from step_data WHERE project_name = 'PiperTestOrg_piper_test_master' Note With this query you can create transparency about which steps ran successfully / not successfully in your pipeline and which ones were not executed at all. By specifying all the steps you consider relevant in your select statement it is very easy to create this transparency.","title":"influxWriteData"},{"location":"steps/influxWriteData/#influxwritedata","text":"","title":"influxWriteData"},{"location":"steps/influxWriteData/#description","text":"Since your Continuous Delivery Pipeline in Jenkins provides your productive development and delivery infrastructure you should monitor the pipeline to ensure it runs as expected. How to setup this monitoring is described in the following. You basically need three components: The InfluxDB Jenkins plugin which allows you to send build metrics to InfluxDB servers The InfluxDB to store this data (Docker available) A Grafana dashboard to visualize the data stored in InfluxDB (Docker available) no InfluxDB available? If you don't have an InfluxDB available yet this step will still provide you some benefit. It will create following files for you and archive them into your build: jenkins_data.json : This file gives you build-specific information, like e.g. build result, stage where the build failed influx_data.json : This file gives you detailed information about your pipeline, e.g. stage durations, steps executed, ...","title":"Description"},{"location":"steps/influxWriteData/#prerequisites","text":"","title":"Prerequisites"},{"location":"steps/influxWriteData/#setting-up-influxdb-with-grafana","text":"The easiest way to start with is using the available official docker images. You can either run these docker containers on the same host on which you run your Jenkins or each docker on individual VMs (hosts). Very basic setup can be done like that (with user \"admin\" and password \"adminPwd\" for both InfluxDB and Grafana): docker run -d -p 8083:8083 -p 8086:8086 --restart=always --name influxdb -v /var/influx_data:/var/lib/influxdb influxdb docker run -d -p 3000:3000 --name grafana --restart=always --link influxdb:influxdb -e \"GF_SECURITY_ADMIN_PASSWORD=adminPwd\" grafana/grafana For more advanced setup please reach out to the respective documentation: InfluxDB ( Docker Hub GitHub ) Grafana ( Docker Hub GitHub ) After you have started your InfluxDB docker you need to create a database: in a Webbrowser open the InfluxDB Web-UI using the following URL: <host of your docker>:8083 (port 8083 is used for access via Web-UI, for Jenkins you use port 8086 to access the DB) create new DB (the name of this DB you need to provide later to Jenkins) create Admin user (this user you need to provide later to Jenkins) With InfluxDB version 1.1 the InfluxDB Web-UI is deprecated You can perform the above steps via commandline: The following command will create a database with name <databasename> curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE \\<databasename\\>\" The admin user with the name <adminusername> and the password <adminuserpwd> can be created with curl -i -XPOST http://localhost:8086/query --data-urlencode \"q=CREATE USER \\<adminusername\\> WITH PASSWORD '\\<adminuserpwd\\>' WITH ALL PRIVILEGES\" Once you have started both docker containers and Influx and Grafana are running you need to configure the Jenkins Plugin according to your settings.","title":"Setting up InfluxDB with Grafana"},{"location":"steps/influxWriteData/#pipeline-configuration","text":"To setup your Jenkins you need to do two configuration steps: Configure Jenkins (via Manage Jenkins) Adapt pipeline configuration","title":"Pipeline configuration"},{"location":"steps/influxWriteData/#configure-jenkins","text":"Once the plugin is available in your Jenkins: go to \"Manage Jenkins\" > \"Configure System\" > scroll down to section \"influxdb target\" maintain Influx data Jenkins as a Service For Jenkins as a Service instances this is already preset to the local InfluxDB with the name jenkins . In this case there is not need to do any additional configuration.","title":"Configure Jenkins"},{"location":"steps/influxWriteData/#adapt-pipeline-configuration","text":"You need to define the influxDB server in your pipeline as it is defined in the InfluxDb plugin configuration (see above). influxDBServer = jenkins","title":"Adapt pipeline configuration"},{"location":"steps/influxWriteData/#parameters","text":"name mandatory default possible values artifactVersion no customData no customDataMap no customDataMapTags no customDataTags no influxPrefix no influxServer no `` script yes wrapInNode no artifactVersion - Defines the version of the current artifact. Defaults to commonPipelineEnvironment.getArtifactVersion() customData - Defines custom data (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomData() customDataMap - Defines a map of measurement names containing custom data (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataMap() customDataMapTags - Defines a map of measurement names containing tags (map of key-value pairs) to be written to Influx. Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() customDataTags - Defines tags (map of key-value pairs) to be written to Influx into measurement jenkins_custom_data . Defaults to commonPipelineEnvironment.getInfluxCustomDataTags() influxPrefix - Defines a custom prefix. For example in multi branch pipelines, where every build is named after the branch built and thus you have different builds called 'master' that report different metrics. influxServer - Defines the name of the Influx server as configured in Jenkins global configuration. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. wrapInNode - Defines if a dedicated node/executor should be created in the pipeline run. This is especially relevant when running the step in a declarative POST stage where by default no executor is available.","title":"Parameters"},{"location":"steps/influxWriteData/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage artifactVersion X customData X customDataMap X customDataMapTags X customDataTags X influxPrefix X influxServer X script wrapInNode X","title":"Step configuration"},{"location":"steps/influxWriteData/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/influxWriteData/#example","text":"influxWriteData script: this","title":"Example"},{"location":"steps/influxWriteData/#work-with-influxdb-and-grafana","text":"You can access your Grafana via Web-UI: <host of your grafana(-docker)>:<port3000> (or another port in case you have defined another one when starting your docker) As a first step you need to add your InfluxDB as Data source to your Grafana: Login as user admin (PW as defined when starting your docker) in the navigation go to data sources -> add data source: name type: InfluxDB Url: http://<host of your InfluxDB server>:<port> Access: direct (not via proxy) database: <name of the DB as specified above> User: <name of the admin user as specified in step above> Password: <password of the admin user as specified in step above> Jenkins as a Service For Jenkins as a Service the data source configuration is already available. Therefore no need to go through the data source configuration step unless you want to add addtional data sources.","title":"Work with InfluxDB and Grafana"},{"location":"steps/influxWriteData/#data-collected-in-influxdb","text":"The Influx plugin collects following data in the Piper context: All data as per default InfluxDB plugin capabilities Additional data collected via InfluxData.addField(measurement, key, value) Add custom information to your InfluxDB You can simply add custom data collected during your pipeline runs via available data objects. Example: //add data to measurement jenkins_custom_data - value can be a String or a Number commonPipelineEnvironment . setInfluxCustomDataProperty ( 'myProperty' , 2018 )","title":"Data collected in InfluxDB"},{"location":"steps/influxWriteData/#collected-influxdb-measurements","text":"Measurements are potentially pre-fixed - see parameter influxPrefix above. Measurement name data column description All measurements build_number project_name All below measurements will have these columns. Details see InfluxDB plugin documentation jenkins_data build_result build_time last_successful_build tests_failed tests_skipped tests_total ... Details see InfluxDB plugin documentation cobertura_data cobertura_branch_coverage_rate cobertura_class_coverage_rate cobertura_line_coverage_rate cobertura_package_coverage_rate ... Details see InfluxDB plugin documentation jacoco_data jacoco_branch_coverage_rate jacoco_class_coverage_rate jacoco_instruction_coverage_rate jacoco_line_coverage_rate jacoco_method_coverage_rate Details see InfluxDB plugin documentation performance_data 90Percentile average max median min error_count error_percent ... Details see InfluxDB plugin documentation sonarqube_data blocker_issues critical_issues info_issues major_issues minor_issues lines_of_code ... Details see InfluxDB plugin documentation jenkins_custom_data Piper fills following colums by default: build_result build_result_key build_step (->step in case of error) build_error (->error message in case of error) filled by commonPipelineEnvironment.setInfluxCustomDataProperty() pipeline_data Examples from the Piper templates: build_duration opa_duration deploy_test_duration deploy_test_duration fortify_duration release_duration ... filled by step measureDuration using parameter measurementName step_data Considered, e.g.: build_url bats checkmarx fortify gauge nsp snyk sonar ... filled by InfluxData.addField('step_data', key, value)","title":"Collected InfluxDB measurements"},{"location":"steps/influxWriteData/#examples-for-influxdb-queries-which-can-be-used-in-grafana","text":"Project Names containing dashes (-) The InfluxDB plugin replaces dashes (-) with underscores (_). Please keep this in mind when specifying your project_name for a InfluxDB query.","title":"Examples for InfluxDB queries which can be used in Grafana"},{"location":"steps/influxWriteData/#example-1-select-last-10-successful-builds","text":"select top ( build_number , 10 ), build_result from jenkins_data WHERE build_result = 'SUCCESS'","title":"Example 1: Select last 10 successful builds"},{"location":"steps/influxWriteData/#example-2-select-last-10-step-names-of-failed-builds","text":"select top ( build_number , 10 ), build_result , build_step from jenkins_custom_data WHERE build_result = 'FAILURE'","title":"Example 2: Select last 10 step names of failed builds"},{"location":"steps/influxWriteData/#example-3-select-build-duration-of-step-for-a-specific-project","text":"select build_duration / 1000 from \"pipeline_data\" WHERE project_name = 'PiperTestOrg_piper_test_master'","title":"Example 3: Select build duration of step for a specific project"},{"location":"steps/influxWriteData/#example-4-get-transparency-about-successfulfailed-steps-for-a-specific-project","text":"select top ( build_number , 10 ) AS \"Build\" , build_url , build_quality , fortify , gauge , vulas , opa from step_data WHERE project_name = 'PiperTestOrg_piper_test_master' Note With this query you can create transparency about which steps ran successfully / not successfully in your pipeline and which ones were not executed at all. By specifying all the steps you consider relevant in your select statement it is very easy to create this transparency.","title":"Example 4: Get transparency about successful/failed steps for a specific project"},{"location":"steps/kanikoExecute/","text":"kanikoExecute \u00b6 Description \u00b6 Executes a Kaniko build for creating a Docker container. Prerequsites \u00b6 When pushing to a container registry, you need to maintain the respective credentials in your Jenkins credentials store: Kaniko expects a Docker config.json file containing the credential information for registries. You can create it like explained in the Docker Success Center in the articale about How to generate a new auth in the config.json file . Please copy this file and upload it to your Jenkins for example via Jenkins -> Credentials -> System -> Global credentials (unrestricted) -> Add Credentials -> Kind: Secret file File: upload your config.json file ID: specify id which you then use for the configuration of dockerConfigJsonCredentialsId (see below) Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 kanikoExecute script: this Parameters \u00b6 name mandatory default possible values containerBuildOptions no --skip-tls-verify-pull containerCommand no /busybox/tail -f /dev/null containerImageNameAndTag no containerPreparationCommand no rm /kaniko/.docker/config.json containerShell no /busybox/sh customTlsCertificateLinks no [] dockerConfigJsonCredentialsId no dockerEnvVars no dockerImage no gcr.io/kaniko-project/executor:debug dockerOptions no -u 0 --entrypoint='' dockerfile no Dockerfile script yes containerBuildOptions - Defines the build options for the kaniko build. containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerImageNameAndTag - Defines the full name of the Docker image to be created including registry, image name and tag like my.docker.registry/path/myImageName:myTag . containerPreparationCommand - Defines the command to prepare the Kaniko container. By default the contained credentials are removed in order to allow anonymous access to container registries. containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. customTlsCertificateLinks - List containing download links of custom TLS certificates. This is required to ensure trusted connections to registries with custom certificates. dockerConfigJsonCredentialsId - Defines the id of the file credentials in your Jenkins credentials store which contain the file .docker/config.json . You can find more details about the Docker credentials in the Docker documentation . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). dockerfile - Defines the location of the Dockerfile relative to the Jenkins workspace. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerBuildOptions X containerCommand X containerImageNameAndTag X containerPreparationCommand X containerShell X customTlsCertificateLinks X dockerConfigJsonCredentialsId X dockerEnvVars X dockerImage X dockerOptions X dockerfile X script","title":"kanikoExecute"},{"location":"steps/kanikoExecute/#kanikoexecute","text":"","title":"kanikoExecute"},{"location":"steps/kanikoExecute/#description","text":"Executes a Kaniko build for creating a Docker container.","title":"Description"},{"location":"steps/kanikoExecute/#prerequsites","text":"When pushing to a container registry, you need to maintain the respective credentials in your Jenkins credentials store: Kaniko expects a Docker config.json file containing the credential information for registries. You can create it like explained in the Docker Success Center in the articale about How to generate a new auth in the config.json file . Please copy this file and upload it to your Jenkins for example via Jenkins -> Credentials -> System -> Global credentials (unrestricted) -> Add Credentials -> Kind: Secret file File: upload your config.json file ID: specify id which you then use for the configuration of dockerConfigJsonCredentialsId (see below)","title":"Prerequsites"},{"location":"steps/kanikoExecute/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/kanikoExecute/#example","text":"kanikoExecute script: this","title":"Example"},{"location":"steps/kanikoExecute/#parameters","text":"name mandatory default possible values containerBuildOptions no --skip-tls-verify-pull containerCommand no /busybox/tail -f /dev/null containerImageNameAndTag no containerPreparationCommand no rm /kaniko/.docker/config.json containerShell no /busybox/sh customTlsCertificateLinks no [] dockerConfigJsonCredentialsId no dockerEnvVars no dockerImage no gcr.io/kaniko-project/executor:debug dockerOptions no -u 0 --entrypoint='' dockerfile no Dockerfile script yes containerBuildOptions - Defines the build options for the kaniko build. containerCommand - Kubernetes only: Allows to specify start command for container created with dockerImage parameter to overwrite Piper default ( /usr/bin/tail -f /dev/null ). containerImageNameAndTag - Defines the full name of the Docker image to be created including registry, image name and tag like my.docker.registry/path/myImageName:myTag . containerPreparationCommand - Defines the command to prepare the Kaniko container. By default the contained credentials are removed in order to allow anonymous access to container registries. containerShell - Kubernetes only: Allows to specify the shell to be used for execution of commands. customTlsCertificateLinks - List containing download links of custom TLS certificates. This is required to ensure trusted connections to registries with custom certificates. dockerConfigJsonCredentialsId - Defines the id of the file credentials in your Jenkins credentials store which contain the file .docker/config.json . You can find more details about the Docker credentials in the Docker documentation . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). dockerfile - Defines the location of the Dockerfile relative to the Jenkins workspace. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/kanikoExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerBuildOptions X containerCommand X containerImageNameAndTag X containerPreparationCommand X containerShell X customTlsCertificateLinks X dockerConfigJsonCredentialsId X dockerEnvVars X dockerImage X dockerOptions X dockerfile X script","title":"Step configuration"},{"location":"steps/karmaExecuteTests/","text":"karmaExecuteTests \u00b6 Description \u00b6 In this step the ( Karma test runner ) is executed. The step is using the seleniumExecuteTest step to spin up two containers in a Docker network: a Selenium/Chrome container ( selenium/standalone-chrome ) a NodeJS container ( node:8-stretch ) In the Docker network, the containers can be referenced by the values provided in dockerName and sidecarName , the default values are karma and selenium . These values must be used in the hostname properties of the test configuration ( Karma and WebDriver ). Note In a Kubernetes environment, the containers both need to be referenced with localhost . Prerequisites \u00b6 running Karma tests - have a NPM module with running tests executed with Karma configured WebDriver - have the karma-webdriver-launcher package installed and a custom, WebDriver-based browser configured in Karma Dependencies \u00b6 The step depends on the following Jenkins plugins git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Parameters \u00b6 name mandatory default possible values containerPortMappings no [node:8-stretch:[[containerPort:9876, hostPort:9876]]] dockerEnvVars no [NO_PROXY:localhost,selenium,$NO_PROXY, no_proxy:localhost,selenium,$no_proxy] dockerImage no node:8-stretch dockerName no karma dockerWorkspace no /home/node failOnError no true , false installCommand no npm install --quiet modules no [.] runCommand no npm run karma script yes sidecarEnvVars no [NO_PROXY:localhost,karma,$NO_PROXY, no_proxy:localhost,karma,$no_proxy] sidecarImage no sidecarName no sidecarVolumeBind no stashContent no [buildDescriptor, tests] containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - A map of environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - The name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. installCommand - The command that is executed to install the test tool. modules - Define the paths of the modules to execute tests on. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - A map of environment variables to set in the sidecar container, similar to dockerEnvVars . sidecarImage - The name of the docker image of the sidecar container. If empty, no sidecar container is started. sidecarName - as dockerName for the sidecar container sidecarVolumeBind - Volumes that should be mounted into the sidecar container. stashContent - If specific stashes should be considered for the tests, their names need to be passed via the parameter stashContent . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerWorkspace X X failOnError X X installCommand X X modules X X runCommand X X script sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X Side effects \u00b6 Step uses seleniumExecuteTest & dockerExecute inside. Exceptions \u00b6 none Example \u00b6 karmaExecuteTests script: this , modules: [ './shoppinglist' , './catalog' ]","title":"karmaExecuteTests"},{"location":"steps/karmaExecuteTests/#karmaexecutetests","text":"","title":"karmaExecuteTests"},{"location":"steps/karmaExecuteTests/#description","text":"In this step the ( Karma test runner ) is executed. The step is using the seleniumExecuteTest step to spin up two containers in a Docker network: a Selenium/Chrome container ( selenium/standalone-chrome ) a NodeJS container ( node:8-stretch ) In the Docker network, the containers can be referenced by the values provided in dockerName and sidecarName , the default values are karma and selenium . These values must be used in the hostname properties of the test configuration ( Karma and WebDriver ). Note In a Kubernetes environment, the containers both need to be referenced with localhost .","title":"Description"},{"location":"steps/karmaExecuteTests/#prerequisites","text":"running Karma tests - have a NPM module with running tests executed with Karma configured WebDriver - have the karma-webdriver-launcher package installed and a custom, WebDriver-based browser configured in Karma","title":"Prerequisites"},{"location":"steps/karmaExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/karmaExecuteTests/#parameters","text":"name mandatory default possible values containerPortMappings no [node:8-stretch:[[containerPort:9876, hostPort:9876]]] dockerEnvVars no [NO_PROXY:localhost,selenium,$NO_PROXY, no_proxy:localhost,selenium,$no_proxy] dockerImage no node:8-stretch dockerName no karma dockerWorkspace no /home/node failOnError no true , false installCommand no npm install --quiet modules no [.] runCommand no npm run karma script yes sidecarEnvVars no [NO_PROXY:localhost,karma,$NO_PROXY, no_proxy:localhost,karma,$no_proxy] sidecarImage no sidecarName no sidecarVolumeBind no stashContent no [buildDescriptor, tests] containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - A map of environment variables to set in the container, e.g. [http_proxy:'proxy:8080']. dockerImage - The name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. installCommand - The command that is executed to install the test tool. modules - Define the paths of the modules to execute tests on. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - A map of environment variables to set in the sidecar container, similar to dockerEnvVars . sidecarImage - The name of the docker image of the sidecar container. If empty, no sidecar container is started. sidecarName - as dockerName for the sidecar container sidecarVolumeBind - Volumes that should be mounted into the sidecar container. stashContent - If specific stashes should be considered for the tests, their names need to be passed via the parameter stashContent .","title":"Parameters"},{"location":"steps/karmaExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerWorkspace X X failOnError X X installCommand X X modules X X runCommand X X script sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X","title":"Step configuration"},{"location":"steps/karmaExecuteTests/#side-effects","text":"Step uses seleniumExecuteTest & dockerExecute inside.","title":"Side effects"},{"location":"steps/karmaExecuteTests/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/karmaExecuteTests/#example","text":"karmaExecuteTests script: this , modules: [ './shoppinglist' , './catalog' ]","title":"Example"},{"location":"steps/mailSendNotification/","text":"mailSendNotification \u00b6 Description \u00b6 Sends notifications to all potential culprits of a current or previous build failure and to fixed list of recipients. It will attach the current build log to the email. Notifications are sent in following cases: current build failed or is unstable current build is successful and previous build failed or was unstable Prerequsites \u00b6 none Example \u00b6 Usage of pipeline step: mailSendNotification script: this Parameters \u00b6 name mandatory default possible values buildResult no gitCommitId no gitSshKeyCredentialsId no `` Jenkins credentials id gitUrl no notificationAttachment no true true , false notificationRecipients no notifyCulprits no true true , false numLogLinesInBody no 100 projectName no script yes wrapInNode no false true , false buildResult - Set the build result used to determine the mail template. default currentBuild.result gitCommitId - Only if notifyCulprits is set: Defines a dedicated git commitId for culprit retrieval. default commonPipelineEnvironment.getGitCommitId() gitSshKeyCredentialsId - Only if notifyCulprits is set: Credentials if the repository is protected. gitUrl - Only if notifyCulprits is set: Repository url used to retrieve culprit information. default commonPipelineEnvironment.getGitSshUrl() notificationAttachment - defines if the console log file should be attached to the notification mail. notificationRecipients - A space-separated list of recipients that always get the notification. notifyCulprits - Notify all committers since the last successful build. numLogLinesInBody - Number of log line which are included in the email body. projectName - The project name used in the email subject. default currentBuild.fullProjectName script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. wrapInNode - Needs to be set to true if step is used outside of a node context, e.g. post actions in a declarative pipeline script. default false Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildResult X gitCommitId X gitSshKeyCredentialsId X X gitUrl X notificationAttachment X notificationRecipients X notifyCulprits X numLogLinesInBody X projectName X script wrapInNode X Dependencies \u00b6 The step depends on the following Jenkins plugins email-ext pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none","title":"mailSendNotification"},{"location":"steps/mailSendNotification/#mailsendnotification","text":"","title":"mailSendNotification"},{"location":"steps/mailSendNotification/#description","text":"Sends notifications to all potential culprits of a current or previous build failure and to fixed list of recipients. It will attach the current build log to the email. Notifications are sent in following cases: current build failed or is unstable current build is successful and previous build failed or was unstable","title":"Description"},{"location":"steps/mailSendNotification/#prerequsites","text":"none","title":"Prerequsites"},{"location":"steps/mailSendNotification/#example","text":"Usage of pipeline step: mailSendNotification script: this","title":"Example"},{"location":"steps/mailSendNotification/#parameters","text":"name mandatory default possible values buildResult no gitCommitId no gitSshKeyCredentialsId no `` Jenkins credentials id gitUrl no notificationAttachment no true true , false notificationRecipients no notifyCulprits no true true , false numLogLinesInBody no 100 projectName no script yes wrapInNode no false true , false buildResult - Set the build result used to determine the mail template. default currentBuild.result gitCommitId - Only if notifyCulprits is set: Defines a dedicated git commitId for culprit retrieval. default commonPipelineEnvironment.getGitCommitId() gitSshKeyCredentialsId - Only if notifyCulprits is set: Credentials if the repository is protected. gitUrl - Only if notifyCulprits is set: Repository url used to retrieve culprit information. default commonPipelineEnvironment.getGitSshUrl() notificationAttachment - defines if the console log file should be attached to the notification mail. notificationRecipients - A space-separated list of recipients that always get the notification. notifyCulprits - Notify all committers since the last successful build. numLogLinesInBody - Number of log line which are included in the email body. projectName - The project name used in the email subject. default currentBuild.fullProjectName script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. wrapInNode - Needs to be set to true if step is used outside of a node context, e.g. post actions in a declarative pipeline script. default false","title":"Parameters"},{"location":"steps/mailSendNotification/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildResult X gitCommitId X gitSshKeyCredentialsId X X gitUrl X notificationAttachment X notificationRecipients X notifyCulprits X numLogLinesInBody X projectName X script wrapInNode X","title":"Step configuration"},{"location":"steps/mailSendNotification/#dependencies","text":"The step depends on the following Jenkins plugins email-ext pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/mailSendNotification/#side-effects","text":"none","title":"Side effects"},{"location":"steps/mailSendNotification/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/mavenExecute/","text":"mavenExecute \u00b6 Description \u00b6 Executes a maven command inside a Docker container. Parameters \u00b6 name mandatory default possible values defines no dockerImage no maven:3.5-jdk-7 dockerOptions no flags no globalSettingsFile no goals no logSuccessfulMavenTransfers no false true , false m2Path no pomPath no projectSettingsFile no script yes defines - Additional properties. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). flags - Flags to provide when running mvn. globalSettingsFile - Path or url to the mvn settings file that should be used as global settings file. goals - Maven goals that should be executed. logSuccessfulMavenTransfers - Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. m2Path - Path to the location of the local repository that should be used. pomPath - Path to the pom file that should be used. projectSettingsFile - Path or url to the mvn settings file that should be used as project settings file. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defines dockerImage X dockerOptions flags globalSettingsFile X goals logSuccessfulMavenTransfers m2Path X pomPath X projectSettingsFile X script Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 None Example \u00b6 mavenExecute script: this , goals: 'clean install'","title":"mavenExecute"},{"location":"steps/mavenExecute/#mavenexecute","text":"","title":"mavenExecute"},{"location":"steps/mavenExecute/#description","text":"Executes a maven command inside a Docker container.","title":"Description"},{"location":"steps/mavenExecute/#parameters","text":"name mandatory default possible values defines no dockerImage no maven:3.5-jdk-7 dockerOptions no flags no globalSettingsFile no goals no logSuccessfulMavenTransfers no false true , false m2Path no pomPath no projectSettingsFile no script yes defines - Additional properties. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). flags - Flags to provide when running mvn. globalSettingsFile - Path or url to the mvn settings file that should be used as global settings file. goals - Maven goals that should be executed. logSuccessfulMavenTransfers - Configures maven to log successful downloads. This is set to false by default to reduce the noise in build logs. m2Path - Path to the location of the local repository that should be used. pomPath - Path to the pom file that should be used. projectSettingsFile - Path or url to the mvn settings file that should be used as project settings file. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/mavenExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defines dockerImage X dockerOptions flags globalSettingsFile X goals logSuccessfulMavenTransfers m2Path X pomPath X projectSettingsFile X script","title":"Step configuration"},{"location":"steps/mavenExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/mavenExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/mavenExecute/#example","text":"mavenExecute script: this , goals: 'clean install'","title":"Example"},{"location":"steps/mtaBuild/","text":"mtaBuild \u00b6 Description \u00b6 Executes the SAP Multitarget Application Archive Builder to create an mtar archive of the application. Prerequisites \u00b6 While using a custom docker file, ensure that the following tools are installed: SAP MTA Archive Builder 1.0.6 or compatible version - can be downloaded from SAP Development Tools . Java 8 or compatible version - necessary to run the MTA Archive Builder itself and to build Java modules. NodeJS installed - the MTA Builder uses npm to download node module dependencies such as grunt . Parameters \u00b6 name mandatory default possible values applicationName no buildTarget no NEO 'CF', 'NEO', 'XSA' defaultNpmRegistry no dockerImage no ppiper/mta-archive-builder dockerOptions no extension no globalSettingsFile no mtaJarLocation no /opt/sap/mta/lib/mta.jar projectSettingsFile no script yes applicationName - The name of the application which is being built. If the parameter has been provided and no mta.yaml exists, the mta.yaml will be automatically generated using this parameter and the information ( name and version ) from package.json before the actual build starts. buildTarget - The target platform to which the mtar can be deployed. defaultNpmRegistry - Url to the npm registry that should be used for installing npm dependencies. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). extension - The path to the extension descriptor file. globalSettingsFile - Path or url to the mvn settings file that should be used as global settings file. mtaJarLocation - The location of the SAP Multitarget Application Archive Builder jar file, including file name and extension. If it is not provided, the SAP Multitarget Application Archive Builder is expected on PATH. projectSettingsFile - Path or url to the mvn settings file that should be used as project settings file. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage applicationName X buildTarget X defaultNpmRegistry dockerImage X dockerOptions extension X globalSettingsFile X mtaJarLocation X projectSettingsFile X script Dependencies \u00b6 The step depends on the following Jenkins plugins docker http_request kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 The file name of the resulting archive is written to the commonPipelineEnvironment with variable name mtarFileName . Exceptions \u00b6 AbortException : If there is an invalid buildTarget . If there is no key ID inside the mta.yaml file. Example \u00b6 dir ( '/path/to/FioriApp' ){ mtaBuild script: this , buildTarget: 'NEO' } def mtarFilePath = commonPipelineEnvironment . getMtarFilePath ()","title":"mtaBuild"},{"location":"steps/mtaBuild/#mtabuild","text":"","title":"mtaBuild"},{"location":"steps/mtaBuild/#description","text":"Executes the SAP Multitarget Application Archive Builder to create an mtar archive of the application.","title":"Description"},{"location":"steps/mtaBuild/#prerequisites","text":"While using a custom docker file, ensure that the following tools are installed: SAP MTA Archive Builder 1.0.6 or compatible version - can be downloaded from SAP Development Tools . Java 8 or compatible version - necessary to run the MTA Archive Builder itself and to build Java modules. NodeJS installed - the MTA Builder uses npm to download node module dependencies such as grunt .","title":"Prerequisites"},{"location":"steps/mtaBuild/#parameters","text":"name mandatory default possible values applicationName no buildTarget no NEO 'CF', 'NEO', 'XSA' defaultNpmRegistry no dockerImage no ppiper/mta-archive-builder dockerOptions no extension no globalSettingsFile no mtaJarLocation no /opt/sap/mta/lib/mta.jar projectSettingsFile no script yes applicationName - The name of the application which is being built. If the parameter has been provided and no mta.yaml exists, the mta.yaml will be automatically generated using this parameter and the information ( name and version ) from package.json before the actual build starts. buildTarget - The target platform to which the mtar can be deployed. defaultNpmRegistry - Url to the npm registry that should be used for installing npm dependencies. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). extension - The path to the extension descriptor file. globalSettingsFile - Path or url to the mvn settings file that should be used as global settings file. mtaJarLocation - The location of the SAP Multitarget Application Archive Builder jar file, including file name and extension. If it is not provided, the SAP Multitarget Application Archive Builder is expected on PATH. projectSettingsFile - Path or url to the mvn settings file that should be used as project settings file. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/mtaBuild/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage applicationName X buildTarget X defaultNpmRegistry dockerImage X dockerOptions extension X globalSettingsFile X mtaJarLocation X projectSettingsFile X script","title":"Step configuration"},{"location":"steps/mtaBuild/#dependencies","text":"The step depends on the following Jenkins plugins docker http_request kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/mtaBuild/#side-effects","text":"The file name of the resulting archive is written to the commonPipelineEnvironment with variable name mtarFileName .","title":"Side effects"},{"location":"steps/mtaBuild/#exceptions","text":"AbortException : If there is an invalid buildTarget . If there is no key ID inside the mta.yaml file.","title":"Exceptions"},{"location":"steps/mtaBuild/#example","text":"dir ( '/path/to/FioriApp' ){ mtaBuild script: this , buildTarget: 'NEO' } def mtarFilePath = commonPipelineEnvironment . getMtarFilePath ()","title":"Example"},{"location":"steps/multicloudDeploy/","text":"multicloudDeploy \u00b6 Parameters \u00b6 name mandatory default possible values cfTargets no enableZeroDowntimeDeployment no neoTargets no script yes source yes stage no cfTargets - Defines the targets to deploy on cloudFoundry. enableZeroDowntimeDeployment - Defines the deployment type. neoTargets - Defines the targets to deploy on neo. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The source file to deploy to the SAP Cloud Platform. stage - The stage name. If the stage name is not provided, it will be taken from the environment variable 'STAGE_NAME'. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cfTargets X enableZeroDowntimeDeployment neoTargets X script source stage Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Examples \u00b6 multicloudDeploy ( script: script , cfTargets: [[ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ]], neoTargets: [[ credentialsId: 'my-credentials-id' , host: hana . example . org , account: 'trialuser1' ]], enableZeroDowntimeDeployment: 'true' )","title":"multicloudDeploy"},{"location":"steps/multicloudDeploy/#multiclouddeploy","text":"","title":"multicloudDeploy"},{"location":"steps/multicloudDeploy/#parameters","text":"name mandatory default possible values cfTargets no enableZeroDowntimeDeployment no neoTargets no script yes source yes stage no cfTargets - Defines the targets to deploy on cloudFoundry. enableZeroDowntimeDeployment - Defines the deployment type. neoTargets - Defines the targets to deploy on neo. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The source file to deploy to the SAP Cloud Platform. stage - The stage name. If the stage name is not provided, it will be taken from the environment variable 'STAGE_NAME'.","title":"Parameters"},{"location":"steps/multicloudDeploy/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cfTargets X enableZeroDowntimeDeployment neoTargets X script source stage","title":"Step configuration"},{"location":"steps/multicloudDeploy/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/multicloudDeploy/#examples","text":"multicloudDeploy ( script: script , cfTargets: [[ apiEndpoint: 'https://test.server.com' , appName: 'cfAppName' , credentialsId: 'cfCredentialsId' , manifest: 'cfManifest' , org: 'cfOrg' , space: 'cfSpace' ]], neoTargets: [[ credentialsId: 'my-credentials-id' , host: hana . example . org , account: 'trialuser1' ]], enableZeroDowntimeDeployment: 'true' )","title":"Examples"},{"location":"steps/neoDeploy/","text":"neoDeploy \u00b6 Description \u00b6 Deploys an Application to SAP Cloud Platform (SAP CP) using the SAP Cloud Platform Console Client (Neo Java Web SDK). Prerequisites \u00b6 SAP CP account - the account to where the application is deployed. SAP CP user for deployment - a user with deployment permissions in the given account. Jenkins credentials for deployment - must be configured in Jenkins credentials with a dedicated Id. Neo Java Web SDK 3.39.10 or compatible version - can be downloaded from Maven Central . This step is capable of triggering the neo deploy tool provided inside a docker image. We provide docker image ppiper/neo-cli . neo.sh needs to be contained in path, e.g by adding a symbolic link to /usr/local/bin . Java 8 or compatible version - needed by the Neo-Java-Web-SDK . Java environment needs to be properly configured (JAVA_HOME, java exectutable contained in path). Parameters \u00b6 name mandatory default possible values deployMode no mta 'mta', 'warParams', 'warPropertiesFile' dockerEnvVars no dockerImage no s4sdk/docker-neo-cli dockerOptions no extensions no [] neo/account for deployMode=warParams neo/application for deployMode=warParams neo/credentialsId no CI_CREDENTIALS_ID neo/environment no neo/host for deployMode=warParams neo/propertiesFile for deployMode=warPropertiesFile neo/runtime for deployMode=warParams neo/runtimeVersion for deployMode=warParams neo/size no lite neo/vmArguments no script yes source yes warAction no deploy 'deploy', 'rolling-update' deployMode - The deployment mode which should be used. Available options are: 'mta' - default, 'warParams' - deploying WAR file and passing all the deployment parameters via the function call, * 'warPropertiesFile' - deploying WAR file and putting all the deployment parameters in a .properties file. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). extensions - Extension files. Provided to the neo command via parameter --extensions ( -e ). Only valid for deploy mode mta . neo/account - The SAP Cloud Platform account to deploy to. neo/application - Name of the application you want to manage, configure, or deploy. neo/credentialsId - The Jenkins credentials containing user and password used for SAP CP deployment. neo/environment - Map of environment variables in the form of KEY: VALUE. neo/host - The SAP Cloud Platform host to deploy to. neo/propertiesFile - The path to the .properties file in which all necessary deployment properties for the application are defined. neo/runtime - Name of SAP Cloud Platform application runtime. neo/runtimeVersion - Version of SAP Cloud Platform application runtime. neo/size - Compute unit (VM) size. Acceptable values: lite, pro, prem, prem-plus. neo/vmArguments - String of VM arguments passed to the JVM. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The path to the archive for deployment to SAP CP. If not provided mtarFilePath from commom pipeline environment is used instead. warAction - Action mode when using WAR file mode. Available options are deploy (default) and rolling-update which performs update of an application without downtime in one go. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage deployMode dockerEnvVars X dockerImage X dockerOptions X extensions X neo/account X X neo/application X X neo/credentialsId X X neo/environment X X neo/host X X neo/propertiesFile X X neo/runtime X X neo/runtimeVersion X X neo/size X X neo/vmArguments X X script source X warAction Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 Exception : If source is not provided. If propertiesFile is not provided (when using 'WAR_PROPERTIESFILE' deployment mode). If application is not provided (when using 'WAR_PARAMS' deployment mode). If runtime is not provided (when using 'WAR_PARAMS' deployment mode). If runtimeVersion is not provided (when using 'WAR_PARAMS' deployment mode). AbortException : If neo-java-web-sdk is not installed, or neoHome is wrong. CredentialNotFoundException : If the credentials cannot be resolved. Example \u00b6 neoDeploy script: this , source: 'path/to/archiveFile.mtar' , neo: [ credentialsId: 'my-credentials-id' , host: hana . example . org ] Example configuration: steps : <...> neoDeploy : deployMode : mta neo : account : <myDeployAccount> host : hana.example.org","title":"neoDeploy"},{"location":"steps/neoDeploy/#neodeploy","text":"","title":"neoDeploy"},{"location":"steps/neoDeploy/#description","text":"Deploys an Application to SAP Cloud Platform (SAP CP) using the SAP Cloud Platform Console Client (Neo Java Web SDK).","title":"Description"},{"location":"steps/neoDeploy/#prerequisites","text":"SAP CP account - the account to where the application is deployed. SAP CP user for deployment - a user with deployment permissions in the given account. Jenkins credentials for deployment - must be configured in Jenkins credentials with a dedicated Id. Neo Java Web SDK 3.39.10 or compatible version - can be downloaded from Maven Central . This step is capable of triggering the neo deploy tool provided inside a docker image. We provide docker image ppiper/neo-cli . neo.sh needs to be contained in path, e.g by adding a symbolic link to /usr/local/bin . Java 8 or compatible version - needed by the Neo-Java-Web-SDK . Java environment needs to be properly configured (JAVA_HOME, java exectutable contained in path).","title":"Prerequisites"},{"location":"steps/neoDeploy/#parameters","text":"name mandatory default possible values deployMode no mta 'mta', 'warParams', 'warPropertiesFile' dockerEnvVars no dockerImage no s4sdk/docker-neo-cli dockerOptions no extensions no [] neo/account for deployMode=warParams neo/application for deployMode=warParams neo/credentialsId no CI_CREDENTIALS_ID neo/environment no neo/host for deployMode=warParams neo/propertiesFile for deployMode=warPropertiesFile neo/runtime for deployMode=warParams neo/runtimeVersion for deployMode=warParams neo/size no lite neo/vmArguments no script yes source yes warAction no deploy 'deploy', 'rolling-update' deployMode - The deployment mode which should be used. Available options are: 'mta' - default, 'warParams' - deploying WAR file and passing all the deployment parameters via the function call, * 'warPropertiesFile' - deploying WAR file and putting all the deployment parameters in a .properties file. dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerOptions - Docker options to be set when starting the container (List or String). extensions - Extension files. Provided to the neo command via parameter --extensions ( -e ). Only valid for deploy mode mta . neo/account - The SAP Cloud Platform account to deploy to. neo/application - Name of the application you want to manage, configure, or deploy. neo/credentialsId - The Jenkins credentials containing user and password used for SAP CP deployment. neo/environment - Map of environment variables in the form of KEY: VALUE. neo/host - The SAP Cloud Platform host to deploy to. neo/propertiesFile - The path to the .properties file in which all necessary deployment properties for the application are defined. neo/runtime - Name of SAP Cloud Platform application runtime. neo/runtimeVersion - Version of SAP Cloud Platform application runtime. neo/size - Compute unit (VM) size. Acceptable values: lite, pro, prem, prem-plus. neo/vmArguments - String of VM arguments passed to the JVM. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. source - The path to the archive for deployment to SAP CP. If not provided mtarFilePath from commom pipeline environment is used instead. warAction - Action mode when using WAR file mode. Available options are deploy (default) and rolling-update which performs update of an application without downtime in one go.","title":"Parameters"},{"location":"steps/neoDeploy/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage deployMode dockerEnvVars X dockerImage X dockerOptions X extensions X neo/account X X neo/application X X neo/credentialsId X X neo/environment X X neo/host X X neo/propertiesFile X X neo/runtime X X neo/runtimeVersion X X neo/size X X neo/vmArguments X X script source X warAction","title":"Step configuration"},{"location":"steps/neoDeploy/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes lockable-resources pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/neoDeploy/#side-effects","text":"none","title":"Side effects"},{"location":"steps/neoDeploy/#exceptions","text":"Exception : If source is not provided. If propertiesFile is not provided (when using 'WAR_PROPERTIESFILE' deployment mode). If application is not provided (when using 'WAR_PARAMS' deployment mode). If runtime is not provided (when using 'WAR_PARAMS' deployment mode). If runtimeVersion is not provided (when using 'WAR_PARAMS' deployment mode). AbortException : If neo-java-web-sdk is not installed, or neoHome is wrong. CredentialNotFoundException : If the credentials cannot be resolved.","title":"Exceptions"},{"location":"steps/neoDeploy/#example","text":"neoDeploy script: this , source: 'path/to/archiveFile.mtar' , neo: [ credentialsId: 'my-credentials-id' , host: hana . example . org ] Example configuration: steps : <...> neoDeploy : deployMode : mta neo : account : <myDeployAccount> host : hana.example.org","title":"Example"},{"location":"steps/newmanExecute/","text":"newmanExecute \u00b6 Description \u00b6 This script executes Postman tests from a collection via the Newman command line tool. Prerequisites \u00b6 prepared Postman with a test collection Parameters \u00b6 name mandatory default possible values dockerImage no node:8-stretch failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id newmanCollection no **/*.postman_collection.json newmanEnvironment no `` newmanGlobals no `` newmanInstallCommand no npm install newman newman-reporter-html --global --quiet newmanRunCommand no run '${config.newmanCollection}' --environment '${config.newmanEnvironment}' --globals '${config.newmanGlobals}' --reporters junit,html --reporter-junit-export 'target/newman/TEST-${collectionDisplayName}.xml' --reporter-html-export 'target/newman/TEST-${collectionDisplayName}.html' script yes stashContent no [tests] testRepository no dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. failOnError - Defines the behavior, in case tests fail. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository newmanCollection - The test collection that should be executed. This could also be a file pattern. newmanEnvironment - Specify an environment file path or URL. Environments provide a set of variables that one can use within collections. see also Newman docs newmanGlobals - Specify the file path or URL for global variables. Global variables are similar to environment variables but have a lower precedence and can be overridden by environment variables having the same name. see also Newman docs newmanInstallCommand - The shell command that will be executed inside the docker container to install Newman. newmanRunCommand - The newman command that will be executed inside the docker container. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered for the tests, you can pass this via this parameter. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerImage X failOnError X gitBranch X gitSshKeyCredentialsId X newmanCollection X newmanEnvironment X newmanGlobals X newmanInstallCommand X newmanRunCommand X script stashContent X testRepository X Side effects \u00b6 Step uses dockerExecute inside. Dependencies \u00b6 The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 none Example \u00b6 Pipeline step: newmanExecute script: this This step should be used in combination with testsPublishResults : newmanExecute script: this , failOnError: false testsPublishResults script: this , junit: [ pattern: '**/newman/TEST-*.xml' ]","title":"newmanExecute"},{"location":"steps/newmanExecute/#newmanexecute","text":"","title":"newmanExecute"},{"location":"steps/newmanExecute/#description","text":"This script executes Postman tests from a collection via the Newman command line tool.","title":"Description"},{"location":"steps/newmanExecute/#prerequisites","text":"prepared Postman with a test collection","title":"Prerequisites"},{"location":"steps/newmanExecute/#parameters","text":"name mandatory default possible values dockerImage no node:8-stretch failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id newmanCollection no **/*.postman_collection.json newmanEnvironment no `` newmanGlobals no `` newmanInstallCommand no npm install newman newman-reporter-html --global --quiet newmanRunCommand no run '${config.newmanCollection}' --environment '${config.newmanEnvironment}' --globals '${config.newmanGlobals}' --reporters junit,html --reporter-junit-export 'target/newman/TEST-${collectionDisplayName}.xml' --reporter-html-export 'target/newman/TEST-${collectionDisplayName}.html' script yes stashContent no [tests] testRepository no dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. failOnError - Defines the behavior, in case tests fail. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository newmanCollection - The test collection that should be executed. This could also be a file pattern. newmanEnvironment - Specify an environment file path or URL. Environments provide a set of variables that one can use within collections. see also Newman docs newmanGlobals - Specify the file path or URL for global variables. Global variables are similar to environment variables but have a lower precedence and can be overridden by environment variables having the same name. see also Newman docs newmanInstallCommand - The shell command that will be executed inside the docker container to install Newman. newmanRunCommand - The newman command that will be executed inside the docker container. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashContent - If specific stashes should be considered for the tests, you can pass this via this parameter. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url.","title":"Parameters"},{"location":"steps/newmanExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerImage X failOnError X gitBranch X gitSshKeyCredentialsId X newmanCollection X newmanEnvironment X newmanGlobals X newmanInstallCommand X newmanRunCommand X script stashContent X testRepository X","title":"Step configuration"},{"location":"steps/newmanExecute/#side-effects","text":"Step uses dockerExecute inside.","title":"Side effects"},{"location":"steps/newmanExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/newmanExecute/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/newmanExecute/#example","text":"Pipeline step: newmanExecute script: this This step should be used in combination with testsPublishResults : newmanExecute script: this , failOnError: false testsPublishResults script: this , junit: [ pattern: '**/newman/TEST-*.xml' ]","title":"Example"},{"location":"steps/npmExecute/","text":"npmExecute \u00b6 Parameters \u00b6 name mandatory default possible values defaultNpmRegistry no dockerImage no node:8-stretch dockerOptions no npmCommand no script yes defaultNpmRegistry - URL of default NPM registry dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'node:8-stretch'. dockerOptions - Docker options to be set when starting the container. npmCommand - Which NPM command should be executed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defaultNpmRegistry X dockerImage X dockerOptions npmCommand X script Dependencies \u00b6 The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 None Examples \u00b6 npmExecute script: this , dockerImage: 'node:8-stretch' , npmCommand: 'run build'","title":"npmExecute"},{"location":"steps/npmExecute/#npmexecute","text":"","title":"npmExecute"},{"location":"steps/npmExecute/#parameters","text":"name mandatory default possible values defaultNpmRegistry no dockerImage no node:8-stretch dockerOptions no npmCommand no script yes defaultNpmRegistry - URL of default NPM registry dockerImage - Name of the docker image that should be used, in which node should be installed and configured. Default value is 'node:8-stretch'. dockerOptions - Docker options to be set when starting the container. npmCommand - Which NPM command should be executed. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/npmExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage defaultNpmRegistry X dockerImage X dockerOptions npmCommand X script","title":"Step configuration"},{"location":"steps/npmExecute/#dependencies","text":"The step depends on the following Jenkins plugins docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/npmExecute/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/npmExecute/#examples","text":"npmExecute script: this , dockerImage: 'node:8-stretch' , npmCommand: 'run build'","title":"Examples"},{"location":"steps/pipelineExecute/","text":"pipelineExecute \u00b6 Description \u00b6 Loads and executes a pipeline from another git repository. The idea is to set up a pipeline job in Jenkins that loads a minimal pipeline, which in turn loads the shared library and then uses this step to load the actual pipeline. A centrally maintained pipeline script (Jenkinsfile) can be re-used by several projects using pipelineExecute as outlined in the example below. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values branch no master credentialsId no `` path no Jenkinsfile repoUrl yes script yes branch - The branch of the git repository from which the pipeline should be checked out. credentialsId - The Jenkins credentials containing user and password needed to access a private git repository. In case access to the repository containing the pipeline script is restricted the credentialsId of the credentials used for accessing the repository needs to be provided. The corresponding credentials needs to be configured in Jenkins accordingly. path - The path to the Jenkinsfile, inside the repository, to be loaded. repoUrl - The url to the git repository of the pipeline to be loaded. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage branch credentialsId path repoUrl script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 Exception If repoUrl is not provided. Example \u00b6 pipelineExecute repoUrl: \"https://github.com/MyOrg/MyPipelineRepo.git\" , branch: 'feature1' , path: 'path/to/Jenkinsfile' , credentialsId: 'MY_REPO_CREDENTIALS'","title":"pipelineExecute"},{"location":"steps/pipelineExecute/#pipelineexecute","text":"","title":"pipelineExecute"},{"location":"steps/pipelineExecute/#description","text":"Loads and executes a pipeline from another git repository. The idea is to set up a pipeline job in Jenkins that loads a minimal pipeline, which in turn loads the shared library and then uses this step to load the actual pipeline. A centrally maintained pipeline script (Jenkinsfile) can be re-used by several projects using pipelineExecute as outlined in the example below.","title":"Description"},{"location":"steps/pipelineExecute/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineExecute/#parameters","text":"name mandatory default possible values branch no master credentialsId no `` path no Jenkinsfile repoUrl yes script yes branch - The branch of the git repository from which the pipeline should be checked out. credentialsId - The Jenkins credentials containing user and password needed to access a private git repository. In case access to the repository containing the pipeline script is restricted the credentialsId of the credentials used for accessing the repository needs to be provided. The corresponding credentials needs to be configured in Jenkins accordingly. path - The path to the Jenkinsfile, inside the repository, to be loaded. repoUrl - The url to the git repository of the pipeline to be loaded. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/pipelineExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage branch credentialsId path repoUrl script","title":"Step configuration"},{"location":"steps/pipelineExecute/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step workflow-scm-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineExecute/#side-effects","text":"none","title":"Side effects"},{"location":"steps/pipelineExecute/#exceptions","text":"Exception If repoUrl is not provided.","title":"Exceptions"},{"location":"steps/pipelineExecute/#example","text":"pipelineExecute repoUrl: \"https://github.com/MyOrg/MyPipelineRepo.git\" , branch: 'feature1' , path: 'path/to/Jenkinsfile' , credentialsId: 'MY_REPO_CREDENTIALS'","title":"Example"},{"location":"steps/pipelineRestartSteps/","text":"pipelineRestartSteps \u00b6 Description \u00b6 Support of restarting failed stages or steps in a pipeline is limited in Jenkins. This has been documented in the Jenkins Jira issue JENKINS-33846 . For declarative pipelines there is a solution available which partially addresses this topic: https://jenkins.io/doc/book/pipeline/running-pipelines/#restart-from-a-stage. Nonetheless, still features are missing, so it can't be used in all cases. The more complex Piper pipelines which share a state via commonPipelineEnvironment will for example not work with the standard restart-from-stage . The step pipelineRestartSteps aims to address this gap and allows individual parts of a pipeline (e.g. a failed deployment) to be restarted. This is done in a way that the pipeline waits for user input to restart the pipeline in case of a failure. In case this user input is not provided the pipeline stops after a timeout which can be configured. Prerequisites \u00b6 none Parameters \u00b6 name mandatory default possible values script yes sendMail no true timeoutInSeconds no 900 script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sendMail - If it is set to true the step mailSendNotification will be triggered in case of an error. timeoutInSeconds - Defines the time period where the job waits for input. Default is 15 minutes. Once this time is passed the job enters state FAILED . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script sendMail X timeoutInSeconds X Example \u00b6 Usage of pipeline step: pipelineRestartSteps ( script: this ) { node { //your steps ... } } Caution Use node inside the step. If a node exists outside the step context, the input step which is triggered in the process will block a Jenkins executor. In case you cannot use node inside this step, please choose the parameter timeoutInSeconds carefully! Side effects \u00b6 none Dependencies \u00b6 The step depends on the following Jenkins plugins email-ext pipeline-input-step pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 none","title":"pipelineRestartSteps"},{"location":"steps/pipelineRestartSteps/#pipelinerestartsteps","text":"","title":"pipelineRestartSteps"},{"location":"steps/pipelineRestartSteps/#description","text":"Support of restarting failed stages or steps in a pipeline is limited in Jenkins. This has been documented in the Jenkins Jira issue JENKINS-33846 . For declarative pipelines there is a solution available which partially addresses this topic: https://jenkins.io/doc/book/pipeline/running-pipelines/#restart-from-a-stage. Nonetheless, still features are missing, so it can't be used in all cases. The more complex Piper pipelines which share a state via commonPipelineEnvironment will for example not work with the standard restart-from-stage . The step pipelineRestartSteps aims to address this gap and allows individual parts of a pipeline (e.g. a failed deployment) to be restarted. This is done in a way that the pipeline waits for user input to restart the pipeline in case of a failure. In case this user input is not provided the pipeline stops after a timeout which can be configured.","title":"Description"},{"location":"steps/pipelineRestartSteps/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/pipelineRestartSteps/#parameters","text":"name mandatory default possible values script yes sendMail no true timeoutInSeconds no 900 script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sendMail - If it is set to true the step mailSendNotification will be triggered in case of an error. timeoutInSeconds - Defines the time period where the job waits for input. Default is 15 minutes. Once this time is passed the job enters state FAILED .","title":"Parameters"},{"location":"steps/pipelineRestartSteps/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script sendMail X timeoutInSeconds X","title":"Step configuration"},{"location":"steps/pipelineRestartSteps/#example","text":"Usage of pipeline step: pipelineRestartSteps ( script: this ) { node { //your steps ... } } Caution Use node inside the step. If a node exists outside the step context, the input step which is triggered in the process will block a Jenkins executor. In case you cannot use node inside this step, please choose the parameter timeoutInSeconds carefully!","title":"Example"},{"location":"steps/pipelineRestartSteps/#side-effects","text":"none","title":"Side effects"},{"location":"steps/pipelineRestartSteps/#dependencies","text":"The step depends on the following Jenkins plugins email-ext pipeline-input-step pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineRestartSteps/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/pipelineStashFiles/","text":"pipelineStashFiles \u00b6 Description \u00b6 This step stashes files that are needed in other build steps (on other nodes). Prerequsites \u00b6 none Parameters \u00b6 name mandatory default possible values script yes stashExcludes no stashIncludes no script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Details: The step is stashing files before and after the build. This is due to the fact, that some of the code that needs to be stashed, is generated during the build (TypeScript for NPM). stash name mandatory prerequisite pattern buildDescriptor no includes: **/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/whitesource_config.py, **/mta*.y*ml, **/.npmrc, **/whitesource.*.json, **/whitesource-fs-agent.config, Dockerfile, **/VERSION, **/version.txt, **/build.sbt, **/sbtDescriptor.json, **/project/* excludes: **/node_modules/**/package.json checkmarx no Checkmarx is enabled includes: **/*.js, **/*.scala, **/*.go excludes: **/*.mockserver.js, node_modules/**/*.js classFiles no includes: **/target/classes/**/*.class, **/target/test-classes/**/*.class excludes: '' deployDescriptor no includes: **/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml exclude: '' git no includes: **/gitmetadata/** exludes: '' opa5 no OPA5 is enabled includes: **/*.* excludes: '' opensourceConfiguration no includes: **/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk excludes: '' pipelineConfigAndTests no includes: .pipeline/*.* excludes: '' securityDescriptor no includes: **/xs-security.json exludes: '' sonar no includes: **/jacoco*.exec, **/sonar-project.properties exludes: '' tests no includes: **/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js excludes: '' Overwriting default stashing behavior It is possible to overwrite the default behavior of the stashes using the parameters stashIncludes and stashExcludes , e.g. stashIncludes: [buildDescriptor: '**/mybuild.yml] stashExcludes: [tests: '**/NOTRELEVANT.*] Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script stashExcludes stashIncludes Dependencies \u00b6 The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Explanation of pipeline step \u00b6 Usage of pipeline step: pipelineStashFiles script: this { mavenExecute script: this , ... }","title":"pipelineStashFiles"},{"location":"steps/pipelineStashFiles/#pipelinestashfiles","text":"","title":"pipelineStashFiles"},{"location":"steps/pipelineStashFiles/#description","text":"This step stashes files that are needed in other build steps (on other nodes).","title":"Description"},{"location":"steps/pipelineStashFiles/#prerequsites","text":"none","title":"Prerequsites"},{"location":"steps/pipelineStashFiles/#parameters","text":"name mandatory default possible values script yes stashExcludes no stashIncludes no script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Details: The step is stashing files before and after the build. This is due to the fact, that some of the code that needs to be stashed, is generated during the build (TypeScript for NPM). stash name mandatory prerequisite pattern buildDescriptor no includes: **/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/whitesource_config.py, **/mta*.y*ml, **/.npmrc, **/whitesource.*.json, **/whitesource-fs-agent.config, Dockerfile, **/VERSION, **/version.txt, **/build.sbt, **/sbtDescriptor.json, **/project/* excludes: **/node_modules/**/package.json checkmarx no Checkmarx is enabled includes: **/*.js, **/*.scala, **/*.go excludes: **/*.mockserver.js, node_modules/**/*.js classFiles no includes: **/target/classes/**/*.class, **/target/test-classes/**/*.class excludes: '' deployDescriptor no includes: **/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml exclude: '' git no includes: **/gitmetadata/** exludes: '' opa5 no OPA5 is enabled includes: **/*.* excludes: '' opensourceConfiguration no includes: **/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk excludes: '' pipelineConfigAndTests no includes: .pipeline/*.* excludes: '' securityDescriptor no includes: **/xs-security.json exludes: '' sonar no includes: **/jacoco*.exec, **/sonar-project.properties exludes: '' tests no includes: **/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js excludes: '' Overwriting default stashing behavior It is possible to overwrite the default behavior of the stashes using the parameters stashIncludes and stashExcludes , e.g. stashIncludes: [buildDescriptor: '**/mybuild.yml] stashExcludes: [tests: '**/NOTRELEVANT.*]","title":"Parameters"},{"location":"steps/pipelineStashFiles/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script stashExcludes stashIncludes","title":"Step configuration"},{"location":"steps/pipelineStashFiles/#dependencies","text":"The step depends on the following Jenkins plugins <none> Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineStashFiles/#explanation-of-pipeline-step","text":"Usage of pipeline step: pipelineStashFiles script: this { mavenExecute script: this , ... }","title":"Explanation of pipeline step"},{"location":"steps/pipelineStashFilesAfterBuild/","text":"pipelineStashFilesAfterBuild \u00b6 Prerequsites \u00b6 none Parameters \u00b6 name mandatory default possible values noDefaultExludes no [] script yes stashExcludes no [checkmarx:**/*.mockserver.js, node_modules/**/*.js, classFiles:, sonar:] stashIncludes no [checkmarx:**/*.js, **/*.scala, **/*.py, **/*.go, **/*.xml, **/*.html, classFiles:**/target/classes/**/*.class, **/target/test-classes/**/*.class, sonar:**/jacoco*.exec, **/sonar-project.properties] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"pipelineStashFilesAfterBuild"},{"location":"steps/pipelineStashFilesAfterBuild/#pipelinestashfilesafterbuild","text":"","title":"pipelineStashFilesAfterBuild"},{"location":"steps/pipelineStashFilesAfterBuild/#prerequsites","text":"none","title":"Prerequsites"},{"location":"steps/pipelineStashFilesAfterBuild/#parameters","text":"name mandatory default possible values noDefaultExludes no [] script yes stashExcludes no [checkmarx:**/*.mockserver.js, node_modules/**/*.js, classFiles:, sonar:] stashIncludes no [checkmarx:**/*.js, **/*.scala, **/*.py, **/*.go, **/*.xml, **/*.html, classFiles:**/target/classes/**/*.class, **/target/test-classes/**/*.class, sonar:**/jacoco*.exec, **/sonar-project.properties] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash","title":"Parameters"},{"location":"steps/pipelineStashFilesAfterBuild/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X","title":"Step configuration"},{"location":"steps/pipelineStashFilesAfterBuild/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/pipelineStashFilesBeforeBuild/","text":"pipelineStashFilesBeforeBuild \u00b6 Description \u00b6 This step stashes files that are needed in other build steps (on other nodes). Prerequsites \u00b6 none Parameters \u00b6 name mandatory default possible values noDefaultExludes no [git] script yes stashExcludes no [buildDescriptor:**/node_modules/**/package.json, deployDescriptor:, git:, opa5:, opensourceConfiguration:, pipelineConfigAndTests:, securityDescriptor:, tests:] stashIncludes no [buildDescriptor:**/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/mta*.y*ml, **/.npmrc, Dockerfile, .hadolint.yaml, **/VERSION, **/version.txt, **/Gopkg.*, **/build.sbt, **/sbtDescriptor.json, **/project/*, deployDescriptor:**/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml, git:.git/**, opa5:**/*.*, opensourceConfiguration:**/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk, **/wss-unified-agent.config, **/vendor/**/*, pipelineConfigAndTests:.pipeline/**, securityDescriptor:**/xs-security.json, tests:**/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js, **/tests/**] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"pipelineStashFilesBeforeBuild"},{"location":"steps/pipelineStashFilesBeforeBuild/#pipelinestashfilesbeforebuild","text":"","title":"pipelineStashFilesBeforeBuild"},{"location":"steps/pipelineStashFilesBeforeBuild/#description","text":"This step stashes files that are needed in other build steps (on other nodes).","title":"Description"},{"location":"steps/pipelineStashFilesBeforeBuild/#prerequsites","text":"none","title":"Prerequsites"},{"location":"steps/pipelineStashFilesBeforeBuild/#parameters","text":"name mandatory default possible values noDefaultExludes no [git] script yes stashExcludes no [buildDescriptor:**/node_modules/**/package.json, deployDescriptor:, git:, opa5:, opensourceConfiguration:, pipelineConfigAndTests:, securityDescriptor:, tests:] stashIncludes no [buildDescriptor:**/pom.xml, **/.mvn/**, **/assembly.xml, **/.swagger-codegen-ignore, **/package.json, **/requirements.txt, **/setup.py, **/mta*.y*ml, **/.npmrc, Dockerfile, .hadolint.yaml, **/VERSION, **/version.txt, **/Gopkg.*, **/build.sbt, **/sbtDescriptor.json, **/project/*, deployDescriptor:**/manifest*.y*ml, **/*.mtaext.y*ml, **/*.mtaext, **/xs-app.json, helm/**, *.y*ml, git:.git/**, opa5:**/*.*, opensourceConfiguration:**/srcclr.yml, **/vulas-custom.properties, **/.nsprc, **/.retireignore, **/.retireignore.json, **/.snyk, **/wss-unified-agent.config, **/vendor/**/*, pipelineConfigAndTests:.pipeline/**, securityDescriptor:**/xs-security.json, tests:**/pom.xml, **/*.json, **/*.xml, **/src/**, **/node_modules/**, **/specs/**, **/env/**, **/*.js, **/tests/**] noDefaultExludes - By default certain files are excluded from stashing (e.g. .git folder). Details can be found as per [Pipeline basic step stash](https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#stash-stash-some-files-to-be-used-later-in-the-build). This parameter allows to provide a list of stash names for which the standard exclude behavior should be switched off. This will allow you to also stash directories like .git`. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. stashExcludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the excludes and can be defined as a map of stash name and exclude patterns. Exclude pattern has to be a string with comma separated patterns as per Pipeline basic step stash stashIncludes - Can be used to overwrite the default behavior of existing stashes as well as to define additional stashes. This parameter handles the includes and can be defined as a map of stash name and include patterns. Include pattern has to be a string with comma separated patterns as per Pipeline basic step stash","title":"Parameters"},{"location":"steps/pipelineStashFilesBeforeBuild/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage noDefaultExludes X script stashExcludes X stashIncludes X","title":"Step configuration"},{"location":"steps/pipelineStashFilesBeforeBuild/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/piperPipelineStagePost/","text":"piperPipelineStagePost \u00b6 Description \u00b6 In this stage reporting actions like mail notification or telemetry reporting are executed. This stage contains following steps: - influxWriteData - mailSendNotification Note This stage is meant to be used in a post section of a pipeline. Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script Dependencies \u00b6 The step depends on the following Jenkins plugins email-ext lockable-resources pipeline-milestone-step pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"piperPipelineStagePost"},{"location":"steps/piperPipelineStagePost/#piperpipelinestagepost","text":"","title":"piperPipelineStagePost"},{"location":"steps/piperPipelineStagePost/#description","text":"In this stage reporting actions like mail notification or telemetry reporting are executed. This stage contains following steps: - influxWriteData - mailSendNotification Note This stage is meant to be used in a post section of a pipeline.","title":"Description"},{"location":"steps/piperPipelineStagePost/#parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/piperPipelineStagePost/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script","title":"Step configuration"},{"location":"steps/piperPipelineStagePost/#dependencies","text":"The step depends on the following Jenkins plugins email-ext lockable-resources pipeline-milestone-step pipeline-utility-steps ssh-agent workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/prepareDefaultValues/","text":"prepareDefaultValues \u00b6 Description \u00b6 Loads the pipeline library default values from the file resources/default_pipeline_environment.yml . Afterwards the values can be loaded by the method: ConfigurationLoader.defaultStepConfiguration Parameters \u00b6 name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script Exceptions \u00b6 None Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 prepareDefaultValues ()","title":"prepareDefaultValues"},{"location":"steps/prepareDefaultValues/#preparedefaultvalues","text":"","title":"prepareDefaultValues"},{"location":"steps/prepareDefaultValues/#description","text":"Loads the pipeline library default values from the file resources/default_pipeline_environment.yml . Afterwards the values can be loaded by the method: ConfigurationLoader.defaultStepConfiguration","title":"Description"},{"location":"steps/prepareDefaultValues/#parameters","text":"name mandatory default possible values script yes script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/prepareDefaultValues/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage script","title":"Step configuration"},{"location":"steps/prepareDefaultValues/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/prepareDefaultValues/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/prepareDefaultValues/#example","text":"prepareDefaultValues ()","title":"Example"},{"location":"steps/seleniumExecuteTests/","text":"seleniumExecuteTests \u00b6 Description \u00b6 Enables UI test execution with Selenium in a sidecar container. The step executes a closure (see example below) connecting to a sidecar container with a Selenium Server. When executing in a local Docker environment, please make sure to set Selenium host to selenium in your tests. Kubernetes environment, plese make sure to set Seleniums host to localhost in your tests. Proxy Environments If work in an environment containing a proxy, please make sure that localhost / selenium is added to your proxy exclusion list, e.g. via environment variable NO_PROXY & no_proxy . You can pass those via parameters dockerEnvVars and sidecarEnvVars directly to the containers if required. Prerequisites \u00b6 none Example \u00b6 seleniumExecuteTests ( script: this ) { git url: 'https://github.wdf.sap.corp/xxxxx/WebDriverIOTest.git' sh '''npm install node index.js''' } Example test using WebdriverIO \u00b6 Example based on http://webdriver.io/guide/getstarted/modes.html and http://webdriver.io/guide.html Configuration for Local Docker Environment \u00b6 var webdriverio = require ( 'webdriverio' ); var options = { host : 'selenium' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } }; Configuration for Kubernetes Environment \u00b6 var webdriverio = require ( 'webdriverio' ); var options = { host : 'localhost' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } }; Test Code (index.js) \u00b6 // ToDo: add configuration from above webdriverio . remote ( options ) . init () . url ( 'http://www.google.com' ) . getTitle (). then ( function ( title ) { console . log ( 'Title was: ' + title ); }) . end () . catch ( function ( err ) { console . log ( err ); }); Parameters \u00b6 name mandatory default possible values buildTool no npm maven , npm , bundler containerPortMappings no [selenium/standalone-chrome:[[containerPort:4444, hostPort:4444]]] dockerEnvVars no dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:8-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id script yes sidecarEnvVars no sidecarImage no selenium/standalone-chrome sidecarName no selenium sidecarVolumeBind no [/dev/shm:/dev/shm] stashContent no [tests] testRepository no buildTool - Defines the tool which is used for executing the tests containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarVolumeBind - as dockerVolumeBind for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerWorkspace X X failOnError X X gitBranch X X gitSshKeyCredentialsId X X script sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X testRepository X X Dependencies \u00b6 The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none","title":"seleniumExecuteTests"},{"location":"steps/seleniumExecuteTests/#seleniumexecutetests","text":"","title":"seleniumExecuteTests"},{"location":"steps/seleniumExecuteTests/#description","text":"Enables UI test execution with Selenium in a sidecar container. The step executes a closure (see example below) connecting to a sidecar container with a Selenium Server. When executing in a local Docker environment, please make sure to set Selenium host to selenium in your tests. Kubernetes environment, plese make sure to set Seleniums host to localhost in your tests. Proxy Environments If work in an environment containing a proxy, please make sure that localhost / selenium is added to your proxy exclusion list, e.g. via environment variable NO_PROXY & no_proxy . You can pass those via parameters dockerEnvVars and sidecarEnvVars directly to the containers if required.","title":"Description"},{"location":"steps/seleniumExecuteTests/#prerequisites","text":"none","title":"Prerequisites"},{"location":"steps/seleniumExecuteTests/#example","text":"seleniumExecuteTests ( script: this ) { git url: 'https://github.wdf.sap.corp/xxxxx/WebDriverIOTest.git' sh '''npm install node index.js''' }","title":"Example"},{"location":"steps/seleniumExecuteTests/#example-test-using-webdriverio","text":"Example based on http://webdriver.io/guide/getstarted/modes.html and http://webdriver.io/guide.html","title":"Example test using WebdriverIO"},{"location":"steps/seleniumExecuteTests/#configuration-for-local-docker-environment","text":"var webdriverio = require ( 'webdriverio' ); var options = { host : 'selenium' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } };","title":"Configuration for Local Docker Environment"},{"location":"steps/seleniumExecuteTests/#configuration-for-kubernetes-environment","text":"var webdriverio = require ( 'webdriverio' ); var options = { host : 'localhost' , port : 4444 , desiredCapabilities : { browserName : 'chrome' } };","title":"Configuration for Kubernetes Environment"},{"location":"steps/seleniumExecuteTests/#test-code-indexjs","text":"// ToDo: add configuration from above webdriverio . remote ( options ) . init () . url ( 'http://www.google.com' ) . getTitle (). then ( function ( title ) { console . log ( 'Title was: ' + title ); }) . end () . catch ( function ( err ) { console . log ( err ); });","title":"Test Code (index.js)"},{"location":"steps/seleniumExecuteTests/#parameters","text":"name mandatory default possible values buildTool no npm maven , npm , bundler containerPortMappings no [selenium/standalone-chrome:[[containerPort:4444, hostPort:4444]]] dockerEnvVars no dockerImage no buildTool= maven : maven:3.5-jdk-8 buildTool= npm : node:8-stretch buildTool= bundler : ruby:2.5.3-stretch dockerName no buildTool= maven : maven buildTool= npm : npm buildTool= bundler : bundler dockerWorkspace no buildTool= maven : <empty> buildTool= npm : /home/node buildTool= bundler : <empty> failOnError no true true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id script yes sidecarEnvVars no sidecarImage no selenium/standalone-chrome sidecarName no selenium sidecarVolumeBind no [/dev/shm:/dev/shm] stashContent no [tests] testRepository no buildTool - Defines the tool which is used for executing the tests containerPortMappings - Map which defines per docker image the port mappings, e.g. containerPortMappings: ['selenium/standalone-chrome': [[name: 'selPort', containerPort: 4444, hostPort: 4444]]] . dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerName - Kubernetes only: Name of the container launching dockerImage . SideCar only: Name of the container in local network. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container sidecarName - as dockerName for the sidecar container sidecarVolumeBind - as dockerVolumeBind for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url.","title":"Parameters"},{"location":"steps/seleniumExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildTool X X containerPortMappings X X dockerEnvVars X X dockerImage X X dockerName X X dockerWorkspace X X failOnError X X gitBranch X X gitSshKeyCredentialsId X X script sidecarEnvVars X X sidecarImage X X sidecarName X X sidecarVolumeBind X X stashContent X X testRepository X X","title":"Step configuration"},{"location":"steps/seleniumExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins docker git kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/seleniumExecuteTests/#side-effects","text":"none","title":"Side effects"},{"location":"steps/seleniumExecuteTests/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/setupCommonPipelineEnvironment/","text":"setupCommonPipelineEnvironment \u00b6 Description \u00b6 Initializes the commonPipelineEnvironment , which is used throughout the complete pipeline. Tip This step needs to run at the beginning of a pipeline right after the SCM checkout. Then subsequent pipeline steps consume the information from commonPipelineEnvironment ; it does not need to be passed to pipeline steps explicitly. Prerequisites \u00b6 A configuration file with properties. The property values are used as default values in many pipeline steps. Parameters \u00b6 name mandatory default possible values collectTelemetryData no true configFile no script yes collectTelemetryData - configFile - Property file defining project specific settings. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage collectTelemetryData X configFile script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 setupCommonPipelineEnvironment script: this","title":"setupCommonPipelineEnvironment"},{"location":"steps/setupCommonPipelineEnvironment/#setupcommonpipelineenvironment","text":"","title":"setupCommonPipelineEnvironment"},{"location":"steps/setupCommonPipelineEnvironment/#description","text":"Initializes the commonPipelineEnvironment , which is used throughout the complete pipeline. Tip This step needs to run at the beginning of a pipeline right after the SCM checkout. Then subsequent pipeline steps consume the information from commonPipelineEnvironment ; it does not need to be passed to pipeline steps explicitly.","title":"Description"},{"location":"steps/setupCommonPipelineEnvironment/#prerequisites","text":"A configuration file with properties. The property values are used as default values in many pipeline steps.","title":"Prerequisites"},{"location":"steps/setupCommonPipelineEnvironment/#parameters","text":"name mandatory default possible values collectTelemetryData no true configFile no script yes collectTelemetryData - configFile - Property file defining project specific settings. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/setupCommonPipelineEnvironment/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage collectTelemetryData X configFile script","title":"Step configuration"},{"location":"steps/setupCommonPipelineEnvironment/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/setupCommonPipelineEnvironment/#side-effects","text":"none","title":"Side effects"},{"location":"steps/setupCommonPipelineEnvironment/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/setupCommonPipelineEnvironment/#example","text":"setupCommonPipelineEnvironment script: this","title":"Example"},{"location":"steps/slackSendNotification/","text":"slackSendNotification \u00b6 Description \u00b6 Sends notifications to the Slack channel about the build status. Notification contains: Build status Repo Owner Repo Name Branch Name Jenkins Build Number Jenkins Build URL Prerequisites \u00b6 Installed and configured Slack JenkinsCI integration secret text Jenkins credentials with the Slack token Installed and configured Jenkins Slack plugin Parameters \u00b6 name mandatory default possible values baseUrl no channel no color no ${buildStatus == 'SUCCESS'?'#008000':'#E60000'} one of good , warning , danger , or any hex color code (eg. #439FE0 ) credentialsId no Jenkins credentials id message no script yes baseUrl - Allows overriding the Slack Plugin Integration Base Url specified in the global configuration. channel - Allows overriding of the default massaging channel from the plugin configuration. color - Defines the message color color defines the message color. credentialsId - The credentials id for the Slack token. message - Send a custom message into the Slack channel. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage baseUrl X channel X color X credentialsId X message X script Dependencies \u00b6 The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Example \u00b6 Usage of pipeline step: pipeline { agent any stages { stage ( 'Build' ) { steps { echo \"do something\" } } } post { always { slackSendNotification script: this } } }","title":"slackSendNotification"},{"location":"steps/slackSendNotification/#slacksendnotification","text":"","title":"slackSendNotification"},{"location":"steps/slackSendNotification/#description","text":"Sends notifications to the Slack channel about the build status. Notification contains: Build status Repo Owner Repo Name Branch Name Jenkins Build Number Jenkins Build URL","title":"Description"},{"location":"steps/slackSendNotification/#prerequisites","text":"Installed and configured Slack JenkinsCI integration secret text Jenkins credentials with the Slack token Installed and configured Jenkins Slack plugin","title":"Prerequisites"},{"location":"steps/slackSendNotification/#parameters","text":"name mandatory default possible values baseUrl no channel no color no ${buildStatus == 'SUCCESS'?'#008000':'#E60000'} one of good , warning , danger , or any hex color code (eg. #439FE0 ) credentialsId no Jenkins credentials id message no script yes baseUrl - Allows overriding the Slack Plugin Integration Base Url specified in the global configuration. channel - Allows overriding of the default massaging channel from the plugin configuration. color - Defines the message color color defines the message color. credentialsId - The credentials id for the Slack token. message - Send a custom message into the Slack channel. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/slackSendNotification/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage baseUrl X channel X color X credentialsId X message X script","title":"Step configuration"},{"location":"steps/slackSendNotification/#dependencies","text":"The step depends on the following Jenkins plugins pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/slackSendNotification/#example","text":"Usage of pipeline step: pipeline { agent any stages { stage ( 'Build' ) { steps { echo \"do something\" } } } post { always { slackSendNotification script: this } } }","title":"Example"},{"location":"steps/snykExecute/","text":"snykExecute \u00b6 Description \u00b6 This step performs an open source vulnerability scan on a Node project or Node module inside an MTA project through snyk.io. Prerequisites \u00b6 Snyk account - have an account on snyk.io Snyk token - have a Snyk user token Parameters \u00b6 name mandatory default possible values buildDescriptorFile no ./package.json dockerImage no node:8-stretch exclude no [] monitor no true scanType no npm npm , mta script yes snykCredentialsId yes Jenkins credentials id snykOrg no toHtml no false toJson no false buildDescriptorFile - The path to the build descriptor file, e.g. ./package.json . dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. exclude - Only scanType 'mta': Exclude modules from MTA projects. monitor - Monitor the application's dependencies for new vulnerabilities. scanType - The type of project that should be scanned. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. snykCredentialsId - Credentials for accessing the Snyk API. snykOrg - Only needed for monitor: true : The organisation ID to determine the organisation to report to. toHtml - Generate and archive a HTML report. toJson - Generate and archive a JSON report. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildDescriptorFile X dockerImage X exclude X monitor X scanType X script snykCredentialsId X X snykOrg X toHtml X toJson X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 Step uses dockerExecute inside. Exceptions \u00b6 none Example \u00b6 snykExecute script: this , snykCredentialsId: 'mySnykToken'","title":"snykExecute"},{"location":"steps/snykExecute/#snykexecute","text":"","title":"snykExecute"},{"location":"steps/snykExecute/#description","text":"This step performs an open source vulnerability scan on a Node project or Node module inside an MTA project through snyk.io.","title":"Description"},{"location":"steps/snykExecute/#prerequisites","text":"Snyk account - have an account on snyk.io Snyk token - have a Snyk user token","title":"Prerequisites"},{"location":"steps/snykExecute/#parameters","text":"name mandatory default possible values buildDescriptorFile no ./package.json dockerImage no node:8-stretch exclude no [] monitor no true scanType no npm npm , mta script yes snykCredentialsId yes Jenkins credentials id snykOrg no toHtml no false toJson no false buildDescriptorFile - The path to the build descriptor file, e.g. ./package.json . dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. exclude - Only scanType 'mta': Exclude modules from MTA projects. monitor - Monitor the application's dependencies for new vulnerabilities. scanType - The type of project that should be scanned. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. snykCredentialsId - Credentials for accessing the Snyk API. snykOrg - Only needed for monitor: true : The organisation ID to determine the organisation to report to. toHtml - Generate and archive a HTML report. toJson - Generate and archive a JSON report.","title":"Parameters"},{"location":"steps/snykExecute/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage buildDescriptorFile X dockerImage X exclude X monitor X scanType X script snykCredentialsId X X snykOrg X toHtml X toJson X","title":"Step configuration"},{"location":"steps/snykExecute/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/snykExecute/#side-effects","text":"Step uses dockerExecute inside.","title":"Side effects"},{"location":"steps/snykExecute/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/snykExecute/#example","text":"snykExecute script: this , snykCredentialsId: 'mySnykToken'","title":"Example"},{"location":"steps/sonarExecuteScan/","text":"sonarExecuteScan \u00b6 Description \u00b6 The step executes the sonar-scanner cli command to scan the defined sources and publish the results to a SonarQube instance. Prerequsites \u00b6 The project needs a sonar-project.properties file that describes the project and defines certain settings, see here . A SonarQube instance needs to be defined in the Jenkins. Parameters \u00b6 name mandatory default possible values disableInlineComments no true , false dockerImage no maven:3.5-jdk-8 githubApiUrl no https://api.github.com githubOrg yes githubRepo yes githubTokenCredentialsId yes Jenkins credential id instance no SonarCloud legacyPRHandling no true , false options no [] organization no projectVersion no script yes sonarTokenCredentialsId no Jenkins credential id disableInlineComments - Pull-Request voting only: Disables the pull-request decoration with inline comments. deprecated: only supported in LTS / < 7.2 dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. see dockerExecute githubApiUrl - Pull-Request voting only: The URL to the Github API. see https://docs.sonarqube.org/display/PLUG/GitHub+Plugin#GitHubPlugin-Usage deprecated: only supported in LTS / < 7.2 githubOrg - Pull-Request voting only: The Github organization. @default: commonPipelineEnvironment.getGithubOrg() githubRepo - Pull-Request voting only: The Github repository. @default: commonPipelineEnvironment.getGithubRepo() githubTokenCredentialsId - Pull-Request voting only: The Jenkins credentialId for a Github token. It is needed to report findings back to the pull-request. deprecated: only supported in LTS / < 7.2 instance - The name of the SonarQube instance defined in the Jenkins settings. legacyPRHandling - Pull-Request voting only: Activates the pull-request handling using the GitHub Plugin (deprecated). deprecated: only supported in LTS / < 7.2 options - A list of options which are passed to the sonar-scanner . organization - Organization that the project will be assigned to in SonarCloud.io. projectVersion - The project version that is reported to SonarQube. @default: major number of commonPipelineEnvironment.getArtifactVersion() script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sonarTokenCredentialsId - The Jenkins credentialsId for a SonarQube token. It is needed for non-anonymous analysis runs. see https://sonarcloud.io/account/security Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage disableInlineComments X dockerImage X githubApiUrl X X githubOrg X X githubRepo X X githubTokenCredentialsId X X instance X legacyPRHandling X options X organization X projectVersion X script sonarTokenCredentialsId X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 none Examples \u00b6","title":"sonarExecuteScan"},{"location":"steps/sonarExecuteScan/#sonarexecutescan","text":"","title":"sonarExecuteScan"},{"location":"steps/sonarExecuteScan/#description","text":"The step executes the sonar-scanner cli command to scan the defined sources and publish the results to a SonarQube instance.","title":"Description"},{"location":"steps/sonarExecuteScan/#prerequsites","text":"The project needs a sonar-project.properties file that describes the project and defines certain settings, see here . A SonarQube instance needs to be defined in the Jenkins.","title":"Prerequsites"},{"location":"steps/sonarExecuteScan/#parameters","text":"name mandatory default possible values disableInlineComments no true , false dockerImage no maven:3.5-jdk-8 githubApiUrl no https://api.github.com githubOrg yes githubRepo yes githubTokenCredentialsId yes Jenkins credential id instance no SonarCloud legacyPRHandling no true , false options no [] organization no projectVersion no script yes sonarTokenCredentialsId no Jenkins credential id disableInlineComments - Pull-Request voting only: Disables the pull-request decoration with inline comments. deprecated: only supported in LTS / < 7.2 dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. see dockerExecute githubApiUrl - Pull-Request voting only: The URL to the Github API. see https://docs.sonarqube.org/display/PLUG/GitHub+Plugin#GitHubPlugin-Usage deprecated: only supported in LTS / < 7.2 githubOrg - Pull-Request voting only: The Github organization. @default: commonPipelineEnvironment.getGithubOrg() githubRepo - Pull-Request voting only: The Github repository. @default: commonPipelineEnvironment.getGithubRepo() githubTokenCredentialsId - Pull-Request voting only: The Jenkins credentialId for a Github token. It is needed to report findings back to the pull-request. deprecated: only supported in LTS / < 7.2 instance - The name of the SonarQube instance defined in the Jenkins settings. legacyPRHandling - Pull-Request voting only: Activates the pull-request handling using the GitHub Plugin (deprecated). deprecated: only supported in LTS / < 7.2 options - A list of options which are passed to the sonar-scanner . organization - Organization that the project will be assigned to in SonarCloud.io. projectVersion - The project version that is reported to SonarQube. @default: major number of commonPipelineEnvironment.getArtifactVersion() script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. sonarTokenCredentialsId - The Jenkins credentialsId for a SonarQube token. It is needed for non-anonymous analysis runs. see https://sonarcloud.io/account/security","title":"Parameters"},{"location":"steps/sonarExecuteScan/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage disableInlineComments X dockerImage X githubApiUrl X X githubOrg X X githubRepo X X githubTokenCredentialsId X X instance X legacyPRHandling X options X organization X projectVersion X script sonarTokenCredentialsId X X","title":"Step configuration"},{"location":"steps/sonarExecuteScan/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/sonarExecuteScan/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/sonarExecuteScan/#examples","text":"","title":"Examples"},{"location":"steps/testsPublishResults/","text":"testsPublishResults \u00b6 Description \u00b6 This step can publish test results from various sources. Prerequsites \u00b6 test result files - To use this step, there must be test result files available. installed plugins: junit jacoco cobertura performance Pipeline configuration \u00b6 none Explanation of pipeline step \u00b6 Usage of pipeline step: testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] ) Parameters \u00b6 name mandatory default possible values cobertura no [pattern:**/target/coverage/cobertura-coverage.xml, onlyStableBuilds:true, allowEmptyResults:true, archive:false, active:false] true , false , Map failOnError no false true , false jacoco no [pattern:**/target/*.exec, allowEmptyResults:true, archive:false, active:false] true , false , Map jmeter no [pattern:**/*.jtl, errorFailedThreshold:20, errorUnstableThreshold:10, errorUnstableResponseTimeThreshold:, relativeFailedThresholdPositive:0, relativeFailedThresholdNegative:0, relativeUnstableThresholdPositive:0, relativeUnstableThresholdNegative:0, modeOfThreshold:false, modeThroughput:false, nthBuildNumber:0, configType:PRT, failBuildIfNoResultFile:false, compareBuildPrevious:true, allowEmptyResults:true, archive:false, active:false] true , false , Map junit no [pattern:**/TEST-*.xml, updateResults:false, allowEmptyResults:true, archive:false, active:false] true , false , Map script yes cobertura - Publishes code coverage with the Cobertura plugin . failOnError - If it is set to true the step will fail the build if JUnit detected any failing tests. jacoco - Publishes code coverage with the JaCoCo plugin . jmeter - Publishes performance test results with the Performance plugin . junit - Publishes test results files in JUnit format with the JUnit Plugin . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. junit \u00b6 parameter mandatory default possible values pattern no '**/TEST-*.xml' archive no false true, false updateResults no false true, false allowEmptyResults no true true, false jacoco \u00b6 parameter mandatory default possible values pattern no '**/target/*.exec' include no '' '**/*.class' exclude no '' '**/Test*' archive no false true, false allowEmptyResults no true true, false cobertura \u00b6 parameter mandatory default possible values pattern no '**/target/coverage/cobertura-coverage.xml' archive no false true, false allowEmptyResults no true true, false onlyStableBuilds no true true, false jmeter \u00b6 parameter mandatory default possible values pattern no '**/*.jtl' errorFailedThreshold no 20 errorUnstableThreshold no 10 errorUnstableResponseTimeThreshold no `` relativeFailedThresholdPositive no 0 relativeFailedThresholdNegative no 0 relativeUnstableThresholdPositive no 0 relativeUnstableThresholdNegative no 0 modeOfThreshold no false true, false modeThroughput no false true, false nthBuildNumber no 0 configType no PRT failBuildIfNoResultFile no false true, false compareBuildPrevious no true true, false archive no false true, false allowEmptyResults no true true, false Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cobertura X X failOnError X jacoco X X jmeter X X junit X X script Dependencies \u00b6 The step depends on the following Jenkins plugins cobertura jacoco junit performance pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Side effects \u00b6 none Exceptions \u00b6 none Example \u00b6 // publish test results with coverage testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] ) // publish test results with coverage testsPublishResults ( junit: [ pattern: '**/target/TEST*.xml' , archive: true ], cobertura: [ pattern: '**/target/coverage/cobertura-coverage.xml' ] )","title":"testsPublishResults"},{"location":"steps/testsPublishResults/#testspublishresults","text":"","title":"testsPublishResults"},{"location":"steps/testsPublishResults/#description","text":"This step can publish test results from various sources.","title":"Description"},{"location":"steps/testsPublishResults/#prerequsites","text":"test result files - To use this step, there must be test result files available. installed plugins: junit jacoco cobertura performance","title":"Prerequsites"},{"location":"steps/testsPublishResults/#pipeline-configuration","text":"none","title":"Pipeline configuration"},{"location":"steps/testsPublishResults/#explanation-of-pipeline-step","text":"Usage of pipeline step: testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] )","title":"Explanation of pipeline step"},{"location":"steps/testsPublishResults/#parameters","text":"name mandatory default possible values cobertura no [pattern:**/target/coverage/cobertura-coverage.xml, onlyStableBuilds:true, allowEmptyResults:true, archive:false, active:false] true , false , Map failOnError no false true , false jacoco no [pattern:**/target/*.exec, allowEmptyResults:true, archive:false, active:false] true , false , Map jmeter no [pattern:**/*.jtl, errorFailedThreshold:20, errorUnstableThreshold:10, errorUnstableResponseTimeThreshold:, relativeFailedThresholdPositive:0, relativeFailedThresholdNegative:0, relativeUnstableThresholdPositive:0, relativeUnstableThresholdNegative:0, modeOfThreshold:false, modeThroughput:false, nthBuildNumber:0, configType:PRT, failBuildIfNoResultFile:false, compareBuildPrevious:true, allowEmptyResults:true, archive:false, active:false] true , false , Map junit no [pattern:**/TEST-*.xml, updateResults:false, allowEmptyResults:true, archive:false, active:false] true , false , Map script yes cobertura - Publishes code coverage with the Cobertura plugin . failOnError - If it is set to true the step will fail the build if JUnit detected any failing tests. jacoco - Publishes code coverage with the JaCoCo plugin . jmeter - Publishes performance test results with the Performance plugin . junit - Publishes test results files in JUnit format with the JUnit Plugin . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters.","title":"Parameters"},{"location":"steps/testsPublishResults/#junit","text":"parameter mandatory default possible values pattern no '**/TEST-*.xml' archive no false true, false updateResults no false true, false allowEmptyResults no true true, false","title":"junit"},{"location":"steps/testsPublishResults/#jacoco","text":"parameter mandatory default possible values pattern no '**/target/*.exec' include no '' '**/*.class' exclude no '' '**/Test*' archive no false true, false allowEmptyResults no true true, false","title":"jacoco"},{"location":"steps/testsPublishResults/#cobertura","text":"parameter mandatory default possible values pattern no '**/target/coverage/cobertura-coverage.xml' archive no false true, false allowEmptyResults no true true, false onlyStableBuilds no true true, false","title":"cobertura"},{"location":"steps/testsPublishResults/#jmeter","text":"parameter mandatory default possible values pattern no '**/*.jtl' errorFailedThreshold no 20 errorUnstableThreshold no 10 errorUnstableResponseTimeThreshold no `` relativeFailedThresholdPositive no 0 relativeFailedThresholdNegative no 0 relativeUnstableThresholdPositive no 0 relativeUnstableThresholdNegative no 0 modeOfThreshold no false true, false modeThroughput no false true, false nthBuildNumber no 0 configType no PRT failBuildIfNoResultFile no false true, false compareBuildPrevious no true true, false archive no false true, false allowEmptyResults no true true, false","title":"jmeter"},{"location":"steps/testsPublishResults/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage cobertura X X failOnError X jacoco X X jmeter X X junit X X script","title":"Step configuration"},{"location":"steps/testsPublishResults/#dependencies","text":"The step depends on the following Jenkins plugins cobertura jacoco junit performance pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/testsPublishResults/#side-effects","text":"none","title":"Side effects"},{"location":"steps/testsPublishResults/#exceptions","text":"none","title":"Exceptions"},{"location":"steps/testsPublishResults/#example","text":"// publish test results with coverage testsPublishResults ( junit: [ updateResults: true , archive: true ], jacoco: [ archive: true ] ) // publish test results with coverage testsPublishResults ( junit: [ pattern: '**/target/TEST*.xml' , archive: true ], cobertura: [ pattern: '**/target/coverage/cobertura-coverage.xml' ] )","title":"Example"},{"location":"steps/transportRequestCreate/","text":"transportRequestCreate \u00b6 Description \u00b6 Creates a Transport Request for a Change Document on the Solution Manager (type SOLMAN ) or a Transport Request inside an ABAP system (type CTS ) The id of the transport request is availabe via commonPipelineEnvironment.getTransportRequestId() Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Solution Manager version ST720 SP08 or newer. Parameters \u00b6 name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/type no NONE SOLMAN , CTS , RFC description yes developmentSystemId yes script yes targetSystem yes transportType yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. description - The description of the transport request. Only for CTS . developmentSystemId - The logical system id for which the transport request is created. The format is <SID>~<TYPE>(/<CLIENT>)? . For ABAP Systems the developmentSystemId looks like DEV~ABAP/100 . For non-ABAP systems the developmentSystemId looks like e.g. L21~EXT_SRV or J01~JAVA . In case the system type is not known (in the examples provided here: EXT_SRV or JAVA ) the information can be retrieved from the Solution Manager instance. Only for SOLMAN . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. targetSystem - The system receiving the transport request. Only for CTS . transportType - Typically W (workbench) or C customizing. Only for CTS . verbose - Provides additional details. Only for RFC . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X changeManagement/type X description X developmentSystemId X script targetSystem X transportType X verbose X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestCreate : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below. Return value \u00b6 none Exceptions \u00b6 AbortException : If the creation of the transport request fails. IllegalStateException : If the change id is not provided. Example \u00b6 // SOLMAN def transportRequestId = transportRequestCreate script: this , changeDocumentId: '001,' changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS def transportRequestId = transportRequestCreate script: this , transportType: 'W' , targetSystem: 'XYZ' , description: 'the description' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"transportRequestCreate"},{"location":"steps/transportRequestCreate/#transportrequestcreate","text":"","title":"transportRequestCreate"},{"location":"steps/transportRequestCreate/#description","text":"Creates a Transport Request for a Change Document on the Solution Manager (type SOLMAN ) or a Transport Request inside an ABAP system (type CTS ) The id of the transport request is availabe via commonPipelineEnvironment.getTransportRequestId()","title":"Description"},{"location":"steps/transportRequestCreate/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Solution Manager version ST720 SP08 or newer.","title":"Prerequisites"},{"location":"steps/transportRequestCreate/#parameters","text":"name mandatory default possible values changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/type no NONE SOLMAN , CTS , RFC description yes developmentSystemId yes script yes targetSystem yes transportType yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. description - The description of the transport request. Only for CTS . developmentSystemId - The logical system id for which the transport request is created. The format is <SID>~<TYPE>(/<CLIENT>)? . For ABAP Systems the developmentSystemId looks like DEV~ABAP/100 . For non-ABAP systems the developmentSystemId looks like e.g. L21~EXT_SRV or J01~JAVA . In case the system type is not known (in the examples provided here: EXT_SRV or JAVA ) the information can be retrieved from the Solution Manager instance. Only for SOLMAN . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. targetSystem - The system receiving the transport request. Only for CTS . transportType - Typically W (workbench) or C customizing. Only for CTS . verbose - Provides additional details. Only for RFC .","title":"Parameters"},{"location":"steps/transportRequestCreate/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/changeDocumentLabel X changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X changeManagement/type X description X developmentSystemId X script targetSystem X transportType X verbose X","title":"Step configuration"},{"location":"steps/transportRequestCreate/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestCreate : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below.","title":"Dependencies"},{"location":"steps/transportRequestCreate/#return-value","text":"none","title":"Return value"},{"location":"steps/transportRequestCreate/#exceptions","text":"AbortException : If the creation of the transport request fails. IllegalStateException : If the change id is not provided.","title":"Exceptions"},{"location":"steps/transportRequestCreate/#example","text":"// SOLMAN def transportRequestId = transportRequestCreate script: this , changeDocumentId: '001,' changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS def transportRequestId = transportRequestCreate script: this , transportType: 'W' , targetSystem: 'XYZ' , description: 'the description' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"Example"},{"location":"steps/transportRequestRelease/","text":"transportRequestRelease \u00b6 Description \u00b6 Releases a Transport Request. Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Parameters \u00b6 name mandatory default possible values changeDocumentId yes changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes script yes transportRequestId yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to release. verbose - Provides additional details. Only for RFC . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X script transportRequestId verbose Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestRelease : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below. Exceptions \u00b6 IllegalArgumentException : If the change id is not provided ( SOLMAN only) If the transport request id is not provided. AbortException : If the release of the transport request fails. Example \u00b6 // SOLMAN transportRequestRelease script: this , changeDocumentId: '001' , transportRequestId: '001' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS transportRequestRelease script: this , transportRequestId: '001' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"transportRequestRelease"},{"location":"steps/transportRequestRelease/#transportrequestrelease","text":"","title":"transportRequestRelease"},{"location":"steps/transportRequestRelease/#description","text":"Releases a Transport Request.","title":"Description"},{"location":"steps/transportRequestRelease/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central.","title":"Prerequisites"},{"location":"steps/transportRequestRelease/#parameters","text":"name mandatory default possible values changeDocumentId yes changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes script yes transportRequestId yes verbose no false changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to release. verbose - Provides additional details. Only for RFC .","title":"Parameters"},{"location":"steps/transportRequestRelease/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage changeDocumentId changeManagement/clientOpts X changeManagement/credentialsId X changeManagement/endpoint X changeManagement/git/format X changeManagement/git/from X changeManagement/git/to X changeManagement/rfc/developmentClient X changeManagement/rfc/developmentInstance X script transportRequestId verbose","title":"Step configuration"},{"location":"steps/transportRequestRelease/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestRelease : changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below.","title":"Dependencies"},{"location":"steps/transportRequestRelease/#exceptions","text":"IllegalArgumentException : If the change id is not provided ( SOLMAN only) If the transport request id is not provided. AbortException : If the release of the transport request fails.","title":"Exceptions"},{"location":"steps/transportRequestRelease/#example","text":"// SOLMAN transportRequestRelease script: this , changeDocumentId: '001' , transportRequestId: '001' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] // CTS transportRequestRelease script: this , transportRequestId: '001' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ]","title":"Example"},{"location":"steps/transportRequestUploadFile/","text":"transportRequestUploadFile \u00b6 Description \u00b6 Uploads a file to a Transport Request. Prerequisites \u00b6 Change Management Client 2.0.0 or compatible version - available for download on Maven Central. Parameters \u00b6 name mandatory default possible values abapPackage yes acceptUnixStyleLineEndings no true applicationDescription yes applicationId yes applicationName yes applicationUrl yes changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/changeManagement/transportRequestLabel no changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/rfc/docker/envVars no [:] changeManagement/rfc/docker/image no rfc changeManagement/rfc/docker/options no [] changeManagement/rfc/docker/pullImage no true changeManagement/type no NONE SOLMAN , CTS , RFC codePage no UTF-8 failOnWarning no true filePath yes script yes transportRequestId yes verbose no false abapPackage - The ABAP package name of your application. acceptUnixStyleLineEndings - applicationDescription - applicationId - The id of the application. Only for SOLMAN . applicationName - applicationUrl - The URL where to find the UI5 package to upload to the transport request. Only for RFC . changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/changeManagement/transportRequestLabel - A pattern used for identifying lines holding the transport request id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/rfc/docker/envVars - changeManagement/rfc/docker/image - changeManagement/rfc/docker/options - changeManagement/rfc/docker/pullImage - changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. codePage - The code page of your ABAP system. E.g. UTF-8. failOnWarning - filePath - The path of the file to upload. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to upload the file. verbose - Provides additional details. Only for RFC . Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage abapPackage X acceptUnixStyleLineEndings X applicationDescription X applicationId X applicationName X applicationUrl X changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/changeManagement/transportRequestLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X changeManagement/rfc/developmentClient X X changeManagement/rfc/developmentInstance X X changeManagement/rfc/docker/envVars X X changeManagement/rfc/docker/image X X changeManagement/rfc/docker/options X X changeManagement/rfc/docker/pullImage X X changeManagement/type X X codePage X failOnWarning filePath X script transportRequestId verbose X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestUploadFile : applicationId : 'FOO' changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below. Exceptions \u00b6 IllegalArgumentException : If the change id is not provided ( SOLMAN only). If the transport request id is not provided. If the application id is not provided ( SOLMAN only). If the file path is not provided. AbortException : If the upload fails. Example \u00b6 // SOLMAN transportRequestUploadFile ( script: this , changeDocumentId: '001' , // typically provided via git commit history transportRequestId: '001' , // typically provided via git commit history applicationId: '001' , filePath: '/path' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] ) // CTS transportRequestUploadFile ( script: this , transportRequestId: '001' , // typically provided via git commit history filePath: '/path' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ] )","title":"transportRequestUploadFile"},{"location":"steps/transportRequestUploadFile/#transportrequestuploadfile","text":"","title":"transportRequestUploadFile"},{"location":"steps/transportRequestUploadFile/#description","text":"Uploads a file to a Transport Request.","title":"Description"},{"location":"steps/transportRequestUploadFile/#prerequisites","text":"Change Management Client 2.0.0 or compatible version - available for download on Maven Central.","title":"Prerequisites"},{"location":"steps/transportRequestUploadFile/#parameters","text":"name mandatory default possible values abapPackage yes acceptUnixStyleLineEndings no true applicationDescription yes applicationId yes applicationName yes applicationUrl yes changeDocumentId yes changeManagement/changeDocumentLabel no ChangeDocument\\s?: regex pattern changeManagement/changeManagement/transportRequestLabel no changeManagement/clientOpts no `` changeManagement/credentialsId no CM changeManagement/endpoint yes changeManagement/git/format no %b see git log --help changeManagement/git/from no origin/master changeManagement/git/to no HEAD changeManagement/rfc/developmentClient yes changeManagement/rfc/developmentInstance yes changeManagement/rfc/docker/envVars no [:] changeManagement/rfc/docker/image no rfc changeManagement/rfc/docker/options no [] changeManagement/rfc/docker/pullImage no true changeManagement/type no NONE SOLMAN , CTS , RFC codePage no UTF-8 failOnWarning no true filePath yes script yes transportRequestId yes verbose no false abapPackage - The ABAP package name of your application. acceptUnixStyleLineEndings - applicationDescription - applicationId - The id of the application. Only for SOLMAN . applicationName - applicationUrl - The URL where to find the UI5 package to upload to the transport request. Only for RFC . changeDocumentId - The id of the change document to that the transport request is bound to. Typically this value is provided via commit message in the commit history. Only for SOLMAN . changeManagement/changeDocumentLabel - A pattern used for identifying lines holding the change document id. changeManagement/changeManagement/transportRequestLabel - A pattern used for identifying lines holding the transport request id. changeManagement/clientOpts - Additional options for cm command line client, e.g. JAVA_OPTS. changeManagement/credentialsId - The id of the credentials to connect to the Solution Manager. The credentials needs to be maintained on Jenkins. changeManagement/endpoint - The service endpoint, e.g. Solution Manager, ABAP System. changeManagement/git/format - Specifies what part of the commit is scanned. By default the body of the commit message is scanned. changeManagement/git/from - The starting point for retrieving the change document id. changeManagement/git/to - The end point for retrieving the change document id. changeManagement/rfc/developmentClient - AS ABAP client number. Only for RFC . changeManagement/rfc/developmentInstance - AS ABAP instance number. Only for RFC . changeManagement/rfc/docker/envVars - changeManagement/rfc/docker/image - changeManagement/rfc/docker/options - changeManagement/rfc/docker/pullImage - changeManagement/type - Defines where the transport request is created, e.g. SAP Solution Manager, ABAP System. codePage - The code page of your ABAP system. E.g. UTF-8. failOnWarning - filePath - The path of the file to upload. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. transportRequestId - The id of the transport request to upload the file. verbose - Provides additional details. Only for RFC .","title":"Parameters"},{"location":"steps/transportRequestUploadFile/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage abapPackage X acceptUnixStyleLineEndings X applicationDescription X applicationId X applicationName X applicationUrl X changeDocumentId changeManagement/changeDocumentLabel X X changeManagement/changeManagement/transportRequestLabel X X changeManagement/clientOpts X X changeManagement/credentialsId X X changeManagement/endpoint X X changeManagement/git/format X X changeManagement/git/from X X changeManagement/git/to X X changeManagement/rfc/developmentClient X X changeManagement/rfc/developmentInstance X X changeManagement/rfc/docker/envVars X X changeManagement/rfc/docker/image X X changeManagement/rfc/docker/options X X changeManagement/rfc/docker/pullImage X X changeManagement/type X X codePage X failOnWarning filePath X script transportRequestId verbose X","title":"Step configuration"},{"location":"steps/transportRequestUploadFile/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. The step is configured using a customer configuration file provided as resource in an custom shared library. @Library ( 'piper-lib-os@master' ) _ // the shared lib containing the additional configuration // needs to be configured in Jenkins @Library ( 'foo@master' ) __ // inside the shared lib denoted by 'foo' the additional configuration file // needs to be located under 'resources' ('resoures/myConfig.yml') prepareDefaultValues script: this , customDefaults: 'myConfig.yml' Example content of 'resources/myConfig.yml' in branch 'master' of the repository denoted by 'foo' : general : changeManagement : changeDocumentLabel : 'ChangeDocument\\s?:' cmClientOpts : '-Djavax.net.ssl.trustStore=<path to truststore>' credentialsId : 'CM' type : 'SOLMAN' endpoint : 'https://example.org/cm' git : from : 'HEAD~1' to : 'HEAD' format : '%b' The properties configured in section 'general/changeManagement' are shared between all change managment related steps. The properties can also be configured on a per-step basis: [ ... ] steps : transportRequestUploadFile : applicationId : 'FOO' changeManagement : type : 'SOLMAN' endpoint : 'https://example.org/cm' [ ... ] The parameters can also be provided when the step is invoked. For examples see below.","title":"Dependencies"},{"location":"steps/transportRequestUploadFile/#exceptions","text":"IllegalArgumentException : If the change id is not provided ( SOLMAN only). If the transport request id is not provided. If the application id is not provided ( SOLMAN only). If the file path is not provided. AbortException : If the upload fails.","title":"Exceptions"},{"location":"steps/transportRequestUploadFile/#example","text":"// SOLMAN transportRequestUploadFile ( script: this , changeDocumentId: '001' , // typically provided via git commit history transportRequestId: '001' , // typically provided via git commit history applicationId: '001' , filePath: '/path' , changeManagement: [ type: 'SOLMAN' endpoint: 'https://example.org/cm' ] ) // CTS transportRequestUploadFile ( script: this , transportRequestId: '001' , // typically provided via git commit history filePath: '/path' , changeManagement: [ type: 'CTS' endpoint: 'https://example.org/cm' ] )","title":"Example"},{"location":"steps/uiVeri5ExecuteTests/","text":"uiVeri5ExecuteTests \u00b6 Description \u00b6 With this step UIVeri5 tests can be executed. UIVeri5 describes following benefits on its GitHub page: Automatic synchronization with UI5 app rendering so there is no need to add waits and sleeps to your test. Tests are reliable by design. Tests are written in synchronous manner, no callbacks, no promise chaining so are really simple to write and maintain. Full power of webdriverjs, protractor and jasmine - deferred selectors, custom matchers, custom locators. Control locators (OPA5 declarative matchers) allow locating and interacting with UI5 controls. Does not depend on testability support in applications - works with autorefreshing views, resizing elements, animated transitions. Declarative authentications - authentication flow over OAuth2 providers, etc. Console operation, CI ready, fully configurable, no need for java (comming soon) or IDE. Covers full ui5 browser matrix - Chrome,Firefox,IE,Edge,Safari,iOS,Android. Open-source, modify to suite your specific neeeds. Browser Matrix With this step and the underlying Docker image ( selenium/standalone-chrome ) only Chrome tests are possible. Testing of further browsers can be done with using a custom Docker image. Prerequisites \u00b6 Parameters \u00b6 name mandatory default possible values dockerEnvVars no [:] dockerImage no dockerWorkspace no failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id installCommand no npm install @ui5/uiveri5 --global --quiet runCommand no uiveri5 --seleniumAddress='http://${config.seleniumHost}:${config.seleniumPort}/wd/hub' script yes seleniumHost no seleniumPort no 4444 sidecarEnvVars no sidecarImage no stashContent no [buildDescriptor, tests] testOptions no `` testRepository no testServerUrl no dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository installCommand - The command that is executed to install the test tool. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHost - The host of the selenium hub, this is set automatically to localhost in a Kubernetes environment (determined by the ON_K8S environment variable) of to selenium in any other case. The value is only needed for the runCommand . seleniumPort - The port of the selenium hub. The value is only needed for the runCommand . sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testOptions - This allows to set specific options for the UIVeri5 execution. Details can be found in the UIVeri5 documentation . testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. testServerUrl - The testServerUrl is passed as environment variable TARGET_SERVER_URL to the test execution. The tests should read the host information from this environment variable in order to be infrastructure agnostic. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerEnvVars X dockerImage X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X X installCommand X runCommand X script seleniumHost X seleniumPort X sidecarEnvVars X sidecarImage X stashContent X testOptions X testRepository X testServerUrl X Dependencies \u00b6 The step depends on the following Jenkins plugins git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 If you see an error like fatal: Not a git repository (or any parent up to mount point /home/jenkins) it is likely that your test description cannot be found. Please make sure to point parameter testOptions to your conf.js file like testOptions: './path/to/my/tests/conf.js' Examples \u00b6 Passing credentials from Jenkins \u00b6 When running acceptance tests in a real environment, authentication will be enabled in most cases. UIVeri5 includes features to automatically perform the login with credentials in the conf.js . However, having credentials to the acceptance system stored in plain text is not an optimal solution. Therefore, UIVeri5 allows templating to set parameters at runtime, as shown in the following example conf.js : // Read environment variables const defaultParams = { url : process . env . TARGET_SERVER_URL , user : process . env . TEST_USER , pass : process . env . TEST_PASS }; // Resolve path to specs relative to the working directory const path = require ( 'path' ); const specs = path . relative ( process . cwd (), path . join ( __dirname , '*.spec.js' )); // export UIVeri5 config exports . config = { profile : 'integration' , baseUrl : '${params.url}' , specs : specs , params : defaultParams , // can be overridden via cli `--params.<key>=<value>` auth : { // set up authorization for CF XSUAA 'sapcloud-form' : { user : '${params.user}' , pass : '${params.pass}' , userFieldSelector : 'input[name=\"username\"]' , passFieldSelector : 'input[name=\"password\"]' , logonButtonSelector : 'input[type=\"submit\"]' , redirectUrl : /cp.portal\\/site/ } } }; While default values for baseUrl , user and pass are read from the environment, they can also be overridden when calling the CLI. In a custom Pipeline, this is very simple: Just wrap the call to uiVeri5ExecuteTests in withCredentials ( TARGET_SERVER_URL is read from config.yml ): withCredentials ([ usernamePassword ( credentialsId: 'MY_ACCEPTANCE_CREDENTIALS' , passwordVariable: 'password' , usernameVariable: 'username' )]) { uiVeri5ExecuteTests script: this , testOptions: \"./uiveri5/conf.js --params.user=${username} --params.pass=${password}\" } In a Pipeline Template, a Stage Exit can be used to fetch the credentials and store them in the environment. As the environment is passed down to uiVeri5ExecuteTests, the variables will be present there. This is an example for the stage exit .pipeline/extensions/Acceptance.groovy where the credentialsId is read from the config.yml : void call ( Map params ) { // read username and password from the credential store withCredentials ([ usernamePassword ( credentialsId: params . config . acceptanceCredentialsId , passwordVariable: 'password' , usernameVariable: 'username' )]) { // store the result in the environment variables for executeUIVeri5Test withEnv ([ \"TEST_USER=${username}\" , \"TEST_PASS=${password}\" ]) { //execute original stage as defined in the template params . originalStage () } } } return this","title":"uiVeri5ExecuteTests"},{"location":"steps/uiVeri5ExecuteTests/#uiveri5executetests","text":"","title":"uiVeri5ExecuteTests"},{"location":"steps/uiVeri5ExecuteTests/#description","text":"With this step UIVeri5 tests can be executed. UIVeri5 describes following benefits on its GitHub page: Automatic synchronization with UI5 app rendering so there is no need to add waits and sleeps to your test. Tests are reliable by design. Tests are written in synchronous manner, no callbacks, no promise chaining so are really simple to write and maintain. Full power of webdriverjs, protractor and jasmine - deferred selectors, custom matchers, custom locators. Control locators (OPA5 declarative matchers) allow locating and interacting with UI5 controls. Does not depend on testability support in applications - works with autorefreshing views, resizing elements, animated transitions. Declarative authentications - authentication flow over OAuth2 providers, etc. Console operation, CI ready, fully configurable, no need for java (comming soon) or IDE. Covers full ui5 browser matrix - Chrome,Firefox,IE,Edge,Safari,iOS,Android. Open-source, modify to suite your specific neeeds. Browser Matrix With this step and the underlying Docker image ( selenium/standalone-chrome ) only Chrome tests are possible. Testing of further browsers can be done with using a custom Docker image.","title":"Description"},{"location":"steps/uiVeri5ExecuteTests/#prerequisites","text":"","title":"Prerequisites"},{"location":"steps/uiVeri5ExecuteTests/#parameters","text":"name mandatory default possible values dockerEnvVars no [:] dockerImage no dockerWorkspace no failOnError no false true , false gitBranch no gitSshKeyCredentialsId no `` Jenkins credentials id installCommand no npm install @ui5/uiveri5 --global --quiet runCommand no uiveri5 --seleniumAddress='http://${config.seleniumHost}:${config.seleniumPort}/wd/hub' script yes seleniumHost no seleniumPort no 4444 sidecarEnvVars no sidecarImage no stashContent no [buildDescriptor, tests] testOptions no `` testRepository no testServerUrl no dockerEnvVars - Environment variables to set in the container, e.g. [http_proxy: 'proxy:8080']. dockerImage - Name of the docker image that should be used. If empty, Docker is not used and the command is executed directly on the Jenkins system. dockerWorkspace - Kubernetes only: Specifies a dedicated user home directory for the container which will be passed as value for environment variable HOME . failOnError - With failOnError the behavior in case tests fail can be defined. gitBranch - Only if testRepository is provided: Branch of testRepository, defaults to master. gitSshKeyCredentialsId - Only if testRepository is provided: Credentials for a protected testRepository installCommand - The command that is executed to install the test tool. runCommand - The command that is executed to start the tests. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. seleniumHost - The host of the selenium hub, this is set automatically to localhost in a Kubernetes environment (determined by the ON_K8S environment variable) of to selenium in any other case. The value is only needed for the runCommand . seleniumPort - The port of the selenium hub. The value is only needed for the runCommand . sidecarEnvVars - as dockerEnvVars for the sidecar container sidecarImage - as dockerImage for the sidecar container stashContent - Specific stashes that should be considered for the step execution. testOptions - This allows to set specific options for the UIVeri5 execution. Details can be found in the UIVeri5 documentation . testRepository - Define an additional repository where the test implementation is located. For protected repositories the testRepository needs to contain the ssh git url. testServerUrl - The testServerUrl is passed as environment variable TARGET_SERVER_URL to the test execution. The tests should read the host information from this environment variable in order to be infrastructure agnostic.","title":"Parameters"},{"location":"steps/uiVeri5ExecuteTests/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage dockerEnvVars X dockerImage X dockerWorkspace X failOnError X gitBranch X gitSshKeyCredentialsId X X installCommand X runCommand X script seleniumHost X seleniumPort X sidecarEnvVars X sidecarImage X stashContent X testOptions X testRepository X testServerUrl X","title":"Step configuration"},{"location":"steps/uiVeri5ExecuteTests/#dependencies","text":"The step depends on the following Jenkins plugins git pipeline-utility-steps workflow-basic-steps workflow-cps-global-lib workflow-durable-task-step Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/uiVeri5ExecuteTests/#exceptions","text":"If you see an error like fatal: Not a git repository (or any parent up to mount point /home/jenkins) it is likely that your test description cannot be found. Please make sure to point parameter testOptions to your conf.js file like testOptions: './path/to/my/tests/conf.js'","title":"Exceptions"},{"location":"steps/uiVeri5ExecuteTests/#examples","text":"","title":"Examples"},{"location":"steps/uiVeri5ExecuteTests/#passing-credentials-from-jenkins","text":"When running acceptance tests in a real environment, authentication will be enabled in most cases. UIVeri5 includes features to automatically perform the login with credentials in the conf.js . However, having credentials to the acceptance system stored in plain text is not an optimal solution. Therefore, UIVeri5 allows templating to set parameters at runtime, as shown in the following example conf.js : // Read environment variables const defaultParams = { url : process . env . TARGET_SERVER_URL , user : process . env . TEST_USER , pass : process . env . TEST_PASS }; // Resolve path to specs relative to the working directory const path = require ( 'path' ); const specs = path . relative ( process . cwd (), path . join ( __dirname , '*.spec.js' )); // export UIVeri5 config exports . config = { profile : 'integration' , baseUrl : '${params.url}' , specs : specs , params : defaultParams , // can be overridden via cli `--params.<key>=<value>` auth : { // set up authorization for CF XSUAA 'sapcloud-form' : { user : '${params.user}' , pass : '${params.pass}' , userFieldSelector : 'input[name=\"username\"]' , passFieldSelector : 'input[name=\"password\"]' , logonButtonSelector : 'input[type=\"submit\"]' , redirectUrl : /cp.portal\\/site/ } } }; While default values for baseUrl , user and pass are read from the environment, they can also be overridden when calling the CLI. In a custom Pipeline, this is very simple: Just wrap the call to uiVeri5ExecuteTests in withCredentials ( TARGET_SERVER_URL is read from config.yml ): withCredentials ([ usernamePassword ( credentialsId: 'MY_ACCEPTANCE_CREDENTIALS' , passwordVariable: 'password' , usernameVariable: 'username' )]) { uiVeri5ExecuteTests script: this , testOptions: \"./uiveri5/conf.js --params.user=${username} --params.pass=${password}\" } In a Pipeline Template, a Stage Exit can be used to fetch the credentials and store them in the environment. As the environment is passed down to uiVeri5ExecuteTests, the variables will be present there. This is an example for the stage exit .pipeline/extensions/Acceptance.groovy where the credentialsId is read from the config.yml : void call ( Map params ) { // read username and password from the credential store withCredentials ([ usernamePassword ( credentialsId: params . config . acceptanceCredentialsId , passwordVariable: 'password' , usernameVariable: 'username' )]) { // store the result in the environment variables for executeUIVeri5Test withEnv ([ \"TEST_USER=${username}\" , \"TEST_PASS=${password}\" ]) { //execute original stage as defined in the template params . originalStage () } } } return this","title":"Passing credentials from Jenkins"},{"location":"steps/whitesourceExecuteScan/","text":"whitesourceExecuteScan \u00b6 Description \u00b6 BETA With this step WhiteSource security and license compliance scans can be executed and assessed. WhiteSource is a Software as a Service offering based on a so called unified agent that locally determines the dependency tree of a node.js, Java, Python, Ruby, or Scala based solution and sends it to the WhiteSource server for a policy based license compliance check and additional Free and Open Source Software Publicly Known Vulnerabilities detection. Docker Images The underlying Docker images are public and specific to the solution's programming language(s) and therefore may have to be exchanged to fit to and support the relevant scenario. The default Python environment used is i.e. Python 3 based. Restrictions Currently the step does contain hardened scan configurations for scanType 'pip' and 'go' . Other environments are still being elaborated, so please thoroughly check your results and do not take them for granted by default. Also not all environments have been thoroughly tested already therefore you might need to tweak around with the default containers used or create your own ones to adequately support your scenario. To do so please modify dockerImage and dockerWorkspace parameters. The step expects an environment containing the programming language related compiler/interpreter as well as the related build tool. For a list of the supported build tools per environment please refer to the WhiteSource Unified Agent Documentation . Prerequisites \u00b6 Your company has registered an account with WhiteSource and you have enabled the use of so called User Keys to manage access to your organization in WhiteSource via dedicated privileges. Scanning your products without adequate user level access protection imposed on the WhiteSource backend would simply allow access based on the organization token. Parameters \u00b6 name mandatory default possible values agentDownloadUrl no https://github.com/whitesource/unified-agent-distribution/raw/master/standAlone/${config.agentFileName} agentFileName no wss-unified-agent.jar agentParameters no `` buildDescriptorExcludeList no [] buildDescriptorFile no scanType= golang : ./Gopkg.toml scanType= maven : ./pom.xml scanType= mta : <empty> scanType= npm : ./package.json scanType= pip : ./setup.py scanType= sbt : ./build.sbt configFilePath no ./wss-unified-agent.config createProductFromPipeline no true cvssSeverityLimit no -1 -1 to switch failing off, any positive integer between 0 and 10 to fail on issues with the specified limit or above dockerImage no scanType= golang : golang:1.12-stretch scanType= maven : maven:3.5-jdk-8 scanType= mta : <empty> scanType= npm : node:8-stretch scanType= pip : python:3.7.2-stretch scanType= sbt : hseeberger/scala-sbt:8u181_2.12.8_1.2.8 dockerWorkspace no scanType= golang : /home/dep scanType= maven : /home/java scanType= mta : <empty> scanType= npm : /home/node scanType= pip : /home/python scanType= sbt : /home/scala emailAddressesOfInitialProductAdmins no [] installCommand no licensingVulnerabilities no true true , false parallelLimit no 15 reporting no true true , false scanType no golang , maven , mta , npm , pip , sbt script yes securityVulnerabilities no true true , false stashContent no scanType= golang : [buildDescriptor, opensourceConfiguration, checkmarx] scanType= maven : [buildDescriptor, opensourceConfiguration] scanType= mta : [buildDescriptor, opensourceConfiguration] scanType= npm : [buildDescriptor, opensourceConfiguration] scanType= pip : [buildDescriptor, opensourceConfiguration] scanType= sbt : [buildDescriptor, opensourceConfiguration] timeout no 0 verbose no false true , false vulnerabilityReportFileName no piper_whitesource_vulnerability_report vulnerabilityReportTitle no WhiteSource Security Vulnerability Report whitesource/jreDownloadUrl no whitesource/orgAdminUserTokenCredentialsId no whitesource/orgToken yes whitesource/productName yes whitesource/productToken no whitesource/productVersion no whitesource/projectNames no whitesource/serviceUrl no https://saas.whitesourcesoftware.com/api whitesource/userTokenCredentialsId yes agentDownloadUrl - URL used to download the latest version of the WhiteSource Unified Agent. agentFileName - Locally used name for the Unified Agent jar file after download. agentParameters - Additional parameters passed to the Unified Agent command line. buildDescriptorExcludeList - List of build descriptors and therefore modules to exclude from the scan and assessment activities. buildDescriptorFile - Explicit path to the build descriptor file. configFilePath - Explicit path to the WhiteSource Unified Agent configuration file. createProductFromPipeline - Whether to create the related WhiteSource product on the fly based on the supplied pipeline configuration. cvssSeverityLimit - Limit of tollerable CVSS v3 score upon assessment and in consequence fails the build, defaults to -1 . dockerImage - Docker image to be used for scanning. dockerWorkspace - Docker workspace to be used for scanning. emailAddressesOfInitialProductAdmins - The list of email addresses to assign as product admins for newly created WhiteSource products. installCommand - Install command that can be used to populate the default docker image for some scenarios. licensingVulnerabilities - Whether license compliance is considered and reported as part of the assessment. parallelLimit - Limit of parallel jobs being run at once in case of scanType: 'mta' based scenarios, defaults to 15 . reporting - Whether assessment is being done at all, defaults to true . scanType - Type of development stack used to implement the solution. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityVulnerabilities - Whether security compliance is considered and reported as part of the assessment. stashContent - List of stashes to be unstashed into the workspace before performing the scan. timeout - Timeout in seconds until a HTTP call is forcefully terminated. verbose - Whether verbose output should be produced. vulnerabilityReportFileName - Name of the file the vulnerability report is written to. vulnerabilityReportTitle - Title of vulnerability report written during the assessment phase. whitesource/jreDownloadUrl - URL used for downloading the Java Runtime Environment (JRE) required to run the WhiteSource Unified Agent. whitesource/orgAdminUserTokenCredentialsId - Jenkins credentials ID referring to the organization admin's token. whitesource/orgToken - WhiteSource token identifying your organization. whitesource/productName - Name of the WhiteSource product to be created and used for results aggregation. whitesource/productToken - Token of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/productVersion - Version of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/projectNames - List of WhiteSource projects to be included in the assessment part of the step, usually determined automatically. whitesource/serviceUrl - URL to the WhiteSource server API used for communication, defaults to https://saas.whitesourcesoftware.com/api . whitesource/userTokenCredentialsId - Jenkins credentials ID referring to the product admin's token. Step configuration \u00b6 We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage agentDownloadUrl X agentFileName X agentParameters X buildDescriptorExcludeList X buildDescriptorFile X configFilePath X createProductFromPipeline X cvssSeverityLimit X dockerImage X dockerWorkspace X emailAddressesOfInitialProductAdmins X installCommand X licensingVulnerabilities X parallelLimit X reporting X scanType X X script securityVulnerabilities X stashContent X timeout X verbose X X vulnerabilityReportFileName X vulnerabilityReportTitle X whitesource/jreDownloadUrl X X whitesource/orgAdminUserTokenCredentialsId X X whitesource/orgToken X X whitesource/productName X X whitesource/productToken X X whitesource/productVersion X X whitesource/projectNames X X whitesource/serviceUrl X X whitesource/userTokenCredentialsId X X Dependencies \u00b6 The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins. Exceptions \u00b6 None Examples \u00b6 whitesourceExecuteScan script: this , scanType: 'pip' , productName: 'My Whitesource Product' , userTokenCredentialsId: 'companyAdminToken' , orgAdminUserTokenCredentialsId: 'orgAdminToken' , orgToken: 'myWhitesourceOrganizationToken'","title":"whitesourceExecuteScan"},{"location":"steps/whitesourceExecuteScan/#whitesourceexecutescan","text":"","title":"whitesourceExecuteScan"},{"location":"steps/whitesourceExecuteScan/#description","text":"BETA With this step WhiteSource security and license compliance scans can be executed and assessed. WhiteSource is a Software as a Service offering based on a so called unified agent that locally determines the dependency tree of a node.js, Java, Python, Ruby, or Scala based solution and sends it to the WhiteSource server for a policy based license compliance check and additional Free and Open Source Software Publicly Known Vulnerabilities detection. Docker Images The underlying Docker images are public and specific to the solution's programming language(s) and therefore may have to be exchanged to fit to and support the relevant scenario. The default Python environment used is i.e. Python 3 based. Restrictions Currently the step does contain hardened scan configurations for scanType 'pip' and 'go' . Other environments are still being elaborated, so please thoroughly check your results and do not take them for granted by default. Also not all environments have been thoroughly tested already therefore you might need to tweak around with the default containers used or create your own ones to adequately support your scenario. To do so please modify dockerImage and dockerWorkspace parameters. The step expects an environment containing the programming language related compiler/interpreter as well as the related build tool. For a list of the supported build tools per environment please refer to the WhiteSource Unified Agent Documentation .","title":"Description"},{"location":"steps/whitesourceExecuteScan/#prerequisites","text":"Your company has registered an account with WhiteSource and you have enabled the use of so called User Keys to manage access to your organization in WhiteSource via dedicated privileges. Scanning your products without adequate user level access protection imposed on the WhiteSource backend would simply allow access based on the organization token.","title":"Prerequisites"},{"location":"steps/whitesourceExecuteScan/#parameters","text":"name mandatory default possible values agentDownloadUrl no https://github.com/whitesource/unified-agent-distribution/raw/master/standAlone/${config.agentFileName} agentFileName no wss-unified-agent.jar agentParameters no `` buildDescriptorExcludeList no [] buildDescriptorFile no scanType= golang : ./Gopkg.toml scanType= maven : ./pom.xml scanType= mta : <empty> scanType= npm : ./package.json scanType= pip : ./setup.py scanType= sbt : ./build.sbt configFilePath no ./wss-unified-agent.config createProductFromPipeline no true cvssSeverityLimit no -1 -1 to switch failing off, any positive integer between 0 and 10 to fail on issues with the specified limit or above dockerImage no scanType= golang : golang:1.12-stretch scanType= maven : maven:3.5-jdk-8 scanType= mta : <empty> scanType= npm : node:8-stretch scanType= pip : python:3.7.2-stretch scanType= sbt : hseeberger/scala-sbt:8u181_2.12.8_1.2.8 dockerWorkspace no scanType= golang : /home/dep scanType= maven : /home/java scanType= mta : <empty> scanType= npm : /home/node scanType= pip : /home/python scanType= sbt : /home/scala emailAddressesOfInitialProductAdmins no [] installCommand no licensingVulnerabilities no true true , false parallelLimit no 15 reporting no true true , false scanType no golang , maven , mta , npm , pip , sbt script yes securityVulnerabilities no true true , false stashContent no scanType= golang : [buildDescriptor, opensourceConfiguration, checkmarx] scanType= maven : [buildDescriptor, opensourceConfiguration] scanType= mta : [buildDescriptor, opensourceConfiguration] scanType= npm : [buildDescriptor, opensourceConfiguration] scanType= pip : [buildDescriptor, opensourceConfiguration] scanType= sbt : [buildDescriptor, opensourceConfiguration] timeout no 0 verbose no false true , false vulnerabilityReportFileName no piper_whitesource_vulnerability_report vulnerabilityReportTitle no WhiteSource Security Vulnerability Report whitesource/jreDownloadUrl no whitesource/orgAdminUserTokenCredentialsId no whitesource/orgToken yes whitesource/productName yes whitesource/productToken no whitesource/productVersion no whitesource/projectNames no whitesource/serviceUrl no https://saas.whitesourcesoftware.com/api whitesource/userTokenCredentialsId yes agentDownloadUrl - URL used to download the latest version of the WhiteSource Unified Agent. agentFileName - Locally used name for the Unified Agent jar file after download. agentParameters - Additional parameters passed to the Unified Agent command line. buildDescriptorExcludeList - List of build descriptors and therefore modules to exclude from the scan and assessment activities. buildDescriptorFile - Explicit path to the build descriptor file. configFilePath - Explicit path to the WhiteSource Unified Agent configuration file. createProductFromPipeline - Whether to create the related WhiteSource product on the fly based on the supplied pipeline configuration. cvssSeverityLimit - Limit of tollerable CVSS v3 score upon assessment and in consequence fails the build, defaults to -1 . dockerImage - Docker image to be used for scanning. dockerWorkspace - Docker workspace to be used for scanning. emailAddressesOfInitialProductAdmins - The list of email addresses to assign as product admins for newly created WhiteSource products. installCommand - Install command that can be used to populate the default docker image for some scenarios. licensingVulnerabilities - Whether license compliance is considered and reported as part of the assessment. parallelLimit - Limit of parallel jobs being run at once in case of scanType: 'mta' based scenarios, defaults to 15 . reporting - Whether assessment is being done at all, defaults to true . scanType - Type of development stack used to implement the solution. script - The common script environment of the Jenkinsfile running. Typically the reference to the script calling the pipeline step is provided with the this parameter, as in script: this . This allows the function to access the commonPipelineEnvironment for retrieving, e.g. configuration parameters. securityVulnerabilities - Whether security compliance is considered and reported as part of the assessment. stashContent - List of stashes to be unstashed into the workspace before performing the scan. timeout - Timeout in seconds until a HTTP call is forcefully terminated. verbose - Whether verbose output should be produced. vulnerabilityReportFileName - Name of the file the vulnerability report is written to. vulnerabilityReportTitle - Title of vulnerability report written during the assessment phase. whitesource/jreDownloadUrl - URL used for downloading the Java Runtime Environment (JRE) required to run the WhiteSource Unified Agent. whitesource/orgAdminUserTokenCredentialsId - Jenkins credentials ID referring to the organization admin's token. whitesource/orgToken - WhiteSource token identifying your organization. whitesource/productName - Name of the WhiteSource product to be created and used for results aggregation. whitesource/productToken - Token of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/productVersion - Version of the WhiteSource product to be created and used for results aggregation, usually determined automatically. whitesource/projectNames - List of WhiteSource projects to be included in the assessment part of the step, usually determined automatically. whitesource/serviceUrl - URL to the WhiteSource server API used for communication, defaults to https://saas.whitesourcesoftware.com/api . whitesource/userTokenCredentialsId - Jenkins credentials ID referring to the product admin's token.","title":"Parameters"},{"location":"steps/whitesourceExecuteScan/#step-configuration","text":"We recommend to define values of step parameters via config.yml file . In following sections of the config.yml the configuration is possible: parameter general step/stage agentDownloadUrl X agentFileName X agentParameters X buildDescriptorExcludeList X buildDescriptorFile X configFilePath X createProductFromPipeline X cvssSeverityLimit X dockerImage X dockerWorkspace X emailAddressesOfInitialProductAdmins X installCommand X licensingVulnerabilities X parallelLimit X reporting X scanType X X script securityVulnerabilities X stashContent X timeout X verbose X X vulnerabilityReportFileName X vulnerabilityReportTitle X whitesource/jreDownloadUrl X X whitesource/orgAdminUserTokenCredentialsId X X whitesource/orgToken X X whitesource/productName X X whitesource/productToken X X whitesource/productVersion X X whitesource/projectNames X X whitesource/serviceUrl X X whitesource/userTokenCredentialsId X X","title":"Step configuration"},{"location":"steps/whitesourceExecuteScan/#dependencies","text":"The step depends on the following Jenkins plugins credentials-binding docker kubernetes pipeline-utility-steps workflow-basic-steps workflow-cps workflow-cps-global-lib workflow-durable-task-step The kubernetes plugin is only used if running in a kubernetes environment. Transitive dependencies are omitted. The list might be incomplete. Consider using the ppiper/jenkins-master docker image. This images comes with preinstalled plugins.","title":"Dependencies"},{"location":"steps/whitesourceExecuteScan/#exceptions","text":"None","title":"Exceptions"},{"location":"steps/whitesourceExecuteScan/#examples","text":"whitesourceExecuteScan script: this , scanType: 'pip' , productName: 'My Whitesource Product' , userTokenCredentialsId: 'companyAdminToken' , orgAdminUserTokenCredentialsId: 'orgAdminToken' , orgToken: 'myWhitesourceOrganizationToken'","title":"Examples"}]}